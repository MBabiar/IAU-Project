{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063d3ffe",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64de97",
   "metadata": {},
   "source": [
    "Quick solution for tensorflow module not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b913d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import os\n",
    "from tensorflow.keras.models import Sequential\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D,InputLayer, Rescaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a67b7",
   "metadata": {},
   "source": [
    "## Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data():\n",
    "    # Load dataset\n",
    "    path = kagglehub.dataset_download(\"arashnic/faces-age-detection-dataset\")\n",
    "\n",
    "    # Define path to files\n",
    "    faces_path = os.path.join(path, \"faces\")\n",
    "    train_path = os.path.join(faces_path, \"Train\")\n",
    "\n",
    "    # Create directory for raw data\n",
    "    export_path = \"../data/raw/faces\"\n",
    "    os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "    # Copy files to raw data directory\n",
    "    shutil.copytree(train_path, os.path.join(export_path, \"images\"), dirs_exist_ok=True)\n",
    "    shutil.copy(os.path.join(faces_path, \"train.csv\"), os.path.join(export_path, \"train.csv\"))\n",
    "\n",
    "    export_path = \"../data/raw\"\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/raw/faces\"):\n",
    "    import_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb901a",
   "metadata": {},
   "source": [
    "-   Faces_02 has no csv file for classification so we are gonna skip it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4adb0b5",
   "metadata": {},
   "source": [
    "## Definitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/raw/faces/train.csv\")\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420be583",
   "metadata": {},
   "source": [
    "# 4.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ade08",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18549f99",
   "metadata": {},
   "source": [
    "-   EDA a data preprocessing pre Vami vybrané charakteristiky z datasetu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e30eb",
   "metadata": {},
   "source": [
    "### EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c57241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62138c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d35342",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/raw/faces/images\"\n",
    "num_files = len([name for name in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, name))])\n",
    "print(f\"Number of images: {num_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"Class\"].value_counts())\n",
    "df_train[\"Class\"].value_counts().plot(kind=\"bar\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f144a",
   "metadata": {},
   "source": [
    "-   There are no nulls\n",
    "-   There are no duplicates\n",
    "-   Number of images is same as number of data in cvs file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e20a0",
   "metadata": {},
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4739f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your CSV file\n",
    "image_dir = \"../data/raw/faces/images\"\n",
    "\n",
    "def is_low_quality(image_path, min_width=50, min_height=50, threshold=50.0):\n",
    "    try:\n",
    "        img = Image.open(image_path)\n",
    "        img2 = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if img2 is None:\n",
    "            return True\n",
    "        laplacian_var = cv2.Laplacian(img2, cv2.CV_64F).var()\n",
    "        width, height = img.size\n",
    "        return width < min_width or height < min_height or laplacian_var < threshold\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error opening image {image_path}: {e}\")\n",
    "        return True  \n",
    "\n",
    "if (not os.path.exists(\"../data/processed\")):\n",
    "    low_quality_images = []\n",
    "    for image_id in df_train['ID']:\n",
    "        image_path = os.path.join(image_dir, image_id)\n",
    "        if not os.path.exists(image_path):\n",
    "            print(f\"File not found: {image_path}\")\n",
    "            break\n",
    "        if is_low_quality(image_path):\n",
    "            low_quality_images.append(image_id)\n",
    "\n",
    "    print(f\"Number of low quality images: {len(low_quality_images)}\")\n",
    "\n",
    "    os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "    df_train = df_train[~df_train['ID'].isin(low_quality_images)]\n",
    "    df_train.to_csv(\"../data/processed/train.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, target_size):\n",
    "    output_dir = \"../data/processed/faces\"\n",
    "\n",
    "    young_dir = os.path.join(output_dir, \"young\")\n",
    "    middle_dir = os.path.join(output_dir, \"middle\")\n",
    "    old_dir = os.path.join(output_dir, \"old\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(young_dir, exist_ok=True)\n",
    "    os.makedirs(middle_dir, exist_ok=True)\n",
    "    os.makedirs(old_dir, exist_ok=True)\n",
    "\n",
    "    for _, row in images.iterrows():\n",
    "        img_name = row[\"ID\"]\n",
    "        img_path = os.path.join(\"../data/raw/faces/images\", img_name)\n",
    "        img = image.load_img(img_path, target_size=target_size, color_mode=\"grayscale\")\n",
    "\n",
    "        if row[\"Class\"].upper() == \"YOUNG\":\n",
    "            img.save(os.path.join(young_dir, img_name))\n",
    "        elif row[\"Class\"].upper() == \"MIDDLE\":\n",
    "            img.save(os.path.join(middle_dir, img_name))\n",
    "        elif row[\"Class\"].upper() == \"OLD\":\n",
    "            img.save(os.path.join(old_dir, img_name))\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/processed/faces\"):\n",
    "    resize_images(df_train, target_size=(IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/processed/faces\", shuffle=True, image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433106a",
   "metadata": {},
   "source": [
    "#### Splitting Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b755921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: IAU_01_CNN-tf-keras_Lung-cancer.ipynb\n",
    "def splitDataset(data, train_split=0.7, val_split=0.2, test_split=0.1):\n",
    "    data_size = len(data)\n",
    "\n",
    "    train_size = int(train_split * data_size)\n",
    "    val_size = int(val_split * data_size)\n",
    "\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "train_ds, val_ds, test_ds = splitDataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8fcc6",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbae96a",
   "metadata": {},
   "source": [
    "-   Zdôvodnite výber ML/DL metód vzhľadom na Vami vybraný dataset pre 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff8c5d",
   "metadata": {},
   "source": [
    "# 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c9b05",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf6444",
   "metadata": {},
   "source": [
    "-   Modeluje Vami tie vybrané charakteristiky pomocou vhodných ML/DL\n",
    "    metód. Výsledok modelovania je najlepší model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = None\n",
    "for batch, labels in train_ds.take(1):\n",
    "    input_shape = batch.shape\n",
    "\n",
    "model = Sequential(\n",
    "    [\n",
    "        InputLayer(shape=input_shape[1:]),\n",
    "        Rescaling(1.0 / 255),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Dropout(0.3),\n",
    "        Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds, epochs=6, validation_data=val_ds, batch_size=BATCH_SIZE, validation_batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(val_ds, batch_size=BATCH_SIZE)\n",
    "print(f\"Loss: {round(loss, 3)}, Acc: {round(acc*100, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(range(6), history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.plot(range(6), history.history[\"loss\"], label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fac1a1",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d8a1",
   "metadata": {},
   "source": [
    "-   Zhodnotíte Váš prístup a získaný výsledok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24c9638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"GPU Details:\")\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    print(gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c178ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Method 1: Check if CUDA is available\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Method 2: List physical devices\n",
    "print(\"\\nPhysical Devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "print(\"\\nGPU Devices:\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Method 3: Run operation to check device placement\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"\\nMatrix multiplication result:\", c)\n",
    "    print(\"Device tensor is on:\", c.device)\n",
    "\n",
    "# Method 4: Get current device\n",
    "print(\"\\nTensorFlow version:\", tf.__version__)\n",
    "print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
