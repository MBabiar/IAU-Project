{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063d3ffe",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64de97",
   "metadata": {},
   "source": [
    "Quick solution for tensorflow module not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b913d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import cv2\n",
    "import kagglehub\n",
    "import keras_tuner as kt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from tensorflow.keras.layers import (\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    InputLayer,\n",
    "    MaxPooling2D,\n",
    "    Rescaling,\n",
    ")\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a67b7",
   "metadata": {},
   "source": [
    "## Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e2c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data():\n",
    "    # Load dataset\n",
    "    path = kagglehub.dataset_download(\"arashnic/faces-age-detection-dataset\")\n",
    "\n",
    "    # Define path to files\n",
    "    faces_path = os.path.join(path, \"faces\")\n",
    "    train_path = os.path.join(faces_path, \"Train\")\n",
    "\n",
    "    # Create directory for raw data\n",
    "    export_path = \"../data/raw/faces\"\n",
    "    os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "    # Copy files to raw data directory\n",
    "    shutil.copytree(train_path, os.path.join(export_path, \"images\"), dirs_exist_ok=True)\n",
    "    shutil.copy(os.path.join(faces_path, \"train.csv\"), os.path.join(export_path, \"train.csv\"))\n",
    "\n",
    "    export_path = \"../data/raw\"\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/raw/faces\"):\n",
    "    import_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb901a",
   "metadata": {},
   "source": [
    "-   Faces_02 has no csv file for classification so we are gonna skip it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4adb0b5",
   "metadata": {},
   "source": [
    "## Definitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b88f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/raw/faces/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420be583",
   "metadata": {},
   "source": [
    "# 4.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ade08",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18549f99",
   "metadata": {},
   "source": [
    "-   EDA a data preprocessing pre Vami vybrané charakteristiky z datasetu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e30eb",
   "metadata": {},
   "source": [
    "### EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c57241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62138c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d35342",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/raw/faces/images\"\n",
    "num_files = len([name for name in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, name))])\n",
    "print(f\"Number of images: {num_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"Class\"].value_counts())\n",
    "df_train[\"Class\"].value_counts().plot(kind=\"bar\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f144a",
   "metadata": {},
   "source": [
    "-   There are no nulls\n",
    "-   There are no duplicates\n",
    "-   Number of images is same as number of data in cvs file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e20a0",
   "metadata": {},
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4739f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize images and save them into categorical directories\n",
    "def process_images(images, target_size, color_mode):\n",
    "    output_dir = f\"../data/processed/faces/{color_mode}/{target_size[0]}x{target_size[1]}\"\n",
    "\n",
    "    young_dir = os.path.join(output_dir, \"young\")\n",
    "    middle_dir = os.path.join(output_dir, \"middle\")\n",
    "    old_dir = os.path.join(output_dir, \"old\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(young_dir, exist_ok=True)\n",
    "    os.makedirs(middle_dir, exist_ok=True)\n",
    "    os.makedirs(old_dir, exist_ok=True)\n",
    "\n",
    "    for _, row in images.iterrows():\n",
    "        img_name = row[\"ID\"]\n",
    "        img_path = os.path.join(\"../data/raw/faces/images\", img_name)\n",
    "        img = image.load_img(img_path, target_size=target_size, color_mode=color_mode)\n",
    "\n",
    "        if row[\"Class\"].upper() == \"YOUNG\":\n",
    "            img.save(os.path.join(young_dir, img_name))\n",
    "        elif row[\"Class\"].upper() == \"MIDDLE\":\n",
    "            img.save(os.path.join(middle_dir, img_name))\n",
    "        elif row[\"Class\"].upper() == \"OLD\":\n",
    "            img.save(os.path.join(old_dir, img_name))\n",
    "\n",
    "\n",
    "# Get low quality images\n",
    "def get_low_quality_images(images, min_width=15, min_height=15):\n",
    "    image_dir = \"../data/raw/faces/images\"\n",
    "    low_quality_images = []\n",
    "\n",
    "    for image_id in images[\"ID\"]:\n",
    "\n",
    "        image_path = os.path.join(image_dir, image_id)\n",
    "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "        if img.shape[0] < min_width or img.shape[1] < min_height:\n",
    "            low_quality_images.append(image_id)\n",
    "            continue\n",
    "\n",
    "        compressed = cv2.resize(img, None, fx=0.5, fy=0.5)\n",
    "        compressed = cv2.resize(compressed, (img.shape[1], img.shape[0]))\n",
    "        score, _ = ssim(img, compressed, multichannel=True, full=True)\n",
    "        if score < 0.88:\n",
    "            low_quality_images.append(image_id)\n",
    "\n",
    "    return low_quality_images\n",
    "\n",
    "\n",
    "df_processed = df_train.copy()\n",
    "if os.path.exists(\"../data/processed\"):\n",
    "    shutil.rmtree(\"../data/processed\")\n",
    "\n",
    "os.makedirs(\"../data/processed/faces\", exist_ok=True)\n",
    "\n",
    "# Get low quality images\n",
    "print(\"Getting low quality images\")\n",
    "low_quality_images = get_low_quality_images(df_processed)\n",
    "print(f\"Number of low quality images: {len(low_quality_images)}\")\n",
    "print(f\"Percentage of low quality images: {len(low_quality_images) / len(df_processed) * 100:.2f}%\")\n",
    "\n",
    "# Remove low quality images\n",
    "df_processed = df_processed[~df_processed[\"ID\"].isin(low_quality_images)]\n",
    "\n",
    "# Process images\n",
    "print(\"Processing images, 64x64, grayscale\")\n",
    "process_images(df_processed, (64, 64), \"grayscale\")\n",
    "\n",
    "print(\"Processing images, 64x64, rgb\")\n",
    "process_images(df_processed, (64, 64), \"rgb\")\n",
    "\n",
    "print(\"Processing images, 128x128, grayscale\")\n",
    "process_images(df_processed, (128, 128), \"grayscale\")\n",
    "\n",
    "print(\"Processing images, 128x128, rgb\")\n",
    "process_images(df_processed, (128, 128), \"rgb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8fcc6",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbae96a",
   "metadata": {},
   "source": [
    "-   Zdôvodnite výber ML/DL metód vzhľadom na Vami vybraný dataset pre 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff8c5d",
   "metadata": {},
   "source": [
    "# 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c9b05",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf6444",
   "metadata": {},
   "source": [
    "-   Modeluje Vami tie vybrané charakteristiky pomocou vhodných ML/DL\n",
    "    metód. Výsledok modelovania je najlepší model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2575b",
   "metadata": {},
   "source": [
    "#### Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afdc553",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "\n",
    "\n",
    "def get_dataset(size, color_mode):\n",
    "    # Load dataset\n",
    "    ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        f\"../data/processed/faces/{color_mode}/{size}x{size}\",\n",
    "        shuffle=True,\n",
    "        image_size=(size, size),\n",
    "        batch_size=BATCH_SIZE,\n",
    "    )\n",
    "\n",
    "    # Split dataset\n",
    "    data_size = len(ds)\n",
    "    train_split = 0.7\n",
    "    val_split = 0.2\n",
    "    test_split = 0.1\n",
    "\n",
    "    train_size = int(train_split * data_size)\n",
    "    val_size = int(val_split * data_size)\n",
    "\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "\n",
    "    # Cache, shuffle and prefetch\n",
    "    buffer_size = len(train_ds) * BATCH_SIZE\n",
    "    buffer_size\n",
    "\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "def get_input_shape(train_ds):\n",
    "    for batch, _ in train_ds.take(1):\n",
    "        return batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd1b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_accuracy(history):\n",
    "    plt.plot(history.history[\"accuracy\"], label=\"Training Accuracy\")\n",
    "    plt.plot(history.history[\"val_accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.title(\"Model accuracy\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_loss(history):\n",
    "    plt.plot(history.history[\"loss\"], label=\"Training Loss\")\n",
    "    plt.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "    plt.title(\"Model loss\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_evaluation(model, val_ds, history):\n",
    "    loss, acc = model.evaluate(val_ds, batch_size=BATCH_SIZE)\n",
    "    print(f\"Loss: {round(loss, 3)}, Acc: {round(acc*100, 3)}%\")\n",
    "    show_accuracy(history)\n",
    "    show_loss(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c366a0ea",
   "metadata": {},
   "source": [
    "#### Main Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc7619a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset(64, \"rgb\")\n",
    "input_shape = get_input_shape(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe10370c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2983ebc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        # Preprocessing layers\n",
    "        InputLayer(shape=input_shape[1:]),\n",
    "        Rescaling(1.0 / 255),\n",
    "        # Input and first conv block\n",
    "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Second conv block\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Third conv block\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b297374",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(model, val_ds, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad8c8f",
   "metadata": {},
   "source": [
    "#### Test Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6dbf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset(64)\n",
    "input_shape = get_input_shape(train_ds)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb367db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            # Input and preprocessing layers\n",
    "            InputLayer(shape=input_shape[1:]),\n",
    "            Rescaling(1.0 / 255),\n",
    "            # First conv block - tune filters and kernel size\n",
    "            Conv2D(\n",
    "                32,\n",
    "                hp.Choice(\"conv1_kernel\", values=[3, 5]),\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Second conv block - tune filters and kernel size\n",
    "            Conv2D(\n",
    "                64,\n",
    "                hp.Choice(\"conv2_kernel\", values=[3, 5]),\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Third conv block - tune filters and kernel size\n",
    "            Conv2D(\n",
    "                128,\n",
    "                hp.Choice(\"conv3_kernel\", values=[3, 5]),\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            Flatten(),\n",
    "            Dense(128, activation=\"relu\"),\n",
    "            Dropout(0.5),\n",
    "            Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=20,\n",
    "    factor=3,\n",
    "    directory=\"tuning_dir\",\n",
    "    project_name=\"age_classification\",\n",
    "    overwrite=True,\n",
    ")\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Search for best hyperparameters\n",
    "tuner.search(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[early_stopping])\n",
    "\n",
    "# Get best hyperparameters and build final model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = build_model(best_hps)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate model\n",
    "show_evaluation(model, val_ds, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b24f61",
   "metadata": {},
   "source": [
    "#### Test Model 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a676891d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset(64)\n",
    "input_shape = get_input_shape(train_ds)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd28ec97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        # Preprocessing layers\n",
    "        InputLayer(shape=input_shape[1:]),\n",
    "        Rescaling(1.0 / 255),\n",
    "        # Input and first conv block\n",
    "        Conv2D(32, (5, 5), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Second conv block\n",
    "        Conv2D(64, (5, 5), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Third conv block\n",
    "        Conv2D(128, (5, 5), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80d669e",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a88d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(model, val_ds, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6268046e",
   "metadata": {},
   "source": [
    "#### Test Model 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e24626",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds, test_ds = get_dataset(64)\n",
    "input_shape = get_input_shape(train_ds)\n",
    "\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.1),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "    ]\n",
    ")\n",
    "\n",
    "train_ds = train_ds.map(lambda x, y: (data_augmentation(x, training=True), y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110968f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(\n",
    "    [\n",
    "        # Preprocessing layers\n",
    "        InputLayer(shape=input_shape[1:]),\n",
    "        Rescaling(1.0 / 255),\n",
    "        # Input and first conv block\n",
    "        Conv2D(32, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Second conv block\n",
    "        Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Third conv block\n",
    "        Conv2D(128, (3, 3), activation=\"relu\"),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        # Flatten and dense layers\n",
    "        Flatten(),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.5),\n",
    "        Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed88c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_batch_size=BATCH_SIZE,\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbaa572",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_evaluation(model, val_ds, history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fac1a1",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d8a1",
   "metadata": {},
   "source": [
    "-   Zhodnotíte Váš prístup a získaný výsledok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a61284f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = Sequential(\n",
    "        [\n",
    "            # Input and preprocessing layers\n",
    "            InputLayer(shape=input_shape[1:]),\n",
    "            Rescaling(1.0 / 255),\n",
    "            # First conv block - tune filters and kernel size\n",
    "            Conv2D(\n",
    "                hp.Int(\"conv1_filters\", min_value=8, max_value=32, step=8),\n",
    "                hp.Choice(\"conv1_kernel\", values=[3, 5]),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Second conv block\n",
    "            Conv2D(\n",
    "                hp.Int(\"conv2_filters\", min_value=16, max_value=64, step=16),\n",
    "                hp.Choice(\"conv2_kernel\", values=[3, 5]),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Third conv block\n",
    "            Conv2D(\n",
    "                hp.Int(\"conv3_filters\", min_value=32, max_value=128, step=32),\n",
    "                hp.Choice(\"conv3_kernel\", values=[3, 5]),\n",
    "                padding=\"same\",\n",
    "                activation=\"relu\",\n",
    "            ),\n",
    "            MaxPooling2D((2, 2)),\n",
    "            # Dense layers\n",
    "            Flatten(),\n",
    "            Dense(hp.Int(\"dense_units\", min_value=32, max_value=128, step=32), activation=\"relu\"),\n",
    "            Dropout(hp.Float(\"dropout\", min_value=0.0, max_value=0.5, step=0.1)),\n",
    "            Dense(3, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Tune learning rate\n",
    "    learning_rate = hp.Float(\"learning_rate\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=tf.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Create tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory=\"tuning_dir\",\n",
    "    project_name=\"age_classification\",\n",
    ")\n",
    "\n",
    "# Define early stopping\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True)\n",
    "\n",
    "# Search for best hyperparameters\n",
    "tuner.search(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[early_stopping])\n",
    "\n",
    "# Get best hyperparameters and build final model\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "model = build_model(best_hps)\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=EPOCHS, callbacks=[early_stopping])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
