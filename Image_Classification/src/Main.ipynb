{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "063d3ffe",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e64de97",
   "metadata": {},
   "source": [
    "Quick solution for tensorflow module not found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb9e2095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (5.29.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (75.6.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.68.0)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programming\\fiit-stu\\semester_5\\iau\\iau-project\\image_classification\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import kagglehub\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import seaborn as sns\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a67b7",
   "metadata": {},
   "source": [
    "## Import data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e2c095",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_raw_data():\n",
    "    # Load dataset\n",
    "    path = kagglehub.dataset_download(\"arashnic/faces-age-detection-dataset\")\n",
    "\n",
    "    # Define path to files\n",
    "    faces_path = os.path.join(path, \"faces\")\n",
    "    train_path = os.path.join(faces_path, \"Train\")\n",
    "\n",
    "    # Create directory for raw data\n",
    "    export_path = \"../data/raw/faces\"\n",
    "    os.makedirs(export_path, exist_ok=True)\n",
    "\n",
    "    # Copy files to raw data directory\n",
    "    shutil.copytree(train_path, os.path.join(export_path, \"images\"), dirs_exist_ok=True)\n",
    "    shutil.copy(os.path.join(faces_path, \"train.csv\"), os.path.join(export_path, \"train.csv\"))\n",
    "\n",
    "    export_path = \"../data/raw\"\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/raw/faces\"):\n",
    "    import_raw_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdb901a",
   "metadata": {},
   "source": [
    "-   Faces_02 has no csv file for classification so we are gonna skip it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4adb0b5",
   "metadata": {},
   "source": [
    "## Definitons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b88f881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"../data/raw/faces/train.csv\")\n",
    "IMAGE_SIZE = 128\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420be583",
   "metadata": {},
   "source": [
    "# 4.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b4ade08",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18549f99",
   "metadata": {},
   "source": [
    "-   EDA a data preprocessing pre Vami vybrané charakteristiky z datasetu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b91e30eb",
   "metadata": {},
   "source": [
    "### EDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c57241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f7384",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502f0298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62138c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734a770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d35342",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = \"../data/raw/faces/images\"\n",
    "num_files = len([name for name in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, name))])\n",
    "print(f\"Number of images: {num_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5905a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_train[\"Class\"].value_counts())\n",
    "df_train[\"Class\"].value_counts().plot(kind=\"bar\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f144a",
   "metadata": {},
   "source": [
    "-   There are no nulls\n",
    "-   There are no duplicates\n",
    "-   Number of images is same as number of data in cvs file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e20a0",
   "metadata": {},
   "source": [
    "### Data preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1422fde",
   "metadata": {},
   "source": [
    "#### Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7001f897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_mapping = {'YOUNG': 0, 'MIDDLE': 1, 'OLD': 2}\n",
    "# df_train[\"Class\"] = df_train[\"Class\"].map(class_mapping)\n",
    "# df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8200a6b5",
   "metadata": {},
   "source": [
    "#### Process images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedaed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(images, target_size):\n",
    "    output_dir = \"../data/processed/faces\"\n",
    "\n",
    "    young_dir = os.path.join(output_dir, \"young\")\n",
    "    middle_dir = os.path.join(output_dir, \"middle\")\n",
    "    old_dir = os.path.join(output_dir, \"old\")\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(young_dir, exist_ok=True)\n",
    "    os.makedirs(middle_dir, exist_ok=True)\n",
    "    os.makedirs(old_dir, exist_ok=True)\n",
    "\n",
    "    for _, row in images.iterrows():\n",
    "        img_name = row[\"ID\"]\n",
    "        img_path = os.path.join(\"../data/raw/faces/images\", img_name)\n",
    "        img = image.load_img(img_path, target_size=target_size, color_mode=\"grayscale\")\n",
    "\n",
    "        if row[\"Class\"].upper() == \"YOUNG\":\n",
    "            img.save(os.path.join(young_dir, img_name))\n",
    "        elif row[\"Class\"].upper() == \"MIDDLE\":\n",
    "            img.save(os.path.join(middle_dir, img_name))\n",
    "        elif row[\"Class\"].upper() == \"OLD\":\n",
    "            img.save(os.path.join(old_dir, img_name))\n",
    "\n",
    "\n",
    "if not os.path.exists(\"../data/processed/faces\"):\n",
    "    resize_images(df_train, target_size=(IMAGE_SIZE, IMAGE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113a157",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"../data/processed/faces\", shuffle=True, image_size=(IMAGE_SIZE, IMAGE_SIZE), batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4433106a",
   "metadata": {},
   "source": [
    "#### Splitting Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b755921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from: IAU_01_CNN-tf-keras_Lung-cancer.ipynb\n",
    "def splitDataset(data, train_split=0.7, val_split=0.2, test_split=0.1):\n",
    "    data_size = len(data)\n",
    "\n",
    "    train_size = int(train_split * data_size)\n",
    "    val_size = int(val_split * data_size)\n",
    "\n",
    "    train_ds = ds.take(train_size)\n",
    "    val_ds = ds.skip(train_size).take(val_size)\n",
    "    test_ds = ds.skip(train_size).skip(val_size)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "\n",
    "train_ds, val_ds, test_ds = splitDataset(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c8fcc6",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbae96a",
   "metadata": {},
   "source": [
    "-   Zdôvodnite výber ML/DL metód vzhľadom na Vami vybraný dataset pre 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ff8c5d",
   "metadata": {},
   "source": [
    "# 4.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47c9b05",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbf6444",
   "metadata": {},
   "source": [
    "-   Modeluje Vami tie vybrané charakteristiky pomocou vhodných ML/DL\n",
    "    metód. Výsledok modelovania je najlepší model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2983ebc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch, labels \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_ds\u001b[49m\u001b[38;5;241m.\u001b[39mtake(\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m      3\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m      6\u001b[0m     [\n\u001b[0;32m      7\u001b[0m         tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mInputLayer(shape\u001b[38;5;241m=\u001b[39minput_shape[\u001b[38;5;241m1\u001b[39m:]),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     ]\n\u001b[0;32m     19\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_ds' is not defined"
     ]
    }
   ],
   "source": [
    "input_shape = None\n",
    "for batch, labels in train_ds.take(1):\n",
    "    input_shape = batch.shape\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.InputLayer(shape=input_shape[1:]),\n",
    "        tf.keras.layers.Rescaling(1.0 / 255),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(3, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\", loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ef08f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e86340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds, epochs=6, validation_data=val_ds, batch_size=BATCH_SIZE, validation_batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a879c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(val_ds, batch_size=BATCH_SIZE)\n",
    "print(f\"Loss: {round(loss, 3)}, Acc: {round(acc*100, 3)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(range(6), history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "plt.plot(range(6), history.history[\"loss\"], label=\"Loss\")\n",
    "plt.title(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fac1a1",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c11d8a1",
   "metadata": {},
   "source": [
    "-   Zhodnotíte Váš prístup a získaný výsledok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c178ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built with CUDA: False\n",
      "\n",
      "Physical Devices:\n",
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')]\n",
      "\n",
      "GPU Devices:\n",
      "[]\n",
      "\n",
      "Matrix multiplication result: tf.Tensor(\n",
      "[[22. 28.]\n",
      " [49. 64.]], shape=(2, 2), dtype=float32)\n",
      "Device tensor is on: /job:localhost/replica:0/task:0/device:CPU:0\n",
      "\n",
      "TensorFlow version: 2.18.0\n",
      "Default GPU Device: \n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Method 1: Check if CUDA is available\n",
    "print(\"Built with CUDA:\", tf.test.is_built_with_cuda())\n",
    "\n",
    "# Method 2: List physical devices\n",
    "print(\"\\nPhysical Devices:\")\n",
    "print(tf.config.list_physical_devices())\n",
    "print(\"\\nGPU Devices:\")\n",
    "print(tf.config.list_physical_devices(\"GPU\"))\n",
    "\n",
    "# Method 3: Run operation to check device placement\n",
    "with tf.device(\"/GPU:0\"):\n",
    "    a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "    b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "    c = tf.matmul(a, b)\n",
    "    print(\"\\nMatrix multiplication result:\", c)\n",
    "    print(\"Device tensor is on:\", c.device)\n",
    "\n",
    "# Method 4: Get current device\n",
    "print(\"\\nTensorFlow version:\", tf.__version__)\n",
    "print(\"Default GPU Device: {}\".format(tf.test.gpu_device_name()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
