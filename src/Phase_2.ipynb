{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import anderson, skew, zscore\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    StandardScaler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = \"../dataset\"\n",
    "files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "dataset: dict[str, pd.DataFrame] = {}\n",
    "for file in files:\n",
    "    dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")\n",
    "    dataset[file] = dataset[file].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(dataset[\"connections\"], dataset[\"processes\"], on=[\"imei\", \"ts\", \"mwra\"], how=\"inner\")\n",
    "df[\"ts\"] = pd.to_datetime(df.ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n",
    "\n",
    "### **Zadanie:** Dáta si rozdeľte na trénovaciu a testovaciu množinu podľa vami preddefinovaného pomeru. Ďalej pracujte len s trénovacím datasetom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n",
    "\n",
    "### **Zadanie:** Transformujte dáta na vhodný formát pre ML t.j. jedno pozorovanie musí byť opísané jedným riadkom a každý atribút musí byť v numerickom formáte (encoding). Iteratívne integrujte aj kroky v predspracovaní dát z prvej fázy (missing values, outlier detection) ako celok.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_ts = train_data.duplicated(subset=\"ts\").any()\n",
    "print(f\"Are there any duplicate timestamps? {duplicate_ts}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   There are no duplicates in datetime, therefore every observation is in one row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   All columns are in numerical format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_counts = train_data.isnull().sum()\n",
    "null_counts = null_counts[null_counts > 0]\n",
    "null_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   There are no missing values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph showing the boxplot and outliers of the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(20, 20), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_distribution = True\n",
    "\n",
    "for col in train_data.columns[2:]:\n",
    "    result = anderson(train_data[col], dist=\"norm\")\n",
    "\n",
    "    if not result.fit_result.success:\n",
    "        norm_distribution = False\n",
    "        print(f\"{col} is not normally distributed\")\n",
    "\n",
    "if norm_distribution:\n",
    "    print(\"All columns are normally distributed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use Z-score (3), to detect outliers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_rows_before = train_data.shape[0]\n",
    "print(f\"Number of rows before removing outliers: {number_of_rows_before}\")\n",
    "\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "\n",
    "number_of_rows_after = train_data.shape[0]\n",
    "print(f\"Number of rows after removing outliers: {number_of_rows_after}\")\n",
    "print(f\"Number of rows removed: {number_of_rows_before - number_of_rows_after}\")\n",
    "print(\n",
    "    f\"Percentage of rows removed: {(number_of_rows_before - number_of_rows_after) / number_of_rows_before * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Removing 4% of the is ok, therefore we are not going to use methods to replace outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(20, 20), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n",
    "\n",
    "### **Zadanie:** Transformujte atribúty dát pre strojové učenie podľa dostupných techník minimálne: scaling (2 techniky), transformers (2 techniky) a ďalšie. Cieľom je aby ste testovali efekty a vhodne kombinovali v dátovom pipeline (od časti 2.3 a v 3. fáze).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skewness_type(skew_value: float) -> str:\n",
    "    if skew_value <= -1:\n",
    "        return \"Highly Negative Skew\"\n",
    "\n",
    "    elif skew_value <= -0.5:\n",
    "        return \"Moderately Negative Skew\"\n",
    "\n",
    "    elif skew_value <= 0.5:\n",
    "        return \"Approximately Symmetric\"\n",
    "\n",
    "    elif skew_value <= 1:\n",
    "        return \"Moderately Positive Skew\"\n",
    "\n",
    "    return \"Highly Positive Skew\"\n",
    "\n",
    "\n",
    "def kurtosis_type(kurtosis_value: float) -> str:\n",
    "    if kurtosis_value < -1:\n",
    "        return \"Negative Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < -0.5:\n",
    "        return \"Moderately Negative Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < 0.5:\n",
    "        return \"Approximately Normal Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < 1:\n",
    "        return \"Moderately Positive Kurtosis\"\n",
    "\n",
    "    return \"Positive Kurtosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_data.columns[3:].tolist()\n",
    "skew_values = [skew(train_data[col]) for col in columns]\n",
    "kurtosis_values = [train_data[col].kurtosis() for col in columns]\n",
    "\n",
    "data = {\n",
    "    \"columns\": columns,\n",
    "    \"skew\": skew_values,\n",
    "    \"kurtosis\": kurtosis_values,\n",
    "}\n",
    "\n",
    "shape_train_data = pd.DataFrame(data)\n",
    "\n",
    "shape_train_data[\"result skew\"] = shape_train_data[\"skew\"].apply(skewness_type)\n",
    "shape_train_data[\"result kurtosis\"] = shape_train_data[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.iloc[:, 3:].plot(kind=\"hist\", bins=50, figsize=(20, 20), subplots=True, layout=(10, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "scaled_data_minmax = scaler.fit_transform(train_data.iloc[:, 3:])\n",
    "\n",
    "scaled_data_minmax = pd.DataFrame(scaled_data_minmax, columns=train_data.columns[3:])\n",
    "scaled_data_minmax.plot(kind=\"hist\", bins=50, figsize=(20, 20), subplots=True, layout=(10, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = scaled_data_minmax.columns.tolist()\n",
    "skew_values = [skew(scaled_data_minmax[col]) for col in columns]\n",
    "kurtosis_values = [scaled_data_minmax[col].kurtosis() for col in columns]\n",
    "\n",
    "data = {\n",
    "    \"columns\": columns,\n",
    "    \"skew\": skew_values,\n",
    "    \"kurtosis\": kurtosis_values,\n",
    "}\n",
    "\n",
    "shape_train_data = pd.DataFrame(data)\n",
    "\n",
    "shape_train_data[\"result skew\"] = shape_train_data[\"skew\"].apply(skewness_type)\n",
    "shape_train_data[\"result kurtosis\"] = shape_train_data[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_data_standard = scaler.fit_transform(train_data.iloc[:, 3:])\n",
    "\n",
    "\n",
    "scaled_data_standard = pd.DataFrame(scaled_data_standard, columns=train_data.columns[3:])\n",
    "scaled_data_standard.plot(kind=\"hist\", bins=50, figsize=(20, 20), subplots=True, layout=(10, 3), xlim=(-5, 5))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "power_transformer = PowerTransformer(method=\"yeo-johnson\")\n",
    "transformed_data_power = power_transformer.fit_transform(train_data.iloc[:, 3:])\n",
    "\n",
    "transformed_data_power = pd.DataFrame(transformed_data_power, columns=train_data.columns[3:])\n",
    "transformed_data_power.plot(kind=\"hist\", bins=50, figsize=(20, 20), subplots=True, layout=(10, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = transformed_data_power.columns.tolist()\n",
    "skew_values = [skew(transformed_data_power[col]) for col in columns]\n",
    "kurtosis_values = [transformed_data_power[col].kurtosis() for col in columns]\n",
    "\n",
    "data = {\n",
    "    \"columns\": columns,\n",
    "    \"skew\": skew_values,\n",
    "    \"kurtosis\": kurtosis_values,\n",
    "}\n",
    "\n",
    "shape_train_data = pd.DataFrame(data)\n",
    "\n",
    "shape_train_data[\"result skew\"] = shape_train_data[\"skew\"].apply(skewness_type)\n",
    "shape_train_data[\"result kurtosis\"] = shape_train_data[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantile_transformer = QuantileTransformer(output_distribution=\"normal\", random_state=42)\n",
    "transformed_data = quantile_transformer.fit_transform(train_data.iloc[:, 3:])\n",
    "\n",
    "transformed_data = pd.DataFrame(transformed_data, columns=train_data.columns[3:])\n",
    "transformed_data.plot(kind=\"hist\", bins=50, figsize=(20, 20), subplots=True, layout=(10, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = transformed_data.columns.tolist()\n",
    "skew_values = [skew(transformed_data[col]) for col in columns]\n",
    "kurtosis_values = [transformed_data[col].kurtosis() for col in columns]\n",
    "\n",
    "data = {\n",
    "    \"columns\": columns,\n",
    "    \"skew\": skew_values,\n",
    "    \"kurtosis\": kurtosis_values,\n",
    "}\n",
    "\n",
    "shape_train_data = pd.DataFrame(data)\n",
    "\n",
    "shape_train_data[\"result skew\"] = shape_train_data[\"skew\"].apply(skewness_type)\n",
    "shape_train_data[\"result kurtosis\"] = shape_train_data[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transformed_data = np.log1p(scaled_data_minmax)\n",
    "\n",
    "log_transformed_data.plot(kind=\"hist\", bins=50, figsize=(20, 20), subplots=True, layout=(10, 3))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n",
    "\n",
    "### **Zadanie:** Zdôvodnite Vaše voľby/rozhodnutie pre realizáciu (t.j. zdokumentovanie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n",
    "\n",
    "### **Zadanie:** Zistite, ktoré atribúty (features) vo vašich dátach pre ML sú informatívne k predikovanej premennej (minimálne 3 techniky s porovnaním medzi sebou).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n",
    "\n",
    "### **Zadanie:** Zoraďte zistené atribúty v poradí podľa dôležitosti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n",
    "\n",
    "### **Zadanie:** Zdôvodnite Vaše voľby/rozhodnutie pre realizáciu (t.j. zdokumentovanie)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n",
    "\n",
    "### **Zadanie:** Upravte váš kód realizujúci predspracovanie trénovacej množiny tak, aby ho bolo možné bez ďalších úprav znovu použiť na predspracovanie testovacej množiny v kontexte strojového učenia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n",
    "\n",
    "### **Zadanie:** Využite možnosti sklearn.pipeline\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
