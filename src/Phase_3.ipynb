{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from graphviz import Source\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython.display import HTML, SVG\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    ParameterGrid,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = \"../data/raw\"\n",
    "files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "dataset: dict[str, pd.DataFrame] = {}\n",
    "for file in files:\n",
    "    dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")\n",
    "    dataset[file] = dataset[file].drop_duplicates()\n",
    "\n",
    "df = pd.merge(dataset[\"connections\"], dataset[\"processes\"], on=[\"imei\", \"ts\", \"mwra\"])\n",
    "df[\"ts\"] = pd.to_datetime(df.ts)\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 iteration of cleaning whole dataset of outliers (including p.android.vending)\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "\n",
    "# Using all columns except c.android.vending for outlier detection\n",
    "columns_for_zscore = train_data.iloc[:, 3:].columns.difference([\"p.android.vending\"])\n",
    "outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "max_iterations = 10\n",
    "iteration = 0\n",
    "\n",
    "# Iterating after we removed all outliers\n",
    "while outliers_count > 0:\n",
    "    train_data = train_data[(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)]\n",
    "    outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "    iteration += 1\n",
    "    if iteration >= max_iterations:\n",
    "        break\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting cleaned data\n",
    "os.makedirs(\"../data/clean\", exist_ok=True)\n",
    "\n",
    "train_data.to_csv(\"../data/clean/train_data.csv\", index=False)\n",
    "test_data.to_csv(\"../data/clean/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/clean/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../data/clean/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = train_data.drop(columns=[\"mwra\", \"ts\", \"imei\"]).columns\n",
    "non_gaussian_columns = [\n",
    "    \"c.android.vending\",\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "    \"p.android.vending\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.olauncher\",\n",
    "    \"p.simulator\",\n",
    "    \"p.inputmethod.latin\",\n",
    "    \"p.android.gms\",\n",
    "    \"p.notifier\",\n",
    "    \"p.katana\",\n",
    "    \"p.gms.persistent\",\n",
    "]\n",
    "gaussian_columns = all_columns[~all_columns.isin(non_gaussian_columns)]\n",
    "transformed_feature_order = pd.Series(gaussian_columns.tolist() + non_gaussian_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vending_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"quantile_transformer\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"general\", general_pipe, gaussian_columns),\n",
    "        (\"vending\", vending_pipeline, non_gaussian_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Create complete pipeline\n",
    "complete_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/processed/train_data.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/processed/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    file_path,\n",
    "    files,\n",
    "    file,\n",
    "    df,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    columns_for_zscore,\n",
    "    outliers_count,\n",
    "    max_iterations,\n",
    "    iteration,\n",
    "    all_columns,\n",
    "    non_gaussian_columns,\n",
    "    gaussian_columns,\n",
    "    transformed_feature_order,\n",
    "    general_pipe,\n",
    "    vending_pipeline,\n",
    "    preprocessor,\n",
    "    complete_pipeline,\n",
    "    train_data_processed,\n",
    "    test_data_processed,\n",
    "    dataset,\n",
    "    selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed = pd.read_csv(\"../data/processed/train_data.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/processed/test_data.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]\n",
    "\n",
    "del train_data_processed, test_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        index=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"roc_auc\"],\n",
    "        columns=pd.MultiIndex.from_product([[model_name], [\"Train\", \"Test\", \"Difference\"]]),\n",
    "    )\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Train\")] = accuracy_train\n",
    "    df.loc[\"precision\", (model_name, \"Train\")] = precision_train\n",
    "    df.loc[\"recall\", (model_name, \"Train\")] = recall_train\n",
    "    df.loc[\"f1-score\", (model_name, \"Train\")] = f1_train\n",
    "    df.loc[\"roc_auc\", (model_name, \"Train\")] = roc_auc_train\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Test\")] = accuracy_test\n",
    "    df.loc[\"precision\", (model_name, \"Test\")] = precision_test\n",
    "    df.loc[\"recall\", (model_name, \"Test\")] = recall_test\n",
    "    df.loc[\"f1-score\", (model_name, \"Test\")] = f1_test\n",
    "    df.loc[\"roc_auc\", (model_name, \"Test\")] = roc_auc_test\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Difference\")] = accuracy_train - accuracy_test\n",
    "    df.loc[\"precision\", (model_name, \"Difference\")] = precision_train - precision_test\n",
    "    df.loc[\"recall\", (model_name, \"Difference\")] = recall_train - recall_test\n",
    "    df.loc[\"f1-score\", (model_name, \"Difference\")] = f1_train - f1_test\n",
    "    df.loc[\"roc_auc\", (model_name, \"Difference\")] = roc_auc_train - roc_auc_test\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_cv(model, model_name, X, y, cv):\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "    # Create MultiIndex DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        index=pd.MultiIndex.from_product([[\"Train\", \"Test\", \"Difference\"], metrics]),\n",
    "        columns=pd.MultiIndex.from_product([[model_name], [\"Mean\", \"Std\"]]),\n",
    "    )\n",
    "\n",
    "    # Calculate scores for each model\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            \"accuracy\": \"accuracy\",\n",
    "            \"precision\": \"precision\",\n",
    "            \"recall\": \"recall\",\n",
    "            \"f1\": \"f1\",\n",
    "            \"roc_auc\": \"roc_auc\",\n",
    "        },\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    # Fill DataFrame with training and test scores\n",
    "    for metric in metrics:\n",
    "        # Training scores\n",
    "        train_key = f\"train_{metric}\"\n",
    "        df.loc[(\"Train\", metric), (model_name, \"Mean\")] = scores[train_key].mean()\n",
    "        df.loc[(\"Train\", metric), (model_name, \"Std\")] = scores[train_key].std()\n",
    "\n",
    "        # Test scores\n",
    "        test_key = f\"test_{metric}\"\n",
    "        df.loc[(\"Test\", metric), (model_name, \"Mean\")] = scores[test_key].mean()\n",
    "        df.loc[(\"Test\", metric), (model_name, \"Std\")] = scores[test_key].std()\n",
    "\n",
    "        # Difference between training and test scores\n",
    "        diff = scores[train_key] - scores[test_key]\n",
    "        df.loc[(\"Difference\", metric), (model_name, \"Mean\")] = diff.mean()\n",
    "        df.loc[(\"Difference\", metric), (model_name, \"Std\")] = diff.std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, train_sizes, cv, scoring, title):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "    train_scores_mean = 1 - train_scores.mean(axis=1)\n",
    "    test_scores_mean = 1 - test_scores.mean(axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_scores_mean, label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, label=\"Cross-Validation Score\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(f\"{scoring} Error\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_complexity_curve(model, X_train, y_train, X_test, y_test, max_depth_range):\n",
    "    # Initialize lists to store the training and validation errors\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "\n",
    "    # Loop over the range of max_depth values\n",
    "    for max_depth in max_depth_range:\n",
    "        # Initialize the model with the current max_depth\n",
    "        model = DecisionTreeClassifier(\n",
    "            criterion=\"gini\",\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=1,\n",
    "            ccp_alpha=0.001,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Compute the training and testing data errors\n",
    "        train_score = accuracy_score(y_train, model.predict(X_train))\n",
    "        test_score = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Compute the mean errors\n",
    "        train_errors.append(1 - train_score)\n",
    "        val_errors.append(1 - test_score)\n",
    "\n",
    "    # Plot the learning curve for model complexity\n",
    "    plt.figure()\n",
    "    plt.plot(max_depth_range, train_errors, label=\"Training Error\")\n",
    "    plt.plot(max_depth_range, val_errors, label=\"Validation Error\")\n",
    "    plt.xlabel(\"Max Depth\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Learning Curve (Model Complexity)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_confusion_matrix(models, X_train, y_train, X_test, y_test):\n",
    "    _, axes = plt.subplots(1, len(models), figsize=(15, 5))\n",
    "\n",
    "    for i, (model_name, model) in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=axes[i])\n",
    "        axes[i].set_title(model_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"ccp_alpha\": 0.001,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "lgr_best_params = {\"C\": 0.01, \"max_iter\": 100, \"penalty\": \"l2\", \"solver\": \"lbfgs\", \"tol\": 0.001}\n",
    "\n",
    "gbg_best_params = {\n",
    "    \"subsample\": 0.8,\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "hbg_best_params = {\n",
    "    \"l2_regularization\": 2.0,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 7,\n",
    "    \"max_iter\": 200,\n",
    "    \"min_samples_leaf\": 20,\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "def ignore(line, cell):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Jednoduchý klasifikátor na základe závislosti v dátach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naimplementujte jednoduchý ID3 klasifikátor s hĺbkou min 2 (vrátane root/koreň).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, left=None, right=None, value=None, info_gain=None):\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.value = value\n",
    "        self.info_gain = info_gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ID3Classifier:\n",
    "    def __init__(self, max_depth: int = 2):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def build_tree(self, X, y, curr_depth: int = 0):\n",
    "        _, num_features = X.shape\n",
    "\n",
    "        if curr_depth <= self.max_depth:\n",
    "            best_split = self.get_best_split(X, y, num_features)\n",
    "            if best_split[\"info_gain\"] > 0:\n",
    "                left_subtree = self.build_tree(best_split[\"X_left\"], best_split[\"y_left\"], curr_depth + 1)\n",
    "                right_subtree = self.build_tree(best_split[\"X_right\"], best_split[\"y_right\"], curr_depth + 1)\n",
    "\n",
    "                return Node(\n",
    "                    feature=best_split[\"feature\"],\n",
    "                    threshold=best_split[\"threshold\"],\n",
    "                    left=left_subtree,\n",
    "                    right=right_subtree,\n",
    "                )\n",
    "\n",
    "        leaf_value = self.calculate_leaf_value(y)\n",
    "        return Node(value=leaf_value)\n",
    "\n",
    "    def get_best_split(self, X, y, num_features):\n",
    "        best_split = {}\n",
    "        max_info_gain = -float(\"inf\")\n",
    "\n",
    "        for feature in range(num_features):\n",
    "            feature_values = X[:, feature]\n",
    "            possible_thresholds = np.unique(feature_values)\n",
    "\n",
    "            for threshold in possible_thresholds:\n",
    "                X_left, X_right, y_left, y_right = self.split(X, y, feature, threshold)\n",
    "                curr_info_gain = self.information_gain(y, y_left, y_right)\n",
    "\n",
    "                if curr_info_gain > max_info_gain:\n",
    "                    best_split[\"feature\"] = feature\n",
    "                    best_split[\"threshold\"] = threshold\n",
    "                    best_split[\"X_left\"] = X_left\n",
    "                    best_split[\"X_right\"] = X_right\n",
    "                    best_split[\"y_left\"] = y_left\n",
    "                    best_split[\"y_right\"] = y_right\n",
    "                    best_split[\"info_gain\"] = curr_info_gain\n",
    "                    max_info_gain = curr_info_gain\n",
    "\n",
    "        return best_split\n",
    "\n",
    "    @staticmethod\n",
    "    def split(X, y, feature, threshold):\n",
    "        left_indices = np.where(X[:, feature] <= threshold)\n",
    "        right_indices = np.where(X[:, feature] > threshold)\n",
    "\n",
    "        X_left = X[left_indices]\n",
    "        X_right = X[right_indices]\n",
    "        y_left = y[left_indices]\n",
    "        y_right = y[right_indices]\n",
    "\n",
    "        return X_left, X_right, y_left, y_right\n",
    "\n",
    "    def information_gain(self, parent, l_child, r_child):\n",
    "        weight_l = len(l_child) / len(parent)\n",
    "        weight_r = len(r_child) / len(parent)\n",
    "\n",
    "        gain = self.entropy(parent) - (weight_l * self.entropy(l_child) + weight_r * self.entropy(r_child))\n",
    "        return gain\n",
    "\n",
    "    @staticmethod\n",
    "    def entropy(y):\n",
    "        class_labels = np.unique(y)\n",
    "        ent = 0\n",
    "\n",
    "        for cls in class_labels:\n",
    "            p = np.sum(y == cls) / len(y)\n",
    "            ent += p * np.log2(p)\n",
    "\n",
    "        return -ent\n",
    "\n",
    "    @staticmethod\n",
    "    def calculate_leaf_value(y):\n",
    "\n",
    "        Y = list(y)\n",
    "        return max(y, key=Y.count)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.tree = self.build_tree(X, y)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self.traverse_tree(x, self.tree) for x in X]\n",
    "\n",
    "    def traverse_tree(self, x, node):\n",
    "        if node.value is not None:\n",
    "            return node.value\n",
    "\n",
    "        if x[node.feature] <= node.threshold:\n",
    "            return self.traverse_tree(x, node.left)\n",
    "\n",
    "        return self.traverse_tree(x, node.right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnoťte Váš ID3 klasifikátor pomocou metrík accuracy, precision a recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_classifier = ID3Classifier(max_depth=5)\n",
    "id3_classifier.fit(X_train.values, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">ID3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.914271</td>\n",
       "      <td>0.90288</td>\n",
       "      <td>0.011391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.91727</td>\n",
       "      <td>0.903275</td>\n",
       "      <td>0.013995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.950271</td>\n",
       "      <td>0.945874</td>\n",
       "      <td>0.004397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.933479</td>\n",
       "      <td>0.924084</td>\n",
       "      <td>0.009395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.901226</td>\n",
       "      <td>0.888562</td>\n",
       "      <td>0.012664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID3                     \n",
       "              Train      Test Difference\n",
       "accuracy   0.914271   0.90288   0.011391\n",
       "precision   0.91727  0.903275   0.013995\n",
       "recall     0.950271  0.945874   0.004397\n",
       "f1-score   0.933479  0.924084   0.009395\n",
       "roc_auc    0.901226  0.888562   0.012664"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_scores_id3(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    y_pred_train = model.predict(X_train.values)\n",
    "    y_pred_test = model.predict(X_test.values)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        index=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"roc_auc\"],\n",
    "        columns=pd.MultiIndex.from_product([[model_name], [\"Train\", \"Test\", \"Difference\"]]),\n",
    "    )\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Train\")] = accuracy_train\n",
    "    df.loc[\"precision\", (model_name, \"Train\")] = precision_train\n",
    "    df.loc[\"recall\", (model_name, \"Train\")] = recall_train\n",
    "    df.loc[\"f1-score\", (model_name, \"Train\")] = f1_train\n",
    "    df.loc[\"roc_auc\", (model_name, \"Train\")] = roc_auc_train\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Test\")] = accuracy_test\n",
    "    df.loc[\"precision\", (model_name, \"Test\")] = precision_test\n",
    "    df.loc[\"recall\", (model_name, \"Test\")] = recall_test\n",
    "    df.loc[\"f1-score\", (model_name, \"Test\")] = f1_test\n",
    "    df.loc[\"roc_auc\", (model_name, \"Test\")] = roc_auc_test\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Difference\")] = accuracy_train - accuracy_test\n",
    "    df.loc[\"precision\", (model_name, \"Difference\")] = precision_train - precision_test\n",
    "    df.loc[\"recall\", (model_name, \"Difference\")] = recall_train - recall_test\n",
    "    df.loc[\"f1-score\", (model_name, \"Difference\")] = f1_train - f1_test\n",
    "    df.loc[\"roc_auc\", (model_name, \"Difference\")] = roc_auc_train - roc_auc_test\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Using ID3 Classifier\n",
    "scores_id3 = get_scores_id3(id3_classifier, \"ID3\", X_train, y_train, X_test, y_test)\n",
    "scores_id3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see that using feature selection gives worse results. We will look at it in more detail later (3.4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zístite či Váš ID3 klasifikátor má overfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Since train and test metrics are close, the model is likely not overfitting.\n",
    "-   But let's also look at learning curves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve - train sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "dtc_nofs = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", max_depth=15, min_samples_split=10, min_samples_leaf=1, ccp_alpha=0.001, random_state=42\n",
    ")\n",
    "\n",
    "# Define the training sizes\n",
    "train_sizes = np.linspace(0.1, 1.0, 50)\n",
    "\n",
    "# Plot learning curve for accuracy\n",
    "plot_learning_curve(\n",
    "    dtc_nofs,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    train_sizes,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    title=\"Learning Curve - Train size (Accuracy)\",\n",
    ")\n",
    "\n",
    "# Plot learning curve for precision\n",
    "plot_learning_curve(\n",
    "    dtc_nofs,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    train_sizes,\n",
    "    cv=5,\n",
    "    scoring=\"precision\",\n",
    "    title=\"Learning Curve - Train size (Precision)\",\n",
    ")\n",
    "\n",
    "# Plot learning curve for recall\n",
    "plot_learning_curve(\n",
    "    dtc_nofs, X_train, y_train, train_sizes, cv=5, scoring=\"recall\", title=\"Learning Curve - Train size (Recall)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We don't see a big gap in metrics between train and test data (Looking at last point since that is what we used in previous steps).\n",
    "-   However we see that model starts of badly (as expected) and then improves with more data. Around 50% of data for training seems to be enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve - model complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of max_depth values\n",
    "max_depth_range = range(1, 30)\n",
    "\n",
    "# Plot model complexity curve\n",
    "plot_model_complexity_curve(dtc_nofs, X_train, y_train, X_test, y_test, max_depth_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   This also shows no overfitting for our graph as there is no significant gap (looking at max_depth=15, as this is what we used in previous steps).\n",
    "-   We can also see that model start of very badly and is underfitting.\n",
    "-   Around max_depth=5 training and testing error stabilizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_nofs = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", max_depth=15, min_samples_split=10, min_samples_leaf=1, ccp_alpha=0.001, random_state=42\n",
    ")\n",
    "\n",
    "dtc_nofs.fit(X_train, y_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for train data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, dtc_nofs.predict_proba(X_train)[:, 1])\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for test data\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, dtc_nofs.predict_proba(X_test)[:, 1])\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color=\"blue\", lw=2, label=f\"Train ROC curve (area = {roc_auc_train:.5f})\")\n",
    "plt.plot(fpr_test, tpr_test, color=\"red\", lw=2, label=f\"Test ROC curve (area = {roc_auc_test:.5f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   ROC also shows no significant gap between train and test data. So we can conclude that model is not overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    dtc_fs,\n",
    "    dtc_nofs,\n",
    "    fpr_train,\n",
    "    tpr_train,\n",
    "    fpr_test,\n",
    "    tpr_test,\n",
    "    train_sizes,\n",
    "    max_depth_range,\n",
    "    roc_auc_test,\n",
    "    roc_auc_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trénovanie a vyhodnotenie klasifikátorov strojového učenia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na trénovanie využite jeden stromový algoritmus v scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use some basic parameters to avoid overfitting\n",
    "dst_classifier = DecisionTreeClassifier(max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "dst_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = get_scores_cv(dst_classifier, \"DecisionTreeClassifier\", X_train, y_train, cv=5)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(dst_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Even quite simple model gives good results without overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porovnajte s jedným iným nestromovým algoritmom v scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = get_scores_cv(log_reg, \"LogisticRegression\", X_train, y_train, cv=5)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(log_reg, \"LogisticRegression\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Basic logistic regression gives quite good results without overfitting as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "del df_1, df_2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_confusion_matrix(\n",
    "    [(\"RandomForestClassifier\", dst_classifier), (\"LogisticRegression\", log_reg)], X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Basic Logistic Regression gives slightly better results than basic Decision Tree Classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porovnajte výsledky s ID3 z prvého kroku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualizujte natrénované pravidlá minimálne pre jeden Vami vybraný algoritmus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RandomForestClassifier\n",
    "dst_classifier = DecisionTreeClassifier(max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dst_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Generate graph\n",
    "graph = Source(\n",
    "    export_graphviz(\n",
    "        dst_classifier, out_file=None, class_names=[\"no\", \"yes\"], filled=True, feature_names=X_train.columns\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display graph\n",
    "display(SVG(graph.pipe(format=\"svg\")))\n",
    "\n",
    "style = \"<style>svg{width:100%;height:70%;}</style>\"\n",
    "HTML(style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnoťte natrénované modely pomocou metrík accuracy, precision a recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We already did this but let's do it again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "dst_classifier = DecisionTreeClassifier(max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "log_reg = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the scores\n",
    "df_1 = get_scores_cv(dst_classifier, \"DecisionTreeClassifier\", X_train, y_train, cv=5)\n",
    "df_2 = get_scores_cv(log_reg, \"LogisticRegression\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "del df_1, df_2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare matrixes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_confusion_matrix(\n",
    "    [\n",
    "        (\"DecisionTreeClassifier\", dst_classifier),\n",
    "        (\"LogisticRegression\", log_reg),\n",
    "    ],\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   As we already said, Logistic Regression gives slightly better results than Decision Tree Classifier.\n",
    "-   However, both models are quite good and don't overfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dst_classifier, log_reg, graph, style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimalizácia alias hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšajte rôzne nastavenie hyperparametrov (tuning) pre zvolený algoritmus tak,\n",
    "aby ste optimalizovali výkonnosť (bez underfitingu).\n",
    "\n",
    "We will test parameters for RandomForestClassifier as we know this will be better than DecisionTreeClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree vs Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"ccp_alpha\": [0.0, 0.0005, 0.001, 0.0015],\n",
    "    \"min_impurity_decrease\": [0.0, 0.0005, 0.001, 0.0015],\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'ccp_alpha': 0.0005, 'max_depth': 10, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
    "-   Best Score: 0.9026635738931255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(\n",
    "    max_depth=10, min_samples_split=2, min_samples_leaf=4, ccp_alpha=0.0005, random_state=42\n",
    ")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "\n",
    "df_1 = get_scores_cv(dt_classifier, \"DecisionTreeClassifier\", X_train, y_train, cv=5)\n",
    "df_2 = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "del df_1, df_2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   This shows difference between optimized Decision Tree and some basic Random Forest (with basic paramters to avoid overfitting).\n",
    "-   We can clearly see that Random Forest is better and therefore we are gonna use it for further steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, find baseline parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_depth=20, ccp_alpha=0.001\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_depth=20, ccp_alpha=0.001\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see that performance is not increasing with n_estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ccp_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(criterion=\"entropy\", n_estimators=100, random_state=42, ccp_alpha=0.002)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(criterion=\"entropy\", n_estimators=100, random_state=42, ccp_alpha=0.005)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see ccp_alpha 0.002 is better considering ROC AUC factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=7,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    "    max_features=\"log2\",\n",
    "    max_depth=7,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   When also using max_depth, there is difference in ROC AUC, sqrt is better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"gini\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Entropy is better considering ROC AUC factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   In previous step, we found that n_estimators=100, ccp_alpha=0.002, max_features=sqrt, criterion=entropy are better.\n",
    "-   However we are not gonna look at max_features and criterion in first tuning method as we will look at them at the end when we have best primary hyperparameters.\n",
    "-   Not using max_features and criterion in first tuning gives more priority to other hyperparameters.\n",
    "-   Our primary hyperparameters are n_estimators, max_depth, min_samples_split, min_samples_leaf, ccp_alpha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the broad parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"ccp_alpha\": [0.001, 0.002, 0.003],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 15, 'ccp_alpha': 0.002}\n",
    "-   Best Score: 0.91579\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Best parameters from RandomizedSearchCV\n",
    "best_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 15,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"ccp_alpha\": 0.002,\n",
    "}\n",
    "\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [\n",
    "        best_params[\"n_estimators\"] - 100,\n",
    "        best_params[\"n_estimators\"],\n",
    "        best_params[\"n_estimators\"] + 100,\n",
    "    ],\n",
    "    \"max_depth\": [\n",
    "        best_params[\"max_depth\"] - 5,\n",
    "        best_params[\"max_depth\"],\n",
    "        best_params[\"max_depth\"] + 5,\n",
    "    ],\n",
    "    \"min_samples_split\": [\n",
    "        best_params[\"min_samples_split\"] - 5,\n",
    "        best_params[\"min_samples_split\"],\n",
    "        best_params[\"min_samples_split\"] + 5,\n",
    "    ],\n",
    "    \"min_samples_leaf\": [\n",
    "        best_params[\"min_samples_leaf\"],\n",
    "        best_params[\"min_samples_leaf\"] + 1,\n",
    "    ],\n",
    "    \"ccp_alpha\": [\n",
    "        best_params[\"ccp_alpha\"],\n",
    "        best_params[\"ccp_alpha\"] + 0.001,\n",
    "        best_params[\"ccp_alpha\"] + 0.002,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.002, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 15, 'n_estimators': 400}\n",
    "-   Best Score after Refining: 0.91606\n",
    "-   The trend for n_estimators is, bigger is better (until some point). So in next iteration we will ignore this parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My colleague found different parameters to be better, so we will look at them in this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [\n",
    "        200\n",
    "    ],\n",
    "    \"max_depth\": [\n",
    "        15\n",
    "    ],\n",
    "    \"min_samples_split\": [\n",
    "        5,10\n",
    "    ],\n",
    "    \"min_samples_leaf\": [\n",
    "        1,2\n",
    "    ],\n",
    "    \"ccp_alpha\": [\n",
    "        0.001, 0.002\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.001, 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "-   Best Score after Refining: 0.91596\n",
    "-   From these observations:\n",
    "    -   We can conclude that max_depth=~15 is the best, as it was 15 in every iteration.\n",
    "    -   We can conclude that ccp_alpha=~0.001 or cpp_alpha=~0.002 is the best.\n",
    "    -   We can conclude that min_samples_leaf=~1 or a little higher is the best.\n",
    "    -   We can conclude that min_samples_split=~10 is the best.\n",
    "    -   We can conclude that higher n_estimators is better (at some value it will be worse).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at cpp_alpha and max_depth in more detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [14, 15, 16],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"ccp_alpha\": [0.0095, 0.01, 0.0105],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   cpp_alpha=0.001 is best\n",
    "-   max_depth=15 is best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at best n_estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"max_depth\": [15],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"ccp_alpha\": [0.001],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   n_estimators=300 is best.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, we will also look at max_features and criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [15],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"ccp_alpha\": [0.001],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.001, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
    "-   Best Score after Refining: 0.91632\n",
    "-   We can see that max_features=sqrt and criterion=gini are best and they are also default values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final parameters are:\n",
    "\n",
    "-   n_estimators=300\n",
    "-   max_depth=15\n",
    "-   min_samples_split=10\n",
    "-   min_samples_leaf=1\n",
    "-   ccp_alpha=0.001\n",
    "-   max_features=\"sqrt\"\n",
    "-   criterion=\"gini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note we did these test without having feature selection in pipeline as we were getting better result without it. (Will be discussed further in 3.4)\n",
    "\n",
    "Since we discovered that it is best practise to always use feature selection, we will use it it next step and look if parameters change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [10, 15],\n",
    "    \"min_samples_split\": [5, 10],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"ccp_alpha\": [0.001, 0.0015],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.001, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
    "-   Best Score after Refining: 0.91591\n",
    "-   Best score without feature selection was 0.91632 vs 0.91591 with feature selection.\n",
    "-   As hinted before, using feature selection gives slightly worse results. But we will look at it in more detail in 3.4.\n",
    "-   We can also see that parameters did change and therefore it is always crucial to try different parameters when changing pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final parameters with feature selection are:\n",
    "\n",
    "-   n_estimators=300\n",
    "-   max_depth=10\n",
    "-   min_samples_split=5\n",
    "-   min_samples_leaf=1\n",
    "-   ccp_alpha=0.001\n",
    "-   max_features=\"sqrt\"\n",
    "-   criterion=\"gini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Let's also look at Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "\n",
    "parameters = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05],\n",
    "    \"max_iter\": [100, 150, 200, 250, 300],\n",
    "    \"tol\": [0.0001, 0.0005, 0.001, 0.005],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    log_reg,\n",
    "    param_grid=parameters,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0005}\n",
    "-   Best Score: 0.91217\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "\n",
    "parameters = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05],\n",
    "    \"max_iter\": [100, 150, 200, 250, 300],\n",
    "    \"tol\": [0.0001, 0.0005, 0.001, 0.005],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    log_reg,\n",
    "    param_grid=parameters,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
    "-   Best Score: 0.91243\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C=0.01, max_iter=100, penalty=\"l2\", solver=\"lbfgs\", tol=0.001, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "df_1 = get_scores(log_reg, \"LogisticRegression - lbfgs\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "log_reg = LogisticRegression(C=0.01, max_iter=100, penalty=\"l1\", solver=\"liblinear\", tol=0.001, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "df_2 = get_scores(log_reg, \"LogisticRegression - liblinear\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', solver=\"lbfgs\",'tol': 0.001}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšajte kombinácie modelov (ensemble) pre zvolený algoritmus tak, aby ste\n",
    "optimalizovali výkonnosť (bez underfitingu).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already used RandomForestClassifier in previous step, but we will now explore more ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Ensemble Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    **rf_best_params,\n",
    ")\n",
    "\n",
    "# Print the scores\n",
    "df_rf = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "df_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Print the scores\n",
    "df_gb = get_scores_cv(gb_classifier, \"GradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_classifier = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Print the scores\n",
    "df_hgb = get_scores_cv(hgb_classifier, \"HistGradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "df_hgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rf, df_gb, df_hgb], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can see that RandomForestClassifier is the best model for our data as we used hyperparameter tuning on it.\n",
    "-   HistGradientBoostingClassifier shows promising results but overfits more than RandomForestClassifier or GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gb_classifier,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"roc_auc\", # ROC_AUC for lowering overfitting\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 4, 'learning_rate': 0.01}\n",
    "-   Best Score: 0.91491\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier(**gbg_best_params)\n",
    "\n",
    "df_gb = get_scores_cv(gb_classifier, \"GradientBoostingClassifier\", X_train, y_train, X_test, y_test)\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_iter\": [100, 200],\n",
    "    \"min_samples_leaf\": [20, 50],\n",
    "    \"l2_regularization\": [0, 1.0, 2.0],\n",
    "}\n",
    "\n",
    "# Base classifier\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Grid search with 5-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=hgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\", # ROC_AUC for lowering overfitting\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Assuming X and y are your features and target\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Create optimized model with best parameters\n",
    "best_model = HistGradientBoostingClassifier(**grid_search.best_params_, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best parameters: {'l2_regularization': 0, 'learning_rate': 0.01, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 20}\n",
    "-   Best cross-validation score: 0.9132202050166413\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingClassifier(\n",
    "    l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=20, random_state=42\n",
    ")\n",
    "\n",
    "df_hgb = get_scores_cv(hgb, \"HistGradientBoostingClassifier - Refined\", X_train, y_train, cv=5)\n",
    "df_hgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rf, df_gb, df_hgb], axis=1)\n",
    "del df_rf, df_gb, df_hgb\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can see that RandomForestClassifier is still the best model.\n",
    "-   Using roc_auc for scoring in GridSearchCV we lover the overfitting of HistGradientBoostingClassifier but it is still worse than RandomForestClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "gb_classifier = GradientBoostingClassifier(**gbg_best_params)\n",
    "hbg_classifier = HistGradientBoostingClassifier(**hbg_best_params)\n",
    "\n",
    "df_rf = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "df_gb = get_scores_cv(gb_classifier, \"GradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "df_hgb = get_scores_cv(hbg_classifier, \"HistGradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_rf, df_gb, df_hgb], axis=1)\n",
    "del df_rf, df_gb, df_hgb\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First best accuracy has RandomForestClassifier then HistGradientBoostingClassifier and last GradientBoostingClassifier.\n",
    "-   Then best F1 score has RandomForestClassifier then HistGradientBoostingClassifier and last GradientBoostingClassifier.\n",
    "-   For Roc_Auc score, RandomForestClassifier is the best model, then GradientBoostingClassifier and last HistGradientBoostingClassifier.\n",
    "-   For overfitting, no model is overfitting greatly, but HistGradientBoostingClassifier still has biggest overfit out of three models.\n",
    "-   Because of this we are going to use GradientBoostingClassifier over HistGradientBoostingClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting & Stacikng Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models with different algorithms\n",
    "rf = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "lgr = LogisticRegression(**lgr_best_params)\n",
    "\n",
    "gbg = GradientBoostingClassifier(**gbg_best_params)\n",
    "\n",
    "# Create voting ensemble with different algorithms\n",
    "voting_clf = VotingClassifier(estimators=[(\"rf\", rf), (\"lgr\", lgr), (\"gbg\", gbg)], n_jobs=-1, voting=\"soft\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"lgr\", lgr), (\"gbg\", gbg)],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Random Forest\": rf,\n",
    "    \"Logistic Regression\": lgr,\n",
    "    \"Gradient Boosting\": gbg,\n",
    "    \"Voting Ensemble\": voting_clf,\n",
    "    \"Stacking Ensemble\": stacking_clf,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    df_tmp = get_scores_cv(model, name, X_train, y_train, cv=5)\n",
    "    df = pd.concat([df, df_tmp], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Voting Classifier and Stacking Classifier performs similarly, but Stacking Classifier takes longer to run. Therefore we are going to compare only Voting Classifier with other models.\n",
    "-   Since Random Forest Classifier was best model until this point, it will be our primary model to compare against.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "df_voting = get_scores_cv(voting_clf, \"VotingClassifier\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_rf, df_voting], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rf, df_voting], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Random Forest Classifier is still the best model across all metrics.\n",
    "-   The only thing VotingClassifier excels at is lower overfitting, but it is very small difference, therefore negligible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at second VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models with different algorithms\n",
    "rf = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "lgr = LogisticRegression(**lgr_best_params)\n",
    "\n",
    "gbg = GradientBoostingClassifier(**gbg_best_params)\n",
    "\n",
    "# Create voting ensemble with different algorithms\n",
    "voting_clf = VotingClassifier(estimators=[(\"rf\", rf), (\"lgr\", lgr), (\"gbg\", gbg)], n_jobs=-1, voting=\"soft\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "voting_clf_2 = VotingClassifier(estimators=[(\"rf\", rf), (\"gbg\", gbg)], n_jobs=-1, voting=\"soft\")\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Random Forest\": rf,\n",
    "    \"Voting Ensemble\": voting_clf,\n",
    "    \"Voting Ensemble 2\": voting_clf_2,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    df_tmp = get_scores_cv(model, name, X_train, y_train, cv=5)\n",
    "    df = pd.concat([df, df_tmp], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Removing Logistic Regression from Voting Classifier gives better results slightly better results in roc_auc metric.\n",
    "-   Random Forest Classifier is still the best model across all metrics.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Využite krížovú validáciu (cross validation) na trénovacej množine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We were already using cross validation in previous steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokážte že Váš nastavený najlepší model je bez overfitingu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models with different algorithms\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Since train metrics and test metrics are close, the model is not overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models with different algorithms\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for train data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, rf_classifier.predict_proba(X_train)[:, 1])\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for test data\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, rf_classifier.predict_proba(X_test)[:, 1])\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color=\"blue\", lw=2, label=f\"Train ROC curve (area = {roc_auc_train:.5f})\")\n",
    "plt.plot(fpr_test, tpr_test, color=\"red\", lw=2, label=f\"Test ROC curve (area = {roc_auc_test:.5f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can also see stable ROC curve for train and test data, so we can conclude that model is not overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnotenie vplyvu zvolenej stratégie riešenia na klasifikáciu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie riešenia chýbajúcich hodnôt a outlierov.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_raw():\n",
    "    file_path: str = \"../data/raw\"\n",
    "    files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "    dataset: dict[str, pd.DataFrame] = {}\n",
    "    for file in files:\n",
    "        dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")\n",
    "        dataset[file] = dataset[file].drop_duplicates()\n",
    "\n",
    "    df = pd.merge(dataset[\"connections\"], dataset[\"processes\"], on=[\"imei\", \"ts\", \"mwra\"])\n",
    "    df[\"ts\"] = pd.to_datetime(df.ts)\n",
    "\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_data = train_data.reset_index(drop=True)\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Define columns\n",
    "all_columns = train_data.drop(columns=[\"mwra\", \"ts\", \"imei\"]).columns\n",
    "non_gaussian_columns = [\n",
    "    \"c.android.vending\",\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "    \"p.android.vending\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.olauncher\",\n",
    "    \"p.simulator\",\n",
    "    \"p.inputmethod.latin\",\n",
    "    \"p.android.gms\",\n",
    "    \"p.notifier\",\n",
    "    \"p.katana\",\n",
    "    \"p.gms.persistent\",\n",
    "]\n",
    "gaussian_columns = all_columns[~all_columns.isin(non_gaussian_columns)]\n",
    "transformed_feature_order = pd.Series(gaussian_columns.tolist() + non_gaussian_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data, columns):\n",
    "    Q1 = data[columns].quantile(0.25)\n",
    "    Q3 = data[columns].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[columns] >= lower_bound).all(axis=1) & (data[columns] <= upper_bound).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vending_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"quantile_transformer\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"general\", general_pipe, gaussian_columns),\n",
    "        (\"vending\", vending_pipeline, non_gaussian_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Create complete pipeline\n",
    "complete_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_outliers = pd.DataFrame(\n",
    "    index=[\"Number of Outliers\", \"Percentage of Outliers\"],\n",
    "    columns=[\"None-iterative IQR\", \"Iterative IQR\", \"None-iterative Z-score\", \"Iterative Z-score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 2767\n",
      "Percentage of rows removed: 23.17%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Get number of rows before removing outliers\n",
    "number_of_rows_before_outliers = train_data.shape[0]\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "train_data = remove_outliers_iqr(train_data, train_data.iloc[:, 3:].columns)\n",
    "\n",
    "# Reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# Print number of outliers removed\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of rows removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "\n",
    "# Save number of outliers removed\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"None-iterative IQR\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"None-iterative IQR\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_1iqr.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_1iqr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 2934\n",
      "Percentage of outliers removed: 24.57%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Get number of rows before removing outliers\n",
    "number_of_rows_before_outliers = train_data.shape[0]\n",
    "\n",
    "# Define columns for IQR\n",
    "columns_for_iqr = train_data.iloc[:, 3:].columns.difference([\"p.android.vending\"])\n",
    "\n",
    "# Remove outliers using IQR method (in all columns)\n",
    "train_data = remove_outliers_iqr(train_data, train_data.iloc[:, 3:].columns)\n",
    "\n",
    "# Get number of outliers removed in next iteration\n",
    "outliers_count = (\n",
    "    ~(\n",
    "        (\n",
    "            train_data[columns_for_iqr]\n",
    "            >= train_data[columns_for_iqr].quantile(0.25)\n",
    "            - 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "        )\n",
    "        & (\n",
    "            train_data[columns_for_iqr]\n",
    "            <= train_data[columns_for_iqr].quantile(0.75)\n",
    "            + 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "        )\n",
    "    ).all(axis=1)\n",
    ").sum()\n",
    "\n",
    "# Define maximum number of iterations\n",
    "max_iterations = 10\n",
    "iteration = 0\n",
    "\n",
    "# Remove outliers iteratively\n",
    "while outliers_count > 0:\n",
    "    # Remove outliers using IQR method (in all columns except p.android.vending)\n",
    "    train_data = remove_outliers_iqr(train_data, columns_for_iqr)\n",
    "\n",
    "    # Get number of outliers removed in next iteration\n",
    "    outliers_count = (\n",
    "        ~(\n",
    "            (\n",
    "                train_data[columns_for_iqr]\n",
    "                >= train_data[columns_for_iqr].quantile(0.25)\n",
    "                - 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "            )\n",
    "            & (\n",
    "                train_data[columns_for_iqr]\n",
    "                <= train_data[columns_for_iqr].quantile(0.75)\n",
    "                + 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "            )\n",
    "        ).all(axis=1)\n",
    "    ).sum()\n",
    "\n",
    "    # Increment iteration and stop if maximum number of iterations reached\n",
    "    iteration += 1\n",
    "    if iteration >= max_iterations:\n",
    "        break\n",
    "\n",
    "# Reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# Print number of outliers removed\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of outliers removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "\n",
    "# Save number of outliers removed\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"Iterative IQR\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"Iterative IQR\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_itiqr.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_itiqr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative Z-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 477\n",
      "Percentage of outliers removed: 3.99%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Get number of rows before removing outliers\n",
    "number_of_rows_before_outliers = train_data.shape[0]\n",
    "\n",
    "# Remove outliers using Z-score method\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of outliers removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"None-iterative Z-score\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"None-iterative Z-score\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_1zscore.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_1zscore.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Z-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 570\n",
      "Percentage of outliers removed: 4.77%\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# 1 iteration of cleaning whole dataset of outliers (including p.android.vending)\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "\n",
    "# Using all columns except c.android.vending for outlier detection\n",
    "columns_for_zscore = train_data.iloc[:, 3:].columns.difference([\"p.android.vending\"])\n",
    "outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "max_iterations = 10\n",
    "iteration = 0\n",
    "\n",
    "# Iterating after we removed all outliers\n",
    "while outliers_count > 0:\n",
    "    train_data = train_data[(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)]\n",
    "    outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "    iteration += 1\n",
    "    if iteration >= max_iterations:\n",
    "        break\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of outliers removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"Iterative Z-score\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"Iterative Z-score\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_itzscore.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_itzscore.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None-iterative IQR</th>\n",
       "      <th>Iterative IQR</th>\n",
       "      <th>None-iterative Z-score</th>\n",
       "      <th>Iterative Z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of Outliers</th>\n",
       "      <td>2767</td>\n",
       "      <td>2934</td>\n",
       "      <td>477</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage of Outliers</th>\n",
       "      <td>23.17</td>\n",
       "      <td>24.57</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       None-iterative IQR Iterative IQR  \\\n",
       "Number of Outliers                   2767          2934   \n",
       "Percentage of Outliers              23.17         24.57   \n",
       "\n",
       "                       None-iterative Z-score Iterative Z-score  \n",
       "Number of Outliers                        477               570  \n",
       "Percentage of Outliers                   3.99              4.77  "
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using on Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Deleting outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]\n",
    "\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "df_none_cv = get_scores_cv(rf_classifier, \"None\", X_train, y_train, cv=5)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "df_none_scores = get_scores(rf_classifier, \"None\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_1iqr.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_1iqr.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_1iqr_cv = get_scores_cv(rf_classifier, \"1IQR\", X_train, y_train, cv=5)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "df_1iqr_scores = get_scores(rf_classifier, \"1IQR\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_itiqr.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_itiqr.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_itiqr_cv = get_scores_cv(rf_classifier, \"1ITIQR\", X_train, y_train, cv=5)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "df_itiqr_scores = get_scores(rf_classifier, \"1ITIQR\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative Z-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_1zscore.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_1zscore.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_1zscore_cv = get_scores_cv(rf_classifier, \"1ZSCORE\", X_train, y_train, cv=5)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "df_1zscore_scores = get_scores(rf_classifier, \"1ZSCORE\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Z-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_itzscore.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_itzscore.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_itzscore_cv = get_scores_cv(rf_classifier, \"1ITZSCORE\", X_train, y_train, cv=5)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "df_itzscore_scores = get_scores(rf_classifier, \"1ITZSCORE\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cv = pd.concat([df_none_cv, df_1iqr_cv, df_itiqr_cv, df_1zscore_cv, df_itzscore_cv], axis=1)\n",
    "df_scores = pd.concat(\n",
    "    [df_none_scores, df_1iqr_scores, df_itiqr_scores, df_1zscore_scores, df_itzscore_scores], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">None</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1IQR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1ITIQR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1ZSCORE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">1ITZSCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.918551</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.922434</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.922799</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.919349</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.919348</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.921994</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.923368</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.922212</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.922232</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.956935</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.952414</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.935943</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.940632</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.937069</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.937336</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.929811</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.93617</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.935692</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.93025</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.92971</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.91451</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.920191</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.915315</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.915501</td>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.919892</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.921835</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.919554</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.919453</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.954914</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.955984</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.948679</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.949715</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.932682</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.937884</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.938589</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.933885</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.934332</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.916022</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.916354</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.914908</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.915958</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.915743</td>\n",
       "      <td>0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.00404</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.00521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          None                1IQR              1ITIQR  \\\n",
       "                          Mean       Std      Mean       Std      Mean   \n",
       "Train      accuracy   0.918551  0.000674  0.922434  0.000418  0.922799   \n",
       "           precision  0.921994  0.000484  0.923368   0.00061  0.923371   \n",
       "           recall     0.950321  0.000878  0.956935  0.000982  0.958551   \n",
       "           f1         0.935943  0.000544  0.939852  0.000345  0.940632   \n",
       "           roc_auc    0.929811  0.001102   0.93617  0.000791  0.935692   \n",
       "Test       accuracy    0.91451  0.002263    0.9199  0.003009  0.920191   \n",
       "           precision  0.919892  0.002462  0.921469  0.003336  0.921835   \n",
       "           recall     0.945841  0.002809  0.954914    0.0043  0.955984   \n",
       "           f1         0.932682  0.001794  0.937884  0.002369  0.938589   \n",
       "           roc_auc    0.916022  0.004215  0.916354  0.003951  0.914908   \n",
       "Difference accuracy    0.00404  0.002463  0.002534  0.003377  0.002609   \n",
       "           precision  0.002102  0.002721  0.001899  0.003933  0.001536   \n",
       "           recall      0.00448  0.003372  0.002022  0.005175  0.002567   \n",
       "           f1         0.003261  0.001965  0.001968  0.002666  0.002043   \n",
       "           roc_auc     0.01379  0.005279  0.019817  0.004361  0.020784   \n",
       "\n",
       "                                 1ZSCORE           1ITZSCORE            \n",
       "                           Std      Mean       Std      Mean       Std  \n",
       "Train      accuracy   0.000592  0.919349  0.000706  0.919348  0.000809  \n",
       "           precision  0.000618  0.922212   0.00052  0.922232  0.000474  \n",
       "           recall     0.000978  0.952414  0.001061  0.952945  0.001311  \n",
       "           f1         0.000474  0.937069  0.000572  0.937336  0.000661  \n",
       "           roc_auc    0.001433   0.93025  0.000772   0.92971  0.000956  \n",
       "Test       accuracy   0.003622  0.915315  0.003237  0.915501  0.002895  \n",
       "           precision  0.002945  0.919554  0.002536  0.919453  0.002379  \n",
       "           recall     0.005357  0.948679  0.003944  0.949715  0.004295  \n",
       "           f1         0.002898  0.933885  0.002577  0.934332  0.002323  \n",
       "           roc_auc    0.005026  0.915958  0.003882  0.915743  0.004327  \n",
       "Difference accuracy   0.004205  0.004034  0.003648  0.003847  0.003507  \n",
       "           precision  0.003549  0.002658     0.003  0.002779  0.002814  \n",
       "           recall     0.006266  0.003735  0.004616   0.00323  0.005333  \n",
       "           f1         0.003362  0.003184  0.002904  0.003004  0.002821  \n",
       "           roc_auc    0.006367  0.014291  0.004521  0.013967   0.00521  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best accuracy: 1ITIQR\n",
    "-   Best F1:1ITIQR\n",
    "-   Best roc_auc: 1IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Train/Test split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">None</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1IQR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1ITIQR</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1ZSCORE</th>\n",
       "      <th colspan=\"3\" halign=\"left\">1ITZSCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Difference</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "      <th>Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.917609</td>\n",
       "      <td>0.915606</td>\n",
       "      <td>0.002002</td>\n",
       "      <td>0.92197</td>\n",
       "      <td>0.913262</td>\n",
       "      <td>0.008708</td>\n",
       "      <td>0.922411</td>\n",
       "      <td>0.910583</td>\n",
       "      <td>0.011828</td>\n",
       "      <td>0.919152</td>\n",
       "      <td>0.916276</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.918667</td>\n",
       "      <td>0.916276</td>\n",
       "      <td>0.002391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.921579</td>\n",
       "      <td>0.914697</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.923243</td>\n",
       "      <td>0.912686</td>\n",
       "      <td>0.010557</td>\n",
       "      <td>0.923219</td>\n",
       "      <td>0.908533</td>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.921934</td>\n",
       "      <td>0.915211</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.921526</td>\n",
       "      <td>0.914784</td>\n",
       "      <td>0.006742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.949184</td>\n",
       "      <td>0.953912</td>\n",
       "      <td>-0.004728</td>\n",
       "      <td>0.95629</td>\n",
       "      <td>0.952304</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.958072</td>\n",
       "      <td>0.95284</td>\n",
       "      <td>0.005232</td>\n",
       "      <td>0.952414</td>\n",
       "      <td>0.954448</td>\n",
       "      <td>-0.002034</td>\n",
       "      <td>0.952632</td>\n",
       "      <td>0.954984</td>\n",
       "      <td>-0.002352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.935178</td>\n",
       "      <td>0.933893</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.939476</td>\n",
       "      <td>0.932074</td>\n",
       "      <td>0.007401</td>\n",
       "      <td>0.940323</td>\n",
       "      <td>0.93016</td>\n",
       "      <td>0.010163</td>\n",
       "      <td>0.936926</td>\n",
       "      <td>0.934418</td>\n",
       "      <td>0.002508</td>\n",
       "      <td>0.936821</td>\n",
       "      <td>0.934452</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.906955</td>\n",
       "      <td>0.902849</td>\n",
       "      <td>0.004106</td>\n",
       "      <td>0.909497</td>\n",
       "      <td>0.900259</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.908812</td>\n",
       "      <td>0.896509</td>\n",
       "      <td>0.012303</td>\n",
       "      <td>0.907408</td>\n",
       "      <td>0.903563</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.906359</td>\n",
       "      <td>0.903385</td>\n",
       "      <td>0.002974</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               None                           1IQR                       \\\n",
       "              Train      Test Difference     Train      Test Difference   \n",
       "accuracy   0.917609  0.915606   0.002002   0.92197  0.913262   0.008708   \n",
       "precision  0.921579  0.914697   0.006882  0.923243  0.912686   0.010557   \n",
       "recall     0.949184  0.953912  -0.004728   0.95629  0.952304   0.003985   \n",
       "f1-score   0.935178  0.933893   0.001285  0.939476  0.932074   0.007401   \n",
       "roc_auc    0.906955  0.902849   0.004106  0.909497  0.900259   0.009238   \n",
       "\n",
       "             1ITIQR                        1ZSCORE                       \\\n",
       "              Train      Test Difference     Train      Test Difference   \n",
       "accuracy   0.922411  0.910583   0.011828  0.919152  0.916276   0.002876   \n",
       "precision  0.923219  0.908533   0.014685  0.921934  0.915211   0.006723   \n",
       "recall     0.958072   0.95284   0.005232  0.952414  0.954448  -0.002034   \n",
       "f1-score   0.940323   0.93016   0.010163  0.936926  0.934418   0.002508   \n",
       "roc_auc    0.908812  0.896509   0.012303  0.907408  0.903563   0.003845   \n",
       "\n",
       "          1ITZSCORE                       \n",
       "              Train      Test Difference  \n",
       "accuracy   0.918667  0.916276   0.002391  \n",
       "precision  0.921526  0.914784   0.006742  \n",
       "recall     0.952632  0.954984  -0.002352  \n",
       "f1-score   0.936821  0.934452   0.002369  \n",
       "roc_auc    0.906359  0.903385   0.002974  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best accuracy: 1ITZSCORE\n",
    "-   Best F1: 1ITZSCORE\n",
    "-   Best roc_auc: 1ITZSCORE\n",
    "\n",
    "-   We can see that using cross validation, it prefers lower outlier removal, this can maybe be because there is not enough data for it to reach optimal learning.\n",
    "-   Using whole train data, to train model and test on test data, it prefers higher outlier removal, this is what we expected.\n",
    "-   Using cross_validation for model comparison is best practice, but since 1ITIQR removes 24.57% of data which is quite substantial amount and 1ITZSCORE which removes only 4.77% and only targets very extreme outliers, we are going to use 1ITZSCORE for further steps as it had best performance in Train/Test split and it also has lower std in cross validation indicating that it is more stable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dátová transformácia (scaling, transformer, ...).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our old clean data as we used iterative Z-score for cleaning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_clean():\n",
    "    file_path: str = \"../data/clean\"\n",
    "\n",
    "    # Load cleaned data (Iterative Z-score)\n",
    "    train_data = pd.read_csv(f\"{file_path}/train_itzscore.csv\")\n",
    "    test_data = pd.read_csv(f\"{file_path}/test_itzscore.csv\")\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['ts', 'imei'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[272], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define columns\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m all_columns \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmwra\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mts\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimei\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m      4\u001b[0m gaussian_columns \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc.dogalize\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc.android.gm\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mp.android.defcontainer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     22\u001b[0m ]\n\u001b[0;32m     24\u001b[0m log_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc.android.vending\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['ts', 'imei'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# Define columns\n",
    "all_columns = train_data.drop(columns=[\"mwra\", \"ts\", \"imei\"]).columns\n",
    "\n",
    "gaussian_columns = [\n",
    "    \"c.dogalize\",\n",
    "    \"c.android.gm\",\n",
    "    \"c.android.youtube\",\n",
    "    \"c.android.chrome\",\n",
    "    \"c.katana\",\n",
    "    \"c.raider\",\n",
    "    \"p.android.packageinstaller\",\n",
    "    \"p.android.settings\",\n",
    "    \"p.android.documentsui\",\n",
    "    \"p.android.chrome\",\n",
    "    \"p.android.gm\",\n",
    "    \"p.system\",\n",
    "    \"p.android.externalstorage\",\n",
    "    \"p.process.gapps\",\n",
    "    \"p.google\",\n",
    "    \"p.browser.provider\",\n",
    "    \"p.android.defcontainer\",\n",
    "]\n",
    "\n",
    "log_columns = [\"c.android.vending\"]\n",
    "\n",
    "uniform_columns = [\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "    \"p.android.vending\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.olauncher\",\n",
    "    \"p.simulator\",\n",
    "    \"p.inputmethod.latin\",\n",
    "    \"p.android.gms\",\n",
    "    \"p.notifier\",\n",
    "    \"p.katana\",\n",
    "    \"p.gms.persistent\",\n",
    "]\n",
    "\n",
    "\n",
    "transformed_feature_order = pd.Series(gaussian_columns + log_columns + uniform_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define different pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our pipeline from 2nd Phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "non_gaussian_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"quantile_transformer\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"general\", gaussian_pipeline, gaussian_columns),\n",
    "        (\"other\", non_gaussian_pipeline, [log_columns, uniform_columns]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "our_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining different scalers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define pipelines\n",
    "min_max_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", MinMaxScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "standard_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "robust_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "quantile_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create column transformers\n",
    "min_max_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"min_max\", min_max_pipeline, gaussian_columns),\n",
    "        (\"other\", quantile_pipeline, [log_columns, uniform_columns]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "standard_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"standard\", standard_pipeline, gaussian_columns),\n",
    "        (\"other\", quantile_pipeline, [log_columns, uniform_columns]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "robust_preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"robust\", robust_pipeline, gaussian_columns),\n",
    "        (\"other\", quantile_pipeline, [log_columns, uniform_columns]),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Create complete pipelines\n",
    "min_max_pipeline = Pipeline([(\"preprocessor\", min_max_preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])\n",
    "standard_pipeline = Pipeline([(\"preprocessor\", standard_preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])\n",
    "robust_pipeline = Pipeline([(\"preprocessor\", robust_preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using on Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['c.android.gm', 'c.android.chrome', 'c.raider', 'c.android.vending', 'c.UCMobile.x86', 'c.updateassist', 'c.UCMobile.intl', 'p.android.gm', 'p.android.vending', 'p.google', 'p.browser.provider', 'p.android.defcontainer', 'p.dogalize', 'p.olauncher', 'p.simulator', 'p.inputmethod.latin', 'p.android.gms', 'p.notifier', 'p.katana', 'p.gms.persistent'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[254], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m train_data, test_data \u001b[38;5;241m=\u001b[39m load_data_clean()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Transform data\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m train_data_processed \u001b[38;5;241m=\u001b[39m min_max_pipeline\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43mall_columns\u001b[49m\u001b[43m]\u001b[49m, train_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmwra\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m      6\u001b[0m test_data_processed \u001b[38;5;241m=\u001b[39m min_max_pipeline\u001b[38;5;241m.\u001b[39mtransform(test_data[all_columns])\n\u001b[0;32m      8\u001b[0m feature_mask \u001b[38;5;241m=\u001b[39m min_max_pipeline\u001b[38;5;241m.\u001b[39mnamed_steps[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mselector\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_support()\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['c.android.gm', 'c.android.chrome', 'c.raider', 'c.android.vending', 'c.UCMobile.x86', 'c.updateassist', 'c.UCMobile.intl', 'p.android.gm', 'p.android.vending', 'p.google', 'p.browser.provider', 'p.android.defcontainer', 'p.dogalize', 'p.olauncher', 'p.simulator', 'p.inputmethod.latin', 'p.android.gms', 'p.notifier', 'p.katana', 'p.gms.persistent'] not in index\""
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_clean()\n",
    "\n",
    "# Transform data\n",
    "train_data_processed = min_max_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = min_max_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "feature_mask = min_max_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]\n",
    "\n",
    "# Use on model\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "df_min_max_cv = get_scores_cv(\n",
    "    rf_classifier, \"MinMax\", train_data_processed.drop(columns=[\"mwra\"]), train_data_processed[\"mwra\"], cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_clean()\n",
    "\n",
    "# Transform data\n",
    "train_data_processed = standard_pipeline.fit_transform(train_data[transformed_feature_order], train_data[\"mwra\"])\n",
    "test_data_processed = standard_pipeline.transform(test_data[transformed_feature_order])\n",
    "\n",
    "feature_mask = standard_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]\n",
    "\n",
    "# Use on model\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "df_standard_cv = get_scores_cv(\n",
    "    rf_classifier, \"Standard\", train_data_processed.drop(columns=[\"mwra\"]), train_data_processed[\"mwra\"], cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_clean()\n",
    "\n",
    "# Transform data\n",
    "train_data_processed = robust_pipeline.fit_transform(train_data[transformed_feature_order], train_data[\"mwra\"])\n",
    "test_data_processed = robust_pipeline.transform(test_data[transformed_feature_order])\n",
    "\n",
    "feature_mask = robust_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]\n",
    "\n",
    "# Use on model\n",
    "df_robust_cv = get_scores_cv(\n",
    "    rf_classifier, \"Robust\", train_data_processed.drop(columns=[\"mwra\"]), train_data_processed[\"mwra\"], cv=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_min_max_cv, df_standard_cv, df_robust_cv], axis=1)\n",
    "del df_min_max_cv, df_standard_cv, df_robust_cv\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výber atribútov, výber algoritmov, hyperparameter tuning, ensemble learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ktorý model je Váš najlepší model pre nasadenie (deployment)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aký je data pipeline pre jeho vybudovanie na základe Vášho datasetu v produkcii?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
