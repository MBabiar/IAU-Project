{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from graphviz import Source\n",
    "from IPython.core.magic import register_cell_magic\n",
    "from IPython.display import HTML, SVG\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import (\n",
    "    GradientBoostingClassifier,\n",
    "    HistGradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    "    StackingClassifier,\n",
    "    VotingClassifier,\n",
    ")\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    ")\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV,\n",
    "    ParameterGrid,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    "    cross_validate,\n",
    "    learning_curve,\n",
    "    train_test_split,\n",
    ")\n",
    "from sklearn.pipeline import FunctionTransformer, Pipeline\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    PowerTransformer,\n",
    "    QuantileTransformer,\n",
    "    RobustScaler,\n",
    "    StandardScaler,\n",
    ")\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = \"../data/raw\"\n",
    "files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "dataset: dict[str, pd.DataFrame] = {}\n",
    "for file in files:\n",
    "    dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")\n",
    "    dataset[file] = dataset[file].drop_duplicates()\n",
    "\n",
    "df = pd.merge(dataset[\"connections\"], dataset[\"processes\"], on=[\"imei\", \"ts\", \"mwra\"])\n",
    "df[\"ts\"] = pd.to_datetime(df.ts)\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 iteration of cleaning whole dataset of outliers (including p.android.vending)\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "\n",
    "# Using all columns except c.android.vending for outlier detection\n",
    "columns_for_zscore = train_data.iloc[:, 3:].columns.difference([\"p.android.vending\"])\n",
    "outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "max_iterations = 10\n",
    "iteration = 0\n",
    "\n",
    "# Iterating after we removed all outliers\n",
    "while outliers_count > 0:\n",
    "    train_data = train_data[(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)]\n",
    "    outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "    iteration += 1\n",
    "    if iteration >= max_iterations:\n",
    "        break\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting cleaned data\n",
    "os.makedirs(\"../data/clean\", exist_ok=True)\n",
    "\n",
    "train_data.to_csv(\"../data/clean/train_data.csv\", index=False)\n",
    "test_data.to_csv(\"../data/clean/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"../data/clean/train_data.csv\")\n",
    "test_data = pd.read_csv(\"../data/clean/test_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns = train_data.drop(columns=[\"mwra\", \"ts\", \"imei\"]).columns\n",
    "non_gaussian_columns = [\n",
    "    \"c.android.vending\",\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "    \"p.android.vending\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.olauncher\",\n",
    "    \"p.simulator\",\n",
    "    \"p.inputmethod.latin\",\n",
    "    \"p.android.gms\",\n",
    "    \"p.notifier\",\n",
    "    \"p.katana\",\n",
    "    \"p.gms.persistent\",\n",
    "]\n",
    "gaussian_columns = all_columns[~all_columns.isin(non_gaussian_columns)]\n",
    "transformed_feature_order = pd.Series(gaussian_columns.tolist() + non_gaussian_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vending_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"quantile_transformer\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"general\", general_pipe, gaussian_columns),\n",
    "        (\"vending\", vending_pipeline, non_gaussian_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Create complete pipeline\n",
    "complete_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/processed/train_data.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/processed/test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    file_path,\n",
    "    files,\n",
    "    file,\n",
    "    df,\n",
    "    train_data,\n",
    "    test_data,\n",
    "    columns_for_zscore,\n",
    "    outliers_count,\n",
    "    max_iterations,\n",
    "    iteration,\n",
    "    all_columns,\n",
    "    non_gaussian_columns,\n",
    "    gaussian_columns,\n",
    "    transformed_feature_order,\n",
    "    general_pipe,\n",
    "    vending_pipeline,\n",
    "    preprocessor,\n",
    "    complete_pipeline,\n",
    "    train_data_processed,\n",
    "    test_data_processed,\n",
    "    dataset,\n",
    "    selected_features,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Stuff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_processed = pd.read_csv(\"../data/processed/train_data.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/processed/test_data.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]\n",
    "\n",
    "del train_data_processed, test_data_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        index=[\"accuracy\", \"precision\", \"recall\", \"f1-score\", \"roc_auc\"],\n",
    "        columns=pd.MultiIndex.from_product([[model_name], [\"Train\", \"Test\", \"Difference\"]]),\n",
    "    )\n",
    "\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    precision_train = precision_score(y_train, y_pred_train)\n",
    "    recall_train = recall_score(y_train, y_pred_train)\n",
    "    f1_train = f1_score(y_train, y_pred_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Train\")] = accuracy_train\n",
    "    df.loc[\"precision\", (model_name, \"Train\")] = precision_train\n",
    "    df.loc[\"recall\", (model_name, \"Train\")] = recall_train\n",
    "    df.loc[\"f1-score\", (model_name, \"Train\")] = f1_train\n",
    "    df.loc[\"roc_auc\", (model_name, \"Train\")] = roc_auc_train\n",
    "\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    precision_test = precision_score(y_test, y_pred_test)\n",
    "    recall_test = recall_score(y_test, y_pred_test)\n",
    "    f1_test = f1_score(y_test, y_pred_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Test\")] = accuracy_test\n",
    "    df.loc[\"precision\", (model_name, \"Test\")] = precision_test\n",
    "    df.loc[\"recall\", (model_name, \"Test\")] = recall_test\n",
    "    df.loc[\"f1-score\", (model_name, \"Test\")] = f1_test\n",
    "    df.loc[\"roc_auc\", (model_name, \"Test\")] = roc_auc_test\n",
    "\n",
    "    df.loc[\"accuracy\", (model_name, \"Difference\")] = accuracy_train - accuracy_test\n",
    "    df.loc[\"precision\", (model_name, \"Difference\")] = precision_train - precision_test\n",
    "    df.loc[\"recall\", (model_name, \"Difference\")] = recall_train - recall_test\n",
    "    df.loc[\"f1-score\", (model_name, \"Difference\")] = f1_train - f1_test\n",
    "    df.loc[\"roc_auc\", (model_name, \"Difference\")] = roc_auc_train - roc_auc_test\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_cv(model, model_name, X, y, cv):\n",
    "    metrics = [\"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\"]\n",
    "\n",
    "    # Create MultiIndex DataFrame\n",
    "    df = pd.DataFrame(\n",
    "        index=pd.MultiIndex.from_product([[\"Train\", \"Test\", \"Difference\"], metrics]),\n",
    "        columns=pd.MultiIndex.from_product([[model_name], [\"Mean\", \"Std\"]]),\n",
    "    )\n",
    "\n",
    "    # Calculate scores for each model\n",
    "    scores = cross_validate(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=cv,\n",
    "        scoring={\n",
    "            \"accuracy\": \"accuracy\",\n",
    "            \"precision\": \"precision\",\n",
    "            \"recall\": \"recall\",\n",
    "            \"f1\": \"f1\",\n",
    "            \"roc_auc\": \"roc_auc\",\n",
    "        },\n",
    "        return_train_score=True,\n",
    "    )\n",
    "\n",
    "    # Fill DataFrame with training and test scores\n",
    "    for metric in metrics:\n",
    "        # Training scores\n",
    "        train_key = f\"train_{metric}\"\n",
    "        df.loc[(\"Train\", metric), (model_name, \"Mean\")] = scores[train_key].mean()\n",
    "        df.loc[(\"Train\", metric), (model_name, \"Std\")] = scores[train_key].std()\n",
    "\n",
    "        # Test scores\n",
    "        test_key = f\"test_{metric}\"\n",
    "        df.loc[(\"Test\", metric), (model_name, \"Mean\")] = scores[test_key].mean()\n",
    "        df.loc[(\"Test\", metric), (model_name, \"Std\")] = scores[test_key].std()\n",
    "\n",
    "        # Difference between training and test scores\n",
    "        diff = scores[train_key] - scores[test_key]\n",
    "        df.loc[(\"Difference\", metric), (model_name, \"Mean\")] = diff.mean()\n",
    "        df.loc[(\"Difference\", metric), (model_name, \"Std\")] = diff.std()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, X, y, train_sizes, cv, scoring, title):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, train_sizes=train_sizes, scoring=scoring, n_jobs=-1\n",
    "    )\n",
    "    train_scores_mean = 1 - train_scores.mean(axis=1)\n",
    "    test_scores_mean = 1 - test_scores.mean(axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_scores_mean, label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, label=\"Cross-Validation Score\")\n",
    "    plt.xlabel(\"Training Size\")\n",
    "    plt.ylabel(f\"{scoring} Error\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_complexity_curve(model, X_train, y_train, X_test, y_test, max_depth_range):\n",
    "    # Initialize lists to store the training and validation errors\n",
    "    train_errors = []\n",
    "    val_errors = []\n",
    "\n",
    "    # Loop over the range of max_depth values\n",
    "    for max_depth in max_depth_range:\n",
    "        # Initialize the model with the current max_depth\n",
    "        model = DecisionTreeClassifier(\n",
    "            criterion=\"gini\",\n",
    "            max_depth=max_depth,\n",
    "            min_samples_split=10,\n",
    "            min_samples_leaf=1,\n",
    "            ccp_alpha=0.001,\n",
    "            random_state=42,\n",
    "        )\n",
    "\n",
    "        # Fit model\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Compute the training and testing data errors\n",
    "        train_score = accuracy_score(y_train, model.predict(X_train))\n",
    "        test_score = accuracy_score(y_test, model.predict(X_test))\n",
    "\n",
    "        # Compute the mean errors\n",
    "        train_errors.append(1 - train_score)\n",
    "        val_errors.append(1 - test_score)\n",
    "\n",
    "    # Plot the learning curve for model complexity\n",
    "    plt.figure()\n",
    "    plt.plot(max_depth_range, train_errors, label=\"Training Error\")\n",
    "    plt.plot(max_depth_range, val_errors, label=\"Validation Error\")\n",
    "    plt.xlabel(\"Max Depth\")\n",
    "    plt.ylabel(\"Error\")\n",
    "    plt.title(\"Learning Curve (Model Complexity)\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_confusion_matrix(models, X_train, y_train, X_test, y_test):\n",
    "    _, axes = plt.subplots(1, len(models), figsize=(15, 5))\n",
    "\n",
    "    for i, (model_name, model) in enumerate(models):\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=axes[i])\n",
    "        axes[i].set_title(model_name)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(model, model_name, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
    "    plt.title(model_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_best_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 10,\n",
    "    \"min_samples_split\": 5,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"ccp_alpha\": 0.001,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "lgr_best_params = {\"C\": 0.01, \"max_iter\": 100, \"penalty\": \"l2\", \"solver\": \"lbfgs\", \"tol\": 0.001}\n",
    "\n",
    "gbg_best_params = {\n",
    "    \"subsample\": 0.8,\n",
    "    \"n_estimators\": 100,\n",
    "    \"min_samples_split\": 2,\n",
    "    \"min_samples_leaf\": 1,\n",
    "    \"max_depth\": 4,\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"random_state\": 42,\n",
    "}\n",
    "\n",
    "hbg_best_params = {\n",
    "    \"l2_regularization\": 2.0,\n",
    "    \"learning_rate\": 0.1,\n",
    "    \"max_depth\": 7,\n",
    "    \"max_iter\": 200,\n",
    "    \"min_samples_leaf\": 20,\n",
    "    \"random_state\": 42,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "def ignore(line, cell):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Jednoduchý klasifikátor na základe závislosti v dátach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naimplementujte jednoduchý ID3 klasifikátor s hĺbkou min 2 (vrátane root/koreň).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, attribute=None, value=None, is_leaf=False, prediction=None):\n",
    "        self.attribute = attribute\n",
    "        self.value = value\n",
    "        self.is_leaf = is_leaf\n",
    "        self.prediction = prediction\n",
    "        self.children = {}\n",
    "\n",
    "\n",
    "class ID3Classifier:\n",
    "    def __init__(self, min_depth: int = 2, max_depth: int = None) -> None:\n",
    "        self.max_depth = max_depth\n",
    "        self.min_depth = min_depth\n",
    "        self.tree = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        data = X.copy()\n",
    "        data[\"label\"] = y\n",
    "        self.tree = self._build_tree(data, current_depth=0)\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        proportions = y.value_counts(normalize=True)\n",
    "        return -np.sum(proportions * np.log2(proportions))\n",
    "\n",
    "    def _information_gain(self, data, attribute, target=\"label\"):\n",
    "        total_entropy = self._entropy(data[target])\n",
    "        values = data[attribute].unique()\n",
    "        weighted_entropy = 0\n",
    "        for value in values:\n",
    "            subset = data[data[attribute] == value]\n",
    "            weighted_entropy += (len(subset) / len(data)) * self._entropy(subset[target])\n",
    "        return total_entropy - weighted_entropy\n",
    "\n",
    "    def _best_split(self, data, attributes, target=\"label\"):\n",
    "        best_gain = -1\n",
    "        best_attribute = None\n",
    "        for attribute in attributes:\n",
    "            gain = self._information_gain(data, attribute, target)\n",
    "            if gain > best_gain:\n",
    "                best_gain = gain\n",
    "                best_attribute = attribute\n",
    "        return best_attribute\n",
    "\n",
    "    def _build_tree(self, data, current_depth):\n",
    "        X = data.drop(columns=[\"label\"])\n",
    "        y = data[\"label\"]\n",
    "\n",
    "        if len(y.unique()) == 1 or (self.max_depth is not None and current_depth >= self.max_depth):\n",
    "            return Node(is_leaf=True, prediction=y.iloc[0])\n",
    "\n",
    "        if current_depth >= self.min_depth or X.empty:\n",
    "            return Node(is_leaf=True, prediction=y.mode().iloc[0])\n",
    "\n",
    "        best_attribute = self._best_split(data, X.columns)\n",
    "        root = Node(attribute=best_attribute)\n",
    "\n",
    "        for value in data[best_attribute].unique():\n",
    "            subset = data[data[best_attribute] == value]\n",
    "            root.children[value] = self._build_tree(subset, current_depth + 1)\n",
    "\n",
    "        return root\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X.apply(self._predict_row, axis=1, args=(self.tree,))\n",
    "\n",
    "    def _predict_row(self, row, node):\n",
    "        if node.is_leaf:\n",
    "            return node.prediction\n",
    "\n",
    "        attribute_value = row[node.attribute]\n",
    "        if attribute_value in node.children:\n",
    "            return self._predict_row(row, node.children[attribute_value])\n",
    "\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnoťte Váš ID3 klasifikátor pomocou metrík accuracy, precision a recall.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id3_classifier = ID3Classifier(min_depth=2, max_depth=5)\n",
    "id3_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:390: RuntimeWarning: invalid value encountered in cast\n",
      "  return x.astype(dtype, copy=copy, casting=casting)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input y_pred contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[194], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mid3_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mID3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[53], line 22\u001b[0m, in \u001b[0;36mget_scores\u001b[1;34m(model, model_name, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m     19\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m, (model_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;241m=\u001b[39m f1_train\n\u001b[0;32m     20\u001b[0m df\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m, (model_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m)] \u001b[38;5;241m=\u001b[39m roc_auc_train\n\u001b[1;32m---> 22\u001b[0m accuracy_test \u001b[38;5;241m=\u001b[39m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m precision_test \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred_test)\n\u001b[0;32m     24\u001b[0m recall_test \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred_test)\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:231\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    229\u001b[0m xp, _, device \u001b[38;5;241m=\u001b[39m get_namespace_and_device(y_true, y_pred, sample_weight)\n\u001b[0;32m    230\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 231\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    232\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:105\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m    103\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[0;32m    104\u001b[0m type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 105\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m}:\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\multiclass.py:398\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y, input_name)\u001b[0m\n\u001b[0;32m    396\u001b[0m     data \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;28;01mif\u001b[39;00m issparse(y) \u001b[38;5;28;01melse\u001b[39;00m y\n\u001b[0;32m    397\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m xp\u001b[38;5;241m.\u001b[39many(data \u001b[38;5;241m!=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(data, \u001b[38;5;28mint\u001b[39m)):\n\u001b[1;32m--> 398\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[0;32m    401\u001b[0m \u001b[38;5;66;03m# Check multiclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:123\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m--> 123\u001b[0m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    129\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    130\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:172\u001b[0m, in \u001b[0;36m_assert_all_finite_element_wise\u001b[1;34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[0;32m    157\u001b[0m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[0;32m    158\u001b[0m     msg_err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not accept missing values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    170\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#estimators-that-handle-nan-values\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    171\u001b[0m     )\n\u001b[1;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[1;31mValueError\u001b[0m: Input y_pred contains NaN."
     ]
    }
   ],
   "source": [
    "df = get_scores(id3_classifier, \"ID3\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see that using feature selection gives worse results. We will look at it in more detail later (3.4).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zístite či Váš ID3 klasifikátor má overfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Since train and test metrics are close, the model is likely not overfitting.\n",
    "-   But let's also look at learning curves.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve - train sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "dtc_nofs = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", max_depth=15, min_samples_split=10, min_samples_leaf=1, ccp_alpha=0.001, random_state=42\n",
    ")\n",
    "\n",
    "# Define the training sizes\n",
    "train_sizes = np.linspace(0.1, 1.0, 50)\n",
    "\n",
    "# Plot learning curve for accuracy\n",
    "plot_learning_curve(\n",
    "    dtc_nofs,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    train_sizes,\n",
    "    cv=5,\n",
    "    scoring=\"accuracy\",\n",
    "    title=\"Learning Curve - Train size (Accuracy)\",\n",
    ")\n",
    "\n",
    "# Plot learning curve for precision\n",
    "plot_learning_curve(\n",
    "    dtc_nofs,\n",
    "    X_train,\n",
    "    y_train,\n",
    "    train_sizes,\n",
    "    cv=5,\n",
    "    scoring=\"precision\",\n",
    "    title=\"Learning Curve - Train size (Precision)\",\n",
    ")\n",
    "\n",
    "# Plot learning curve for recall\n",
    "plot_learning_curve(\n",
    "    dtc_nofs, X_train, y_train, train_sizes, cv=5, scoring=\"recall\", title=\"Learning Curve - Train size (Recall)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We don't see a big gap in metrics between train and test data (Looking at last point since that is what we used in previous steps).\n",
    "-   However we see that model starts of badly (as expected) and then improves with more data. Around 50% of data for training seems to be enough.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curve - model complexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the range of max_depth values\n",
    "max_depth_range = range(1, 30)\n",
    "\n",
    "# Plot model complexity curve\n",
    "plot_model_complexity_curve(dtc_nofs, X_train, y_train, X_test, y_test, max_depth_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   This also shows no overfitting for our graph as there is no significant gap (looking at max_depth=15, as this is what we used in previous steps).\n",
    "-   We can also see that model start of very badly and is underfitting.\n",
    "-   Around max_depth=5 training and testing error stabilizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_nofs = DecisionTreeClassifier(\n",
    "    criterion=\"gini\", max_depth=15, min_samples_split=10, min_samples_leaf=1, ccp_alpha=0.001, random_state=42\n",
    ")\n",
    "\n",
    "dtc_nofs.fit(X_train, y_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for train data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, dtc_nofs.predict_proba(X_train)[:, 1])\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for test data\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, dtc_nofs.predict_proba(X_test)[:, 1])\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color=\"blue\", lw=2, label=f\"Train ROC curve (area = {roc_auc_train:.5f})\")\n",
    "plt.plot(fpr_test, tpr_test, color=\"red\", lw=2, label=f\"Test ROC curve (area = {roc_auc_test:.5f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   ROC also shows no significant gap between train and test data. So we can conclude that model is not overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del (\n",
    "    dtc_fs,\n",
    "    dtc_nofs,\n",
    "    fpr_train,\n",
    "    tpr_train,\n",
    "    fpr_test,\n",
    "    tpr_test,\n",
    "    train_sizes,\n",
    "    max_depth_range,\n",
    "    roc_auc_test,\n",
    "    roc_auc_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trénovanie a vyhodnotenie klasifikátorov strojového učenia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na trénovanie využite jeden stromový algoritmus v scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use some basic parameters to avoid overfitting\n",
    "dst_classifier = DecisionTreeClassifier(max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "dst_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = get_scores_cv(dst_classifier, \"DecisionTreeClassifier\", X_train, y_train, cv=5)\n",
    "df_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(dst_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Even quite simple model gives good results without overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porovnajte s jedným iným nestromovým algoritmom v scikit-learn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = get_scores_cv(log_reg, \"LogisticRegression\", X_train, y_train, cv=5)\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_confusion_matrix(log_reg, \"LogisticRegression\", X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Basic logistic regression gives quite good results without overfitting as well\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "del df_1, df_2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_confusion_matrix(\n",
    "    [(\"RandomForestClassifier\", dst_classifier), (\"LogisticRegression\", log_reg)], X_train, y_train, X_test, y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Basic Logistic Regression gives slightly better results than basic Decision Tree Classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Porovnajte výsledky s ID3 z prvého kroku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Finish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vizualizujte natrénované pravidlá minimálne pre jeden Vami vybraný algoritmus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize RandomForestClassifier\n",
    "dst_classifier = DecisionTreeClassifier(max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dst_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Generate graph\n",
    "graph = Source(\n",
    "    export_graphviz(\n",
    "        dst_classifier, out_file=None, class_names=[\"no\", \"yes\"], filled=True, feature_names=X_train.columns\n",
    "    )\n",
    ")\n",
    "\n",
    "# Display graph\n",
    "display(SVG(graph.pipe(format=\"svg\")))\n",
    "\n",
    "style = \"<style>svg{width:100%;height:70%;}</style>\"\n",
    "HTML(style)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnoťte natrénované modely pomocou metrík accuracy, precision a recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We already did this but let's do it again.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize classifiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classifiers\n",
    "dst_classifier = DecisionTreeClassifier(max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "log_reg = LogisticRegression(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the scores\n",
    "df_1 = get_scores_cv(dst_classifier, \"DecisionTreeClassifier\", X_train, y_train, cv=5)\n",
    "df_2 = get_scores_cv(log_reg, \"LogisticRegression\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "del df_1, df_2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare matrixes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_confusion_matrix(\n",
    "    [\n",
    "        (\"DecisionTreeClassifier\", dst_classifier),\n",
    "        (\"LogisticRegression\", log_reg),\n",
    "    ],\n",
    "    X_train,\n",
    "    y_train,\n",
    "    X_test,\n",
    "    y_test,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   As we already said, Logistic Regression gives slightly better results than Decision Tree Classifier.\n",
    "-   However, both models are quite good and don't overfit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dst_classifier, log_reg, graph, style"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimalizácia alias hyperparameter tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšajte rôzne nastavenie hyperparametrov (tuning) pre zvolený algoritmus tak,\n",
    "aby ste optimalizovali výkonnosť (bez underfitingu).\n",
    "\n",
    "We will test parameters for RandomForestClassifier as we know this will be better than DecisionTreeClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree vs Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"max_depth\": [5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"ccp_alpha\": [0.0, 0.0005, 0.001, 0.0015],\n",
    "    \"min_impurity_decrease\": [0.0, 0.0005, 0.001, 0.0015],\n",
    "}\n",
    "\n",
    "# Initialize the DecisionTreeClassifier\n",
    "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=dt_classifier, param_grid=param_grid, cv=5, scoring=\"accuracy\", n_jobs=-1, verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Score:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'ccp_alpha': 0.0005, 'max_depth': 10, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 4, 'min_samples_split': 2}\n",
    "-   Best Score: 0.9026635738931255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_classifier = DecisionTreeClassifier(\n",
    "    max_depth=10, min_samples_split=2, min_samples_leaf=4, ccp_alpha=0.0005, random_state=42\n",
    ")\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, max_depth=15, ccp_alpha=0.001, random_state=42)\n",
    "\n",
    "df_1 = get_scores_cv(dt_classifier, \"DecisionTreeClassifier\", X_train, y_train, cv=5)\n",
    "df_2 = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "del df_1, df_2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   This shows difference between optimized Decision Tree and some basic Random Forest (with basic paramters to avoid overfitting).\n",
    "-   We can clearly see that Random Forest is better and therefore we are gonna use it for further steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, find baseline parameters\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### n_estimators\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=100, min_samples_split=2, min_samples_leaf=2, max_depth=20, ccp_alpha=0.001\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    n_estimators=1000, min_samples_split=2, min_samples_leaf=2, max_depth=20, ccp_alpha=0.001\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see that performance is not increasing with n_estimators.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ccp_alpha\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(criterion=\"entropy\", n_estimators=100, random_state=42, ccp_alpha=0.002)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(criterion=\"entropy\", n_estimators=100, random_state=42, ccp_alpha=0.005)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see ccp_alpha 0.002 is better considering ROC AUC factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### max_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=7,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    "    max_features=\"log2\",\n",
    "    max_depth=7,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   When also using max_depth, there is difference in ROC AUC, sqrt is better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### criterion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"entropy\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    criterion=\"gini\",\n",
    "    n_estimators=100,\n",
    "    random_state=42,\n",
    "    ccp_alpha=0.002,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Print the scores\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Entropy is better considering ROC AUC factor.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   In previous step, we found that n_estimators=100, ccp_alpha=0.002, max_features=sqrt, criterion=entropy are better.\n",
    "-   However we are not gonna look at max_features and criterion in first tuning method as we will look at them at the end when we have best primary hyperparameters.\n",
    "-   Not using max_features and criterion in first tuning gives more priority to other hyperparameters.\n",
    "-   Our primary hyperparameters are n_estimators, max_depth, min_samples_split, min_samples_leaf, ccp_alpha.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the broad parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"max_depth\": [5, 10, 15, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"ccp_alpha\": [0.001, 0.002, 0.003],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf_classifier,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'n_estimators': 300, 'min_samples_split': 10, 'min_samples_leaf': 2, 'max_depth': 15, 'ccp_alpha': 0.002}\n",
    "-   Best Score: 0.91579\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Best parameters from RandomizedSearchCV\n",
    "best_params = {\n",
    "    \"n_estimators\": 300,\n",
    "    \"max_depth\": 15,\n",
    "    \"min_samples_split\": 10,\n",
    "    \"min_samples_leaf\": 2,\n",
    "    \"ccp_alpha\": 0.002,\n",
    "}\n",
    "\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [\n",
    "        best_params[\"n_estimators\"] - 100,\n",
    "        best_params[\"n_estimators\"],\n",
    "        best_params[\"n_estimators\"] + 100,\n",
    "    ],\n",
    "    \"max_depth\": [\n",
    "        best_params[\"max_depth\"] - 5,\n",
    "        best_params[\"max_depth\"],\n",
    "        best_params[\"max_depth\"] + 5,\n",
    "    ],\n",
    "    \"min_samples_split\": [\n",
    "        best_params[\"min_samples_split\"] - 5,\n",
    "        best_params[\"min_samples_split\"],\n",
    "        best_params[\"min_samples_split\"] + 5,\n",
    "    ],\n",
    "    \"min_samples_leaf\": [\n",
    "        best_params[\"min_samples_leaf\"],\n",
    "        best_params[\"min_samples_leaf\"] + 1,\n",
    "    ],\n",
    "    \"ccp_alpha\": [\n",
    "        best_params[\"ccp_alpha\"],\n",
    "        best_params[\"ccp_alpha\"] + 0.001,\n",
    "        best_params[\"ccp_alpha\"] + 0.002,\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.002, 'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 15, 'n_estimators': 400}\n",
    "-   Best Score after Refining: 0.91606\n",
    "-   The trend for n_estimators is, bigger is better (until some point). So in next iteration we will ignore this parameter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My colleague found different parameters to be better, so we will look at them in this step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [\n",
    "        200\n",
    "    ],\n",
    "    \"max_depth\": [\n",
    "        15\n",
    "    ],\n",
    "    \"min_samples_split\": [\n",
    "        5,10\n",
    "    ],\n",
    "    \"min_samples_leaf\": [\n",
    "        1,2\n",
    "    ],\n",
    "    \"ccp_alpha\": [\n",
    "        0.001, 0.002\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.001, 'max_depth': 15, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 200}\n",
    "-   Best Score after Refining: 0.91596\n",
    "-   From these observations:\n",
    "    -   We can conclude that max_depth=~15 is the best, as it was 15 in every iteration.\n",
    "    -   We can conclude that ccp_alpha=~0.001 or cpp_alpha=~0.002 is the best.\n",
    "    -   We can conclude that min_samples_leaf=~1 or a little higher is the best.\n",
    "    -   We can conclude that min_samples_split=~10 is the best.\n",
    "    -   We can conclude that higher n_estimators is better (at some value it will be worse).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at cpp_alpha and max_depth in more detail.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [14, 15, 16],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"ccp_alpha\": [0.0095, 0.01, 0.0105],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   cpp_alpha=0.001 is best\n",
    "-   max_depth=15 is best\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at best n_estimators.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],\n",
    "    \"max_depth\": [15],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"ccp_alpha\": [0.001],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   n_estimators=300 is best.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final iteration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As discussed earlier, we will also look at max_features and criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [15],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [1],\n",
    "    \"ccp_alpha\": [0.001],\n",
    "    \"max_features\": [\"sqrt\", \"log2\"],\n",
    "    \"criterion\": [\"entropy\", \"gini\"],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.001, 'criterion': 'gini', 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
    "-   Best Score after Refining: 0.91632\n",
    "-   We can see that max_features=sqrt and criterion=gini are best and they are also default values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final parameters are:\n",
    "\n",
    "-   n_estimators=300\n",
    "-   max_depth=15\n",
    "-   min_samples_split=10\n",
    "-   min_samples_leaf=1\n",
    "-   ccp_alpha=0.001\n",
    "-   max_features=\"sqrt\"\n",
    "-   criterion=\"gini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To note we did these test without having feature selection in pipeline as we were getting better result without it. (Will be discussed further in 3.4)\n",
    "\n",
    "Since we discovered that it is best practise to always use feature selection, we will use it it next step and look if parameters change.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the refined parameter grid for GridSearchCV\n",
    "param_grid_refined = {\n",
    "    \"n_estimators\": [300],\n",
    "    \"max_depth\": [10, 15],\n",
    "    \"min_samples_split\": [5, 10],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"ccp_alpha\": [0.001, 0.0015],\n",
    "}\n",
    "\n",
    "# Initialize the RandomForestClassifier with the best parameters from RandomizedSearchCV\n",
    "rf_refined = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search_refined = GridSearchCV(\n",
    "    estimator=rf_refined,\n",
    "    param_grid=param_grid_refined,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    cv=10,  # 10-fold cross-validation for more reliable results\n",
    "    scoring=\"roc_auc\",\n",
    ")\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params_refined = grid_search_refined.best_params_\n",
    "best_score_refined = grid_search_refined.best_score_\n",
    "\n",
    "print(f\"Best Parameters after Refining: {best_params_refined}\")\n",
    "print(f\"Best Score after Refining: {best_score_refined:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters after Refining: {'ccp_alpha': 0.001, 'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
    "-   Best Score after Refining: 0.91591\n",
    "-   Best score without feature selection was 0.91632 vs 0.91591 with feature selection.\n",
    "-   As hinted before, using feature selection gives slightly worse results. But we will look at it in more detail in 3.4.\n",
    "-   We can also see that parameters did change and therefore it is always crucial to try different parameters when changing pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our final parameters with feature selection are:\n",
    "\n",
    "-   n_estimators=300\n",
    "-   max_depth=10\n",
    "-   min_samples_split=5\n",
    "-   min_samples_leaf=1\n",
    "-   ccp_alpha=0.001\n",
    "-   max_features=\"sqrt\"\n",
    "-   criterion=\"gini\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV - Logistic Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Let's also look at Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "log_reg = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "\n",
    "parameters = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05],\n",
    "    \"max_iter\": [100, 150, 200, 250, 300],\n",
    "    \"tol\": [0.0001, 0.0005, 0.001, 0.005],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    log_reg,\n",
    "    param_grid=parameters,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.0005}\n",
    "-   Best Score: 0.91217\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "log_reg = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "\n",
    "parameters = {\n",
    "    \"penalty\": [\"l1\", \"l2\"],\n",
    "    \"C\": [0.001, 0.005, 0.01, 0.05],\n",
    "    \"max_iter\": [100, 150, 200, 250, 300],\n",
    "    \"tol\": [0.0001, 0.0005, 0.001, 0.005],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    log_reg,\n",
    "    param_grid=parameters,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    "    cv=10,\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', 'tol': 0.001}\n",
    "-   Best Score: 0.91243\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(C=0.01, max_iter=100, penalty=\"l2\", solver=\"lbfgs\", tol=0.001, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "df_1 = get_scores(log_reg, \"LogisticRegression - lbfgs\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "log_reg = LogisticRegression(C=0.01, max_iter=100, penalty=\"l1\", solver=\"liblinear\", tol=0.001, random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "df_2 = get_scores(log_reg, \"LogisticRegression - liblinear\", X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Concatenate the DataFrames\n",
    "df = pd.concat([df_1, df_2], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'C': 0.01, 'max_iter': 100, 'penalty': 'l2', solver=\"lbfgs\",'tol': 0.001}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyskúšajte kombinácie modelov (ensemble) pre zvolený algoritmus tak, aby ste\n",
    "optimalizovali výkonnosť (bez underfitingu).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already used RandomForestClassifier in previous step, but we will now explore more ensemble methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Ensemble Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(\n",
    "    **rf_best_params,\n",
    ")\n",
    "\n",
    "# Print the scores\n",
    "df_rf = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "df_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Print the scores\n",
    "df_gb = get_scores_cv(gb_classifier, \"GradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb_classifier = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Print the scores\n",
    "df_hgb = get_scores_cv(hgb_classifier, \"HistGradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "df_hgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rf, df_gb, df_hgb], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can see that RandomForestClassifier is the best model for our data as we used hyperparameter tuning on it.\n",
    "-   HistGradientBoostingClassifier shows promising results but overfits more than RandomForestClassifier or GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    \"n_estimators\": [100, 200, 300],\n",
    "    \"learning_rate\": [0.01, 0.1, 0.2],\n",
    "    \"max_depth\": [3, 4, 5],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"subsample\": [0.8, 0.9, 1.0],\n",
    "}\n",
    "\n",
    "# Initialize the GradientBoostingClassifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=gb_classifier,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=-1,\n",
    "    scoring=\"roc_auc\", # ROC_AUC for lowering overfitting\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters and best score\n",
    "best_params = random_search.best_params_\n",
    "best_score = random_search.best_score_\n",
    "\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "print(f\"Best Score: {best_score:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best Parameters: {'subsample': 0.8, 'n_estimators': 100, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': 4, 'learning_rate': 0.01}\n",
    "-   Best Score: 0.91491\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb_classifier = GradientBoostingClassifier(**gbg_best_params)\n",
    "\n",
    "df_gb = get_scores_cv(gb_classifier, \"GradientBoostingClassifier\", X_train, y_train, X_test, y_test)\n",
    "df_gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter tuning for HistGradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ignore\n",
    "# Parameter grid\n",
    "param_grid = {\n",
    "    \"learning_rate\": [0.01, 0.1, 0.3],\n",
    "    \"max_depth\": [3, 5, 7],\n",
    "    \"max_iter\": [100, 200],\n",
    "    \"min_samples_leaf\": [20, 50],\n",
    "    \"l2_regularization\": [0, 1.0, 2.0],\n",
    "}\n",
    "\n",
    "# Base classifier\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "\n",
    "# Grid search with 5-fold CV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=hgb,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"roc_auc\", # ROC_AUC for lowering overfitting\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "# Assuming X and y are your features and target\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get best parameters and score\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation score:\", grid_search.best_score_)\n",
    "\n",
    "# Create optimized model with best parameters\n",
    "best_model = HistGradientBoostingClassifier(**grid_search.best_params_, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Best parameters: {'l2_regularization': 0, 'learning_rate': 0.01, 'max_depth': 5, 'max_iter': 200, 'min_samples_leaf': 20}\n",
    "-   Best cross-validation score: 0.9132202050166413\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgb = HistGradientBoostingClassifier(\n",
    "    l2_regularization=0, learning_rate=0.01, max_depth=5, max_iter=200, min_samples_leaf=20, random_state=42\n",
    ")\n",
    "\n",
    "df_hgb = get_scores_cv(hgb, \"HistGradientBoostingClassifier - Refined\", X_train, y_train, cv=5)\n",
    "df_hgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rf, df_gb, df_hgb], axis=1)\n",
    "del df_rf, df_gb, df_hgb\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can see that RandomForestClassifier is still the best model.\n",
    "-   Using roc_auc for scoring in GridSearchCV we lover the overfitting of HistGradientBoostingClassifier but it is still worse than RandomForestClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparisson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "gb_classifier = GradientBoostingClassifier(**gbg_best_params)\n",
    "hbg_classifier = HistGradientBoostingClassifier(**hbg_best_params)\n",
    "\n",
    "df_rf = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "df_gb = get_scores_cv(gb_classifier, \"GradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "df_hgb = get_scores_cv(hbg_classifier, \"HistGradientBoostingClassifier\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_rf, df_gb, df_hgb], axis=1)\n",
    "del df_rf, df_gb, df_hgb\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First best accuracy has RandomForestClassifier then HistGradientBoostingClassifier and last GradientBoostingClassifier.\n",
    "-   Then best F1 score has RandomForestClassifier then HistGradientBoostingClassifier and last GradientBoostingClassifier.\n",
    "-   For Roc_Auc score, RandomForestClassifier is the best model, then GradientBoostingClassifier and last HistGradientBoostingClassifier.\n",
    "-   For overfitting, no model is overfitting greatly, but HistGradientBoostingClassifier still has biggest overfit out of three models.\n",
    "-   Because of this we are going to use GradientBoostingClassifier over HistGradientBoostingClassifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting & Stacikng Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Random Forest\n",
      "\n",
      "Evaluating Logistic Regression\n",
      "\n",
      "Evaluating Gradient Boosting\n",
      "\n",
      "Evaluating Voting Ensemble\n",
      "\n",
      "Evaluating Stacking Ensemble\n"
     ]
    },
    {
     "ename": "NotFittedError",
     "evalue": "This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[188], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([df, df_tmp], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     33\u001b[0m df\n\u001b[1;32m---> 35\u001b[0m df_rf \u001b[38;5;241m=\u001b[39m \u001b[43mget_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrf_classifier\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRandomForestClassifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m df_voting \u001b[38;5;241m=\u001b[39m get_scores(voting_clf, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mVotingClassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m, X_train, y_train, X_test, y_test)\n",
      "Cell \u001b[1;32mIn[53], line 2\u001b[0m, in \u001b[0;36mget_scores\u001b[1;34m(model, model_name, X_train, y_train, X_test, y_test)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_scores\u001b[39m(model, model_name, X_train, y_train, X_test, y_test):\n\u001b[1;32m----> 2\u001b[0m     y_pred_train \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     y_pred_test \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m      5\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\n\u001b[0;32m      6\u001b[0m         index\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrecall\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1-score\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroc_auc\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m      7\u001b[0m         columns\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mMultiIndex\u001b[38;5;241m.\u001b[39mfrom_product([[model_name], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDifference\u001b[39m\u001b[38;5;124m\"\u001b[39m]]),\n\u001b[0;32m      8\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:904\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    884\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    885\u001b[0m \u001b[38;5;124;03m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    886\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    902\u001b[0m \u001b[38;5;124;03m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 904\u001b[0m     proba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_proba\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    906\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    907\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39margmax(proba, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:944\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict_proba\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m    923\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    924\u001b[0m \u001b[38;5;124;03m    Predict class probabilities for X.\u001b[39;00m\n\u001b[0;32m    925\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    942\u001b[0m \u001b[38;5;124;03m        classes corresponds to that in the attribute :term:`classes_`.\u001b[39;00m\n\u001b[0;32m    943\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 944\u001b[0m     \u001b[43mcheck_is_fitted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    945\u001b[0m     \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m    946\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_X_predict(X)\n",
      "File \u001b[1;32mc:\\Programming\\FIIT-STU\\Semester_5\\IAU\\IAU-Project\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1661\u001b[0m, in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m is not an estimator instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (estimator))\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_fitted(estimator, attributes, all_or_any):\n\u001b[1;32m-> 1661\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFittedError(msg \u001b[38;5;241m%\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mtype\u001b[39m(estimator)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m})\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This RandomForestClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# Define base models with different algorithms\n",
    "rf = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "lgr = LogisticRegression(**lgr_best_params)\n",
    "\n",
    "gbg = GradientBoostingClassifier(**gbg_best_params)\n",
    "\n",
    "# Create voting ensemble with different algorithms\n",
    "voting_clf = VotingClassifier(estimators=[(\"rf\", rf), (\"lgr\", lgr), (\"gbg\", gbg)], n_jobs=-1, voting=\"soft\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[(\"rf\", rf), (\"lgr\", lgr), (\"gbg\", gbg)],\n",
    "    final_estimator=LogisticRegression(random_state=42),\n",
    "    n_jobs=-1,\n",
    "    cv=5,\n",
    ")\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Random Forest\": rf,\n",
    "    \"Logistic Regression\": lgr,\n",
    "    \"Gradient Boosting\": gbg,\n",
    "    \"Voting Ensemble\": voting_clf,\n",
    "    \"Stacking Ensemble\": stacking_clf,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    df_tmp = get_scores_cv(model, name, X_train, y_train, cv=5)\n",
    "    df = pd.concat([df, df_tmp], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Voting Classifier and Stacking Classifier performs similarly, but Stacking Classifier takes longer to run. Therefore we are going to compare only Voting Classifier with other models.\n",
    "-   Since Random Forest Classifier was best model until this point, it will be our primary model to compare against.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rf = get_scores_cv(rf_classifier, \"RandomForestClassifier\", X_train, y_train, cv=5)\n",
    "df_voting = get_scores_cv(voting_clf, \"VotingClassifier\", X_train, y_train, cv=5)\n",
    "\n",
    "df = pd.concat([df_rf, df_voting], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_rf, df_voting], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Random Forest Classifier is still the best model across all metrics.\n",
    "-   The only thing VotingClassifier excels at is lower overfitting, but it is very small difference, therefore negligible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking at second VotingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Random Forest\n",
      "\n",
      "Evaluating Voting Ensemble\n",
      "\n",
      "Evaluating Voting Ensemble 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Random Forest</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Voting Ensemble</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Voting Ensemble 2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919348</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.91737</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.917898</td>\n",
       "      <td>0.000625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922232</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.920579</td>\n",
       "      <td>0.000659</td>\n",
       "      <td>0.920106</td>\n",
       "      <td>0.000511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.951556</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.953049</td>\n",
       "      <td>0.001003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.937336</td>\n",
       "      <td>0.000661</td>\n",
       "      <td>0.93581</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.936288</td>\n",
       "      <td>0.000504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.92971</td>\n",
       "      <td>0.000956</td>\n",
       "      <td>0.920414</td>\n",
       "      <td>0.000912</td>\n",
       "      <td>0.929229</td>\n",
       "      <td>0.000797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.915501</td>\n",
       "      <td>0.002895</td>\n",
       "      <td>0.914094</td>\n",
       "      <td>0.003063</td>\n",
       "      <td>0.914006</td>\n",
       "      <td>0.002717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.919453</td>\n",
       "      <td>0.002379</td>\n",
       "      <td>0.917602</td>\n",
       "      <td>0.003484</td>\n",
       "      <td>0.916682</td>\n",
       "      <td>0.001516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.949715</td>\n",
       "      <td>0.004295</td>\n",
       "      <td>0.949576</td>\n",
       "      <td>0.00449</td>\n",
       "      <td>0.950549</td>\n",
       "      <td>0.004678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.934332</td>\n",
       "      <td>0.002323</td>\n",
       "      <td>0.933305</td>\n",
       "      <td>0.002402</td>\n",
       "      <td>0.933301</td>\n",
       "      <td>0.002241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.915743</td>\n",
       "      <td>0.004327</td>\n",
       "      <td>0.914412</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.915455</td>\n",
       "      <td>0.004015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003507</td>\n",
       "      <td>0.003276</td>\n",
       "      <td>0.00349</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>0.003318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002977</td>\n",
       "      <td>0.004097</td>\n",
       "      <td>0.003424</td>\n",
       "      <td>0.001942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.00323</td>\n",
       "      <td>0.005333</td>\n",
       "      <td>0.001979</td>\n",
       "      <td>0.005257</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.005642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.002506</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.002987</td>\n",
       "      <td>0.002729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.00521</td>\n",
       "      <td>0.006003</td>\n",
       "      <td>0.00377</td>\n",
       "      <td>0.013774</td>\n",
       "      <td>0.00473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Random Forest           Voting Ensemble            \\\n",
       "                              Mean       Std            Mean       Std   \n",
       "Train      accuracy       0.919348  0.000809         0.91737  0.000485   \n",
       "           precision      0.922232  0.000474        0.920579  0.000659   \n",
       "           recall         0.952945  0.001311        0.951556  0.000821   \n",
       "           f1             0.937336  0.000661         0.93581  0.000379   \n",
       "           roc_auc         0.92971  0.000956        0.920414  0.000912   \n",
       "Test       accuracy       0.915501  0.002895        0.914094  0.003063   \n",
       "           precision      0.919453  0.002379        0.917602  0.003484   \n",
       "           recall         0.949715  0.004295        0.949576   0.00449   \n",
       "           f1             0.934332  0.002323        0.933305  0.002402   \n",
       "           roc_auc        0.915743  0.004327        0.914412  0.002868   \n",
       "Difference accuracy       0.003847  0.003507        0.003276   0.00349   \n",
       "           precision      0.002779  0.002814        0.002977  0.004097   \n",
       "           recall          0.00323  0.005333        0.001979  0.005257   \n",
       "           f1             0.003004  0.002821        0.002506  0.002736   \n",
       "           roc_auc        0.013967   0.00521        0.006003   0.00377   \n",
       "\n",
       "                     Voting Ensemble 2            \n",
       "                                  Mean       Std  \n",
       "Train      accuracy           0.917898  0.000625  \n",
       "           precision          0.920106  0.000511  \n",
       "           recall             0.953049  0.001003  \n",
       "           f1                 0.936288  0.000504  \n",
       "           roc_auc            0.929229  0.000797  \n",
       "Test       accuracy           0.914006  0.002717  \n",
       "           precision          0.916682  0.001516  \n",
       "           recall             0.950549  0.004678  \n",
       "           f1                 0.933301  0.002241  \n",
       "           roc_auc            0.915455  0.004015  \n",
       "Difference accuracy           0.003891  0.003318  \n",
       "           precision          0.003424  0.001942  \n",
       "           recall               0.0025  0.005642  \n",
       "           f1                 0.002987  0.002729  \n",
       "           roc_auc            0.013774   0.00473  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define base models with different algorithms\n",
    "rf = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "lgr = LogisticRegression(**lgr_best_params)\n",
    "\n",
    "gbg = GradientBoostingClassifier(**gbg_best_params)\n",
    "\n",
    "# Create voting ensemble with different algorithms\n",
    "voting_clf = VotingClassifier(estimators=[(\"rf\", rf), (\"lgr\", lgr), (\"gbg\", gbg)], n_jobs=-1, voting=\"soft\")\n",
    "\n",
    "# Create stacking ensemble\n",
    "voting_clf_2 = VotingClassifier(estimators=[(\"rf\", rf), (\"gbg\", gbg)], n_jobs=-1, voting=\"soft\")\n",
    "\n",
    "# Evaluate all models\n",
    "models = {\n",
    "    \"Random Forest\": rf,\n",
    "    \"Voting Ensemble\": voting_clf,\n",
    "    \"Voting Ensemble 2\": voting_clf_2,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}\")\n",
    "    df_tmp = get_scores_cv(model, name, X_train, y_train, cv=5)\n",
    "    df = pd.concat([df, df_tmp], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Využite krížovú validáciu (cross validation) na trénovacej množine.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We were already using cross validation in previous steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokážte že Váš nastavený najlepší model je bez overfitingu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models with different algorithms\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "df = get_scores(rf_classifier, \"RandomForestClassifier\", X_train, y_train, X_test, y_test)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Since train metrics and test metrics are close, the model is not overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base models with different algorithms\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for train data\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train, rf_classifier.predict_proba(X_train)[:, 1])\n",
    "roc_auc_train = auc(fpr_train, tpr_train)\n",
    "\n",
    "# Compute ROC curve and ROC area for test data\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, rf_classifier.predict_proba(X_test)[:, 1])\n",
    "roc_auc_test = auc(fpr_test, tpr_test)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr_train, tpr_train, color=\"blue\", lw=2, label=f\"Train ROC curve (area = {roc_auc_train:.5f})\")\n",
    "plt.plot(fpr_test, tpr_test, color=\"red\", lw=2, label=f\"Test ROC curve (area = {roc_auc_test:.5f})\")\n",
    "plt.plot([0, 1], [0, 1], color=\"gray\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Receiver Operating Characteristic (ROC) Curve\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can also see stable ROC curve for train and test data, so we can conclude that model is not overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vyhodnotenie vplyvu zvolenej stratégie riešenia na klasifikáciu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratégie riešenia chýbajúcich hodnôt a outlierov.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_raw():\n",
    "    file_path: str = \"../data/raw\"\n",
    "    files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "    dataset: dict[str, pd.DataFrame] = {}\n",
    "    for file in files:\n",
    "        dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")\n",
    "        dataset[file] = dataset[file].drop_duplicates()\n",
    "\n",
    "    df = pd.merge(dataset[\"connections\"], dataset[\"processes\"], on=[\"imei\", \"ts\", \"mwra\"])\n",
    "    df[\"ts\"] = pd.to_datetime(df.ts)\n",
    "\n",
    "    train_data, test_data = train_test_split(df, test_size=0.2, random_state=42)\n",
    "    train_data = train_data.reset_index(drop=True)\n",
    "    test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "    return train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Define columns\n",
    "all_columns = train_data.drop(columns=[\"mwra\", \"ts\", \"imei\"]).columns\n",
    "non_gaussian_columns = [\n",
    "    \"c.android.vending\",\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "    \"p.android.vending\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.olauncher\",\n",
    "    \"p.simulator\",\n",
    "    \"p.inputmethod.latin\",\n",
    "    \"p.android.gms\",\n",
    "    \"p.notifier\",\n",
    "    \"p.katana\",\n",
    "    \"p.gms.persistent\",\n",
    "]\n",
    "gaussian_columns = all_columns[~all_columns.isin(non_gaussian_columns)]\n",
    "transformed_feature_order = pd.Series(gaussian_columns.tolist() + non_gaussian_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(data, columns):\n",
    "    Q1 = data[columns].quantile(0.25)\n",
    "    Q3 = data[columns].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return data[(data[columns] >= lower_bound).all(axis=1) & (data[columns] <= upper_bound).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_pipe = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "vending_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"quantile_transformer\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"general\", general_pipe, gaussian_columns),\n",
    "        (\"vending\", vending_pipeline, non_gaussian_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "# Create complete pipeline\n",
    "complete_pipeline = Pipeline([(\"preprocessor\", preprocessor), (\"selector\", SelectKBest(f_classif, k=10))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_outliers = pd.DataFrame(\n",
    "    index=[\"Number of Outliers\", \"Percentage of Outliers\"],\n",
    "    columns=[\"None-iterative IQR\", \"Iterative IQR\", \"None-iterative Z-score\", \"Iterative Z-score\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning methods\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 2767\n",
      "Percentage of rows removed: 23.17%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Get number of rows before removing outliers\n",
    "number_of_rows_before_outliers = train_data.shape[0]\n",
    "\n",
    "# Remove outliers using IQR method\n",
    "train_data = remove_outliers_iqr(train_data, train_data.iloc[:, 3:].columns)\n",
    "\n",
    "# Reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# Print number of outliers removed\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of rows removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "\n",
    "# Save number of outliers removed\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"None-iterative IQR\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"None-iterative IQR\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export cleaned data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_1iqr.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_1iqr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative IQR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 2934\n",
      "Percentage of outliers removed: 24.57%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Get number of rows before removing outliers\n",
    "number_of_rows_before_outliers = train_data.shape[0]\n",
    "\n",
    "# Define columns for IQR\n",
    "columns_for_iqr = train_data.iloc[:, 3:].columns.difference([\"p.android.vending\"])\n",
    "\n",
    "# Remove outliers using IQR method (in all columns)\n",
    "train_data = remove_outliers_iqr(train_data, train_data.iloc[:, 3:].columns)\n",
    "\n",
    "# Get number of outliers removed in next iteration\n",
    "outliers_count = (\n",
    "    ~(\n",
    "        (\n",
    "            train_data[columns_for_iqr]\n",
    "            >= train_data[columns_for_iqr].quantile(0.25)\n",
    "            - 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "        )\n",
    "        & (\n",
    "            train_data[columns_for_iqr]\n",
    "            <= train_data[columns_for_iqr].quantile(0.75)\n",
    "            + 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "        )\n",
    "    ).all(axis=1)\n",
    ").sum()\n",
    "\n",
    "# Define maximum number of iterations\n",
    "max_iterations = 10\n",
    "iteration = 0\n",
    "\n",
    "# Remove outliers iteratively\n",
    "while outliers_count > 0:\n",
    "    # Remove outliers using IQR method (in all columns except p.android.vending)\n",
    "    train_data = remove_outliers_iqr(train_data, columns_for_iqr)\n",
    "\n",
    "    # Get number of outliers removed in next iteration\n",
    "    outliers_count = (\n",
    "        ~(\n",
    "            (\n",
    "                train_data[columns_for_iqr]\n",
    "                >= train_data[columns_for_iqr].quantile(0.25)\n",
    "                - 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "            )\n",
    "            & (\n",
    "                train_data[columns_for_iqr]\n",
    "                <= train_data[columns_for_iqr].quantile(0.75)\n",
    "                + 1.5 * (train_data[columns_for_iqr].quantile(0.75) - train_data[columns_for_iqr].quantile(0.25))\n",
    "            )\n",
    "        ).all(axis=1)\n",
    "    ).sum()\n",
    "\n",
    "    # Increment iteration and stop if maximum number of iterations reached\n",
    "    iteration += 1\n",
    "    if iteration >= max_iterations:\n",
    "        break\n",
    "\n",
    "# Reset index\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "# Print number of outliers removed\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of outliers removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "\n",
    "# Save number of outliers removed\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"Iterative IQR\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"Iterative IQR\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_itiqr.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_itiqr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative Z-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 477\n",
      "Percentage of outliers removed: 3.99%\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Get number of rows before removing outliers\n",
    "number_of_rows_before_outliers = train_data.shape[0]\n",
    "\n",
    "# Remove outliers using Z-score method\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of outliers removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"None-iterative Z-score\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"None-iterative Z-score\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_1zscore.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_1zscore.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Z-score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of outliers removed: 570\n",
      "Percentage of outliers removed: 4.77%\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# 1 iteration of cleaning whole dataset of outliers (including p.android.vending)\n",
    "train_data = train_data[(np.abs(zscore(train_data.iloc[:, 3:])) < 3).all(axis=1)]\n",
    "\n",
    "# Using all columns except c.android.vending for outlier detection\n",
    "columns_for_zscore = train_data.iloc[:, 3:].columns.difference([\"p.android.vending\"])\n",
    "outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "max_iterations = 10\n",
    "iteration = 0\n",
    "\n",
    "# Iterating after we removed all outliers\n",
    "while outliers_count > 0:\n",
    "    train_data = train_data[(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)]\n",
    "    outliers_count = (~(np.abs(zscore(train_data[columns_for_zscore])) < 3).all(axis=1)).sum()\n",
    "    iteration += 1\n",
    "    if iteration >= max_iterations:\n",
    "        break\n",
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "\n",
    "print(f\"Number of outliers removed: {number_of_rows_before_outliers - train_data.shape[0]}\")\n",
    "print(\n",
    "    f\"Percentage of outliers removed: {((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100:.2f}%\"\n",
    ")\n",
    "number_of_outliers.loc[\"Number of Outliers\", \"Iterative Z-score\"] = (\n",
    "    number_of_rows_before_outliers - train_data.shape[0]\n",
    ")\n",
    "number_of_outliers.loc[\"Percentage of Outliers\", \"Iterative Z-score\"] = round(\n",
    "    ((number_of_rows_before_outliers - train_data.shape[0]) / number_of_rows_before_outliers) * 100, 2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Use pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Export processed data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"../data/clean_methods\", exist_ok=True)\n",
    "\n",
    "train_data_processed.to_csv(\"../data/clean_methods/train_itzscore.csv\", index=False)\n",
    "test_data_processed.to_csv(\"../data/clean_methods/test_itzscore.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>None-iterative IQR</th>\n",
       "      <th>Iterative IQR</th>\n",
       "      <th>None-iterative Z-score</th>\n",
       "      <th>Iterative Z-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of Outliers</th>\n",
       "      <td>2767</td>\n",
       "      <td>2934</td>\n",
       "      <td>477</td>\n",
       "      <td>570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Percentage of Outliers</th>\n",
       "      <td>23.17</td>\n",
       "      <td>24.57</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       None-iterative IQR Iterative IQR  \\\n",
       "Number of Outliers                   2767          2934   \n",
       "Percentage of Outliers              23.17         24.57   \n",
       "\n",
       "                       None-iterative Z-score Iterative Z-score  \n",
       "Number of Outliers                        477               570  \n",
       "Percentage of Outliers                   3.99              4.77  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using on Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not Deleting outliers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, test_data = load_data_raw()\n",
    "\n",
    "# Fit and transform training data, transform test data\n",
    "train_data_processed = complete_pipeline.fit_transform(train_data[all_columns], train_data[\"mwra\"])\n",
    "test_data_processed = complete_pipeline.transform(test_data[all_columns])\n",
    "\n",
    "# Get selected features immediately after fitting\n",
    "feature_mask = complete_pipeline.named_steps[\"selector\"].get_support()\n",
    "selected_features = transformed_feature_order[feature_mask]  # order of features is preserved\n",
    "\n",
    "# Create DataFrames with selected feature names\n",
    "train_data_processed = pd.DataFrame(train_data_processed, columns=selected_features)\n",
    "test_data_processed = pd.DataFrame(test_data_processed, columns=selected_features)\n",
    "\n",
    "train_data_processed[\"mwra\"] = train_data[\"mwra\"]\n",
    "test_data_processed[\"mwra\"] = test_data[\"mwra\"]\n",
    "\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - None</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.918551</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.921994</td>\n",
       "      <td>0.000484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.000878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.935943</td>\n",
       "      <td>0.000544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.929811</td>\n",
       "      <td>0.001102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.91451</td>\n",
       "      <td>0.002263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.919892</td>\n",
       "      <td>0.002462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.002809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.932682</td>\n",
       "      <td>0.001794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.916022</td>\n",
       "      <td>0.004215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.00404</td>\n",
       "      <td>0.002463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.002721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.003372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.001965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.005279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RandomForestClassifier - None          \n",
       "                                              Mean       Std\n",
       "Train      accuracy                       0.918551  0.000674\n",
       "           precision                      0.921994  0.000484\n",
       "           recall                         0.950321  0.000878\n",
       "           f1                             0.935943  0.000544\n",
       "           roc_auc                        0.929811  0.001102\n",
       "Test       accuracy                        0.91451  0.002263\n",
       "           precision                      0.919892  0.002462\n",
       "           recall                         0.945841  0.002809\n",
       "           f1                             0.932682  0.001794\n",
       "           roc_auc                        0.916022  0.004215\n",
       "Difference accuracy                        0.00404  0.002463\n",
       "           precision                      0.002102  0.002721\n",
       "           recall                          0.00448  0.003372\n",
       "           f1                             0.003261  0.001965\n",
       "           roc_auc                         0.01379  0.005279"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "df_none = get_scores_cv(rf_classifier, \"None\", X_train, y_train, cv=5)\n",
    "df_none"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_1iqr.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_1iqr.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - 1IQR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.922434</td>\n",
       "      <td>0.000418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923368</td>\n",
       "      <td>0.00061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.956935</td>\n",
       "      <td>0.000982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.000345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.93617</td>\n",
       "      <td>0.000791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.003009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.003336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.954914</td>\n",
       "      <td>0.0043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.937884</td>\n",
       "      <td>0.002369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.916354</td>\n",
       "      <td>0.003951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.003933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.005175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.004361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RandomForestClassifier - 1IQR          \n",
       "                                              Mean       Std\n",
       "Train      accuracy                       0.922434  0.000418\n",
       "           precision                      0.923368   0.00061\n",
       "           recall                         0.956935  0.000982\n",
       "           f1                             0.939852  0.000345\n",
       "           roc_auc                         0.93617  0.000791\n",
       "Test       accuracy                         0.9199  0.003009\n",
       "           precision                      0.921469  0.003336\n",
       "           recall                         0.954914    0.0043\n",
       "           f1                             0.937884  0.002369\n",
       "           roc_auc                        0.916354  0.003951\n",
       "Difference accuracy                       0.002534  0.003377\n",
       "           precision                      0.001899  0.003933\n",
       "           recall                         0.002022  0.005175\n",
       "           f1                             0.001968  0.002666\n",
       "           roc_auc                        0.019817  0.004361"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_1iqr = get_scores_cv(rf_classifier, \"1IQR\", X_train, y_train, cv=5)\n",
    "df_1iqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative IQR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_itiqr.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_itiqr.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - ITIQR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.922799</td>\n",
       "      <td>0.000592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.000618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.000978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.940632</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.935692</td>\n",
       "      <td>0.001433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.920191</td>\n",
       "      <td>0.003622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.921835</td>\n",
       "      <td>0.002945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.955984</td>\n",
       "      <td>0.005357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.938589</td>\n",
       "      <td>0.002898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.914908</td>\n",
       "      <td>0.005026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.004205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.006266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.003362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.006367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RandomForestClassifier - ITIQR          \n",
       "                                               Mean       Std\n",
       "Train      accuracy                        0.922799  0.000592\n",
       "           precision                       0.923371  0.000618\n",
       "           recall                          0.958551  0.000978\n",
       "           f1                              0.940632  0.000474\n",
       "           roc_auc                         0.935692  0.001433\n",
       "Test       accuracy                        0.920191  0.003622\n",
       "           precision                       0.921835  0.002945\n",
       "           recall                          0.955984  0.005357\n",
       "           f1                              0.938589  0.002898\n",
       "           roc_auc                         0.914908  0.005026\n",
       "Difference accuracy                        0.002609  0.004205\n",
       "           precision                       0.001536  0.003549\n",
       "           recall                          0.002567  0.006266\n",
       "           f1                              0.002043  0.003362\n",
       "           roc_auc                         0.020784  0.006367"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_itiqr = get_scores_cv(rf_classifier, \"ITIQR\", X_train, y_train, cv=5)\n",
    "df_itiqr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### None-iterative Z-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_1zscore.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_1zscore.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - 1ZSCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919349</td>\n",
       "      <td>0.000706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922212</td>\n",
       "      <td>0.00052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.952414</td>\n",
       "      <td>0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.937069</td>\n",
       "      <td>0.000572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.93025</td>\n",
       "      <td>0.000772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.915315</td>\n",
       "      <td>0.003237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.919554</td>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.948679</td>\n",
       "      <td>0.003944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.933885</td>\n",
       "      <td>0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.915958</td>\n",
       "      <td>0.003882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.003648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.004616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.004521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RandomForestClassifier - 1ZSCORE          \n",
       "                                                 Mean       Std\n",
       "Train      accuracy                          0.919349  0.000706\n",
       "           precision                         0.922212   0.00052\n",
       "           recall                            0.952414  0.001061\n",
       "           f1                                0.937069  0.000572\n",
       "           roc_auc                            0.93025  0.000772\n",
       "Test       accuracy                          0.915315  0.003237\n",
       "           precision                         0.919554  0.002536\n",
       "           recall                            0.948679  0.003944\n",
       "           f1                                0.933885  0.002577\n",
       "           roc_auc                           0.915958  0.003882\n",
       "Difference accuracy                          0.004034  0.003648\n",
       "           precision                         0.002658     0.003\n",
       "           recall                            0.003735  0.004616\n",
       "           f1                                0.003184  0.002904\n",
       "           roc_auc                           0.014291  0.004521"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_1zscore = get_scores_cv(rf_classifier, \"1ZSCORE\", X_train, y_train, cv=5)\n",
    "df_1zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterative Z-score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data_processed = pd.read_csv(\"../data/clean_methods/train_itzscore.csv\")\n",
    "test_data_processed = pd.read_csv(\"../data/clean_methods/test_itzscore.csv\")\n",
    "\n",
    "# Train data without feature selection\n",
    "X_train = train_data_processed.drop(columns=[\"mwra\"])\n",
    "y_train = train_data_processed[\"mwra\"]\n",
    "\n",
    "# Test data without feature selection\n",
    "X_test = test_data_processed.drop(columns=[\"mwra\"])\n",
    "y_test = test_data_processed[\"mwra\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - ITZSCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.919348</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.922232</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.937336</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.92971</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.915501</td>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.919453</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.949715</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.934332</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.915743</td>\n",
       "      <td>0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.00323</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.00521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RandomForestClassifier - ITZSCORE          \n",
       "                                                  Mean       Std\n",
       "Train      accuracy                           0.919348  0.000809\n",
       "           precision                          0.922232  0.000474\n",
       "           recall                             0.952945  0.001311\n",
       "           f1                                 0.937336  0.000661\n",
       "           roc_auc                             0.92971  0.000956\n",
       "Test       accuracy                           0.915501  0.002895\n",
       "           precision                          0.919453  0.002379\n",
       "           recall                             0.949715  0.004295\n",
       "           f1                                 0.934332  0.002323\n",
       "           roc_auc                            0.915743  0.004327\n",
       "Difference accuracy                           0.003847  0.003507\n",
       "           precision                          0.002779  0.002814\n",
       "           recall                              0.00323  0.005333\n",
       "           f1                                 0.003004  0.002821\n",
       "           roc_auc                            0.013967   0.00521"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the RandomForestClassifier\n",
    "rf_classifier = RandomForestClassifier(**rf_best_params)\n",
    "\n",
    "# Show the scores\n",
    "df_itzscore = get_scores_cv(rf_classifier, \"ITZSCORE\", X_train, y_train, cv=5)\n",
    "df_itzscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - None</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - 1IQR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - ITIQR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - 1ZSCORE</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RandomForestClassifier - ITZSCORE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Train</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.918551</td>\n",
       "      <td>0.000674</td>\n",
       "      <td>0.922434</td>\n",
       "      <td>0.000418</td>\n",
       "      <td>0.922799</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.919349</td>\n",
       "      <td>0.000706</td>\n",
       "      <td>0.919348</td>\n",
       "      <td>0.000809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.921994</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.923368</td>\n",
       "      <td>0.00061</td>\n",
       "      <td>0.923371</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.922212</td>\n",
       "      <td>0.00052</td>\n",
       "      <td>0.922232</td>\n",
       "      <td>0.000474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.950321</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.956935</td>\n",
       "      <td>0.000982</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.000978</td>\n",
       "      <td>0.952414</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.952945</td>\n",
       "      <td>0.001311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.935943</td>\n",
       "      <td>0.000544</td>\n",
       "      <td>0.939852</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.940632</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.937069</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.937336</td>\n",
       "      <td>0.000661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.929811</td>\n",
       "      <td>0.001102</td>\n",
       "      <td>0.93617</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>0.935692</td>\n",
       "      <td>0.001433</td>\n",
       "      <td>0.93025</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>0.92971</td>\n",
       "      <td>0.000956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Test</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.91451</td>\n",
       "      <td>0.002263</td>\n",
       "      <td>0.9199</td>\n",
       "      <td>0.003009</td>\n",
       "      <td>0.920191</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.915315</td>\n",
       "      <td>0.003237</td>\n",
       "      <td>0.915501</td>\n",
       "      <td>0.002895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.919892</td>\n",
       "      <td>0.002462</td>\n",
       "      <td>0.921469</td>\n",
       "      <td>0.003336</td>\n",
       "      <td>0.921835</td>\n",
       "      <td>0.002945</td>\n",
       "      <td>0.919554</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.919453</td>\n",
       "      <td>0.002379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.945841</td>\n",
       "      <td>0.002809</td>\n",
       "      <td>0.954914</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.955984</td>\n",
       "      <td>0.005357</td>\n",
       "      <td>0.948679</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.949715</td>\n",
       "      <td>0.004295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.932682</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>0.937884</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.938589</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.933885</td>\n",
       "      <td>0.002577</td>\n",
       "      <td>0.934332</td>\n",
       "      <td>0.002323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.916022</td>\n",
       "      <td>0.004215</td>\n",
       "      <td>0.916354</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.914908</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.915958</td>\n",
       "      <td>0.003882</td>\n",
       "      <td>0.915743</td>\n",
       "      <td>0.004327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Difference</th>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.00404</td>\n",
       "      <td>0.002463</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.003377</td>\n",
       "      <td>0.002609</td>\n",
       "      <td>0.004205</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>0.003847</td>\n",
       "      <td>0.003507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.001899</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.001536</td>\n",
       "      <td>0.003549</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.002779</td>\n",
       "      <td>0.002814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.00448</td>\n",
       "      <td>0.003372</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.006266</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.004616</td>\n",
       "      <td>0.00323</td>\n",
       "      <td>0.005333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1</th>\n",
       "      <td>0.003261</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.002666</td>\n",
       "      <td>0.002043</td>\n",
       "      <td>0.003362</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.002904</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roc_auc</th>\n",
       "      <td>0.01379</td>\n",
       "      <td>0.005279</td>\n",
       "      <td>0.019817</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>0.020784</td>\n",
       "      <td>0.006367</td>\n",
       "      <td>0.014291</td>\n",
       "      <td>0.004521</td>\n",
       "      <td>0.013967</td>\n",
       "      <td>0.00521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     RandomForestClassifier - None            \\\n",
       "                                              Mean       Std   \n",
       "Train      accuracy                       0.918551  0.000674   \n",
       "           precision                      0.921994  0.000484   \n",
       "           recall                         0.950321  0.000878   \n",
       "           f1                             0.935943  0.000544   \n",
       "           roc_auc                        0.929811  0.001102   \n",
       "Test       accuracy                        0.91451  0.002263   \n",
       "           precision                      0.919892  0.002462   \n",
       "           recall                         0.945841  0.002809   \n",
       "           f1                             0.932682  0.001794   \n",
       "           roc_auc                        0.916022  0.004215   \n",
       "Difference accuracy                        0.00404  0.002463   \n",
       "           precision                      0.002102  0.002721   \n",
       "           recall                          0.00448  0.003372   \n",
       "           f1                             0.003261  0.001965   \n",
       "           roc_auc                         0.01379  0.005279   \n",
       "\n",
       "                     RandomForestClassifier - 1IQR            \\\n",
       "                                              Mean       Std   \n",
       "Train      accuracy                       0.922434  0.000418   \n",
       "           precision                      0.923368   0.00061   \n",
       "           recall                         0.956935  0.000982   \n",
       "           f1                             0.939852  0.000345   \n",
       "           roc_auc                         0.93617  0.000791   \n",
       "Test       accuracy                         0.9199  0.003009   \n",
       "           precision                      0.921469  0.003336   \n",
       "           recall                         0.954914    0.0043   \n",
       "           f1                             0.937884  0.002369   \n",
       "           roc_auc                        0.916354  0.003951   \n",
       "Difference accuracy                       0.002534  0.003377   \n",
       "           precision                      0.001899  0.003933   \n",
       "           recall                         0.002022  0.005175   \n",
       "           f1                             0.001968  0.002666   \n",
       "           roc_auc                        0.019817  0.004361   \n",
       "\n",
       "                     RandomForestClassifier - ITIQR            \\\n",
       "                                               Mean       Std   \n",
       "Train      accuracy                        0.922799  0.000592   \n",
       "           precision                       0.923371  0.000618   \n",
       "           recall                          0.958551  0.000978   \n",
       "           f1                              0.940632  0.000474   \n",
       "           roc_auc                         0.935692  0.001433   \n",
       "Test       accuracy                        0.920191  0.003622   \n",
       "           precision                       0.921835  0.002945   \n",
       "           recall                          0.955984  0.005357   \n",
       "           f1                              0.938589  0.002898   \n",
       "           roc_auc                         0.914908  0.005026   \n",
       "Difference accuracy                        0.002609  0.004205   \n",
       "           precision                       0.001536  0.003549   \n",
       "           recall                          0.002567  0.006266   \n",
       "           f1                              0.002043  0.003362   \n",
       "           roc_auc                         0.020784  0.006367   \n",
       "\n",
       "                     RandomForestClassifier - 1ZSCORE            \\\n",
       "                                                 Mean       Std   \n",
       "Train      accuracy                          0.919349  0.000706   \n",
       "           precision                         0.922212   0.00052   \n",
       "           recall                            0.952414  0.001061   \n",
       "           f1                                0.937069  0.000572   \n",
       "           roc_auc                            0.93025  0.000772   \n",
       "Test       accuracy                          0.915315  0.003237   \n",
       "           precision                         0.919554  0.002536   \n",
       "           recall                            0.948679  0.003944   \n",
       "           f1                                0.933885  0.002577   \n",
       "           roc_auc                           0.915958  0.003882   \n",
       "Difference accuracy                          0.004034  0.003648   \n",
       "           precision                         0.002658     0.003   \n",
       "           recall                            0.003735  0.004616   \n",
       "           f1                                0.003184  0.002904   \n",
       "           roc_auc                           0.014291  0.004521   \n",
       "\n",
       "                     RandomForestClassifier - ITZSCORE            \n",
       "                                                  Mean       Std  \n",
       "Train      accuracy                           0.919348  0.000809  \n",
       "           precision                          0.922232  0.000474  \n",
       "           recall                             0.952945  0.001311  \n",
       "           f1                                 0.937336  0.000661  \n",
       "           roc_auc                             0.92971  0.000956  \n",
       "Test       accuracy                           0.915501  0.002895  \n",
       "           precision                          0.919453  0.002379  \n",
       "           recall                             0.949715  0.004295  \n",
       "           f1                                 0.934332  0.002323  \n",
       "           roc_auc                            0.915743  0.004327  \n",
       "Difference accuracy                           0.003847  0.003507  \n",
       "           precision                          0.002779  0.002814  \n",
       "           recall                              0.00323  0.005333  \n",
       "           f1                                 0.003004  0.002821  \n",
       "           roc_auc                            0.013967   0.00521  "
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_none, df_1iqr, df_itiqr, df_1zscore, df_itzscore], axis=1)\n",
    "del df_none, df_1iqr, df_itiqr, df_1zscore, df_itzscore\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dátová transformácia (scaling, transformer, ...).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_clean():\n",
    "    file_path: str = \"../data/clean_methods\"\n",
    "\n",
    "    # Load cleaned data (Iterative Z-score)\n",
    "    train_data = pd.read_csv(f\"{file_path}/train_itzscore.csv\")\n",
    "    test_data = pd.read_csv(f\"{file_path}/test_itzscore.csv\")\n",
    "\n",
    "    # Define train & test data\n",
    "    X_train = train_data.drop(columns=[\"mwra\"])\n",
    "    y_train = train_data[\"mwra\"]\n",
    "\n",
    "    X_test = test_data.drop(columns=[\"mwra\"])\n",
    "    y_test = test_data[\"mwra\"]\n",
    "\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define columns\n",
    "gaussian_columns = [\n",
    "    \"c.dogalize\",\n",
    "    \"c.android.gm\",\n",
    "    \"c.android.youtube\",\n",
    "    \"c.android.chrome\",\n",
    "    \"c.katana\",\n",
    "    \"c.raider\",\n",
    "    \"p.android.packageinstaller\",\n",
    "    \"p.android.settings\",\n",
    "    \"p.android.documentsui\",\n",
    "    \"p.android.chrome\",\n",
    "    \"p.android.gm\",\n",
    "    \"p.system\",\n",
    "    \"p.android.externalstorage\",\n",
    "    \"p.process.gapps\",\n",
    "    \"p.google\",\n",
    "    \"p.browser.provider\",\n",
    "    \"p.android.defcontainer\",\n",
    "]\n",
    "\n",
    "log_columns = [\"c.android.vending\"]\n",
    "\n",
    "uniform_columns = [\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "    \"p.android.vending\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.olauncher\",\n",
    "    \"p.simulator\",\n",
    "    \"p.inputmethod.latin\",\n",
    "    \"p.android.gms\",\n",
    "    \"p.notifier\",\n",
    "    \"p.katana\",\n",
    "    \"p.gms.persistent\",\n",
    "]\n",
    "\n",
    "\n",
    "transformed_feature_order = pd.Series(gaussian_columns + log_columns + uniform_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define different pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our pipeline from 2nd Phase\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaussian_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"power_transformer\", PowerTransformer(method=\"yeo-johnson\")),\n",
    "    ]\n",
    ")\n",
    "\n",
    "non_gaussian_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", RobustScaler()),\n",
    "        (\"quantile_transformer\", QuantileTransformer(output_distribution=\"normal\", random_state=42)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"general\", gaussian_pipeline, gaussian_columns),\n",
    "        (\"vending\", non_gaussian_pipeline, non_gaussian_columns),\n",
    "    ],\n",
    "    remainder=\"passthrough\",\n",
    ")\n",
    "\n",
    "robust_pipeline = Pipeline([(\"preprocessor\", preprocessor)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining other pipelines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline 1: Basic scaling\n",
    "basic_pipeline = Pipeline([(\"scaler\", StandardScaler())])\n",
    "\n",
    "# Pipeline 2: Robust scaling for outlier handling\n",
    "robust_pipeline = Pipeline([(\"scaler\", RobustScaler()), (\"power\", PowerTransformer(method=\"yeo-johnson\"))])\n",
    "\n",
    "# Pipeline 3: Quantile transformation\n",
    "quantile_pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"quantile\", QuantileTransformer(output_distribution=\"normal\", n_quantiles=1000)),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pipeline 4: Min-max scaling with power transform\n",
    "minmax_pipeline = Pipeline([(\"scaler\", MinMaxScaler()), (\"power\", PowerTransformer(method=\"yeo-johnson\"))])\n",
    "\n",
    "# Pipeline 5: Log transform for skewed data\n",
    "log_pipeline = Pipeline([(\"log\", FunctionTransformer(func=np.log1p)), (\"scaler\", StandardScaler())])\n",
    "\n",
    "\n",
    "# Create column transformers for different data types\n",
    "def create_full_pipeline(gaussian_pipe, uniform_pipe, log_pipe):\n",
    "    return ColumnTransformer(\n",
    "        [\n",
    "            (\"gaussian\", gaussian_pipe, gaussian_columns),\n",
    "            (\"uniform\", uniform_pipe, uniform_columns),\n",
    "            (\"log\", log_pipe, log_columns),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "# Create different combinations to test\n",
    "pipeline_combinations = [\n",
    "    # Combination 1: Basic scaling for all\n",
    "    create_full_pipeline(basic_pipeline, basic_pipeline, basic_pipeline),\n",
    "    # Combination 2: Robust handling\n",
    "    create_full_pipeline(robust_pipeline, robust_pipeline, robust_pipeline),\n",
    "    # Combination 3: Type-specific transforms\n",
    "    create_full_pipeline(basic_pipeline, quantile_pipeline, log_pipeline),\n",
    "    # Combination 4: Quantile for all\n",
    "    create_full_pipeline(quantile_pipeline, quantile_pipeline, quantile_pipeline),\n",
    "    # Combination 5: MinMax with power transforms\n",
    "    create_full_pipeline(minmax_pipeline, minmax_pipeline, minmax_pipeline),\n",
    "]\n",
    "\n",
    "\n",
    "# Function to evaluate pipeline performance\n",
    "def evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    train_score = pipeline.score(X_train, y_train)\n",
    "    test_score = pipeline.score(X_test, y_test)\n",
    "    return train_score, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Výber atribútov, výber algoritmov, hyperparameter tuning, ensemble learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ktorý model je Váš najlepší model pre nasadenie (deployment)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aký je data pipeline pre jeho vybudovanie na základe Vášho datasetu v produkcii?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
