{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:53.981346Z",
     "start_time": "2024-10-14T17:38:53.815922Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.stats.power import TTestIndPower"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path: str = \"../dataset\"\n",
    "files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "dataset: dict[str, pd.DataFrame] = {}\n",
    "for file in files:\n",
    "    dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1 - Bacis description of data along with their characteristics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connections description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:56.045985Z",
     "start_time": "2024-10-14T17:38:56.029280Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Total Entries: 15,108\n",
    "-   Total Columns: 13\n",
    "-   Column Types:\n",
    "-   11 columns of type float64\n",
    "-   1 column of type int64\n",
    "-   1 column of type object\n",
    "-   There are no missing values in this data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:56.222901Z",
     "start_time": "2024-10-14T17:38:56.212914Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"ts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The object column \"ts\" is date and time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:56.523191Z",
     "start_time": "2024-10-14T17:38:56.497624Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"ts\"] = pd.to_datetime(dataset[\"connections\"][\"ts\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Cast the \"ts\" column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:56.702366Z",
     "start_time": "2024-10-14T17:38:56.629823Z"
    }
   },
   "outputs": [],
   "source": [
    "connection_summary = dataset[\"connections\"].describe()\n",
    "median = (\n",
    "    dataset[\"connections\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  ## adding median to describe method output\n",
    "connection_summary.loc[\"median\"] = median\n",
    "\n",
    "## dropping imei, as it has no meaning to make these statistics out of it\n",
    "connection_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "connection_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   From these tables above we can see imei is a long integer and looks like an ID, if we look at processes table, we can also see same values indicating this could be an Id of device.\n",
    "-   Another assumption we can make is that columns specifying a connection type (columns starting with c. such as c.android.youtube) have values ranging from 0 to 100, this could indicate that it is a percentage amount of time that the connection was established.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First few rows might indicate that the data was sample in a 1 minute interval.\n",
    "-   Let's look at it closer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:56.927935Z",
     "start_time": "2024-10-14T17:38:56.914233Z"
    }
   },
   "outputs": [],
   "source": [
    "times = dataset[\"connections\"].sort_values(by=\"ts\")[\"ts\"]\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Now we see it looks like samples are in a 1 minute interval.\n",
    "-   Let's go further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:57.259981Z",
     "start_time": "2024-10-14T17:38:57.152304Z"
    }
   },
   "outputs": [],
   "source": [
    "previous_time: Optional[pd.Series] = None\n",
    "\n",
    "same_times: int = 0\n",
    "non_minute_differences: int = 0\n",
    "\n",
    "\n",
    "for current_time in times:\n",
    "    if previous_time is None:\n",
    "        previous_time = current_time\n",
    "        continue\n",
    "\n",
    "    if (current_time - previous_time).seconds == 0:\n",
    "        same_times += 1\n",
    "\n",
    "    elif (current_time - previous_time).seconds != 60:\n",
    "        non_minute_differences += 1\n",
    "\n",
    "    previous_time = current_time\n",
    "\n",
    "print(f\"Non minute differences: {non_minute_differences}\")\n",
    "print(f\"Same times: {same_times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   From this we can see, that there are data every minute, sometimes more than once at the same time.\n",
    "-   There are either some duplicates, or data for different devices at the same time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:57.656728Z",
     "start_time": "2024-10-14T17:38:57.437656Z"
    }
   },
   "outputs": [],
   "source": [
    "times = (\n",
    "    dataset[\"connections\"]\n",
    "    .groupby(by=\"imei\")[[\"imei\", \"ts\"]]\n",
    "    .apply(lambda val: val.sort_values(by=\"ts\", ascending=True))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   If we assume that columns starting with \"c.\" are representing percentage amount of time being active during a time window, we need to group them by device serial number (imei) and then look at the time difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:57.879770Z",
     "start_time": "2024-10-14T17:38:57.871203Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"mwra\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   mwra is (Malware-related-activity)\n",
    "-   In data there are only values 1.0 and 0.0 indicating if there was a malware activity in specific time frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Devices description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:58.217278Z",
     "start_time": "2024-10-14T17:38:58.205251Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"devices\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:58.470838Z",
     "start_time": "2024-10-14T17:38:58.442217Z"
    }
   },
   "outputs": [],
   "source": [
    "devices_summary = dataset[\"devices\"].describe()\n",
    "median = (\n",
    "    dataset[\"devices\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  ## adding median to describe method output\n",
    "devices_summary.loc[\"median\"] = median\n",
    "\n",
    "## dropping imei, as it has no meaning to make these statistics out of it\n",
    "devices_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "devices_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:58.894759Z",
     "start_time": "2024-10-14T17:38:58.844760Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"devices\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   \"store_name\" object is a string\n",
    "-   \"code\" is string, holding code for state\n",
    "-   \"location\" is a string, containing continent and city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processes description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:59.086292Z",
     "start_time": "2024-10-14T17:38:59.068491Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:59.360101Z",
     "start_time": "2024-10-14T17:38:59.332696Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"][\"ts\"] = pd.to_datetime(dataset[\"processes\"][\"ts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:38:59.874161Z",
     "start_time": "2024-10-14T17:38:59.752760Z"
    }
   },
   "outputs": [],
   "source": [
    "processes_summary = dataset[\"processes\"].describe()\n",
    "median = (\n",
    "    dataset[\"processes\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  ## adding median to describe method output\n",
    "processes_summary.loc[\"median\"] = median\n",
    "\n",
    "## dropping imei, as it has no meaning to make these statistics out of it\n",
    "processes_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "processes_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:00.083104Z",
     "start_time": "2024-10-14T17:39:00.057753Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Profiles description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:00.430395Z",
     "start_time": "2024-10-14T17:39:00.417574Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"profiles\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:00.709098Z",
     "start_time": "2024-10-14T17:39:00.698411Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"profiles\"][\"birthdate\"] = pd.to_datetime(dataset[\"profiles\"][\"birthdate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:01.103781Z",
     "start_time": "2024-10-14T17:39:01.079446Z"
    }
   },
   "outputs": [],
   "source": [
    "profiles_summary = dataset[\"profiles\"].describe()\n",
    "median = (\n",
    "    dataset[\"profiles\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  ## adding median to describe method output\n",
    "profiles_summary.loc[\"median\"] = median\n",
    "\n",
    "## dropping imei, as it has no meaning to make these statistics out of it\n",
    "profiles_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "profiles_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:01.799403Z",
     "start_time": "2024-10-14T17:39:01.782393Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"profiles\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:01.951799Z",
     "start_time": "2024-10-14T17:39:01.939644Z"
    }
   },
   "outputs": [],
   "source": [
    "null_values = {file: data.isnull().sum() for file, data in dataset.items()}\n",
    "for file, nulls in null_values.items():\n",
    "    if nulls.sum() == 0:\n",
    "        continue\n",
    "    print(f\"Null values in {file} dataset:\")\n",
    "    print(nulls)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWRA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First we look at the most important column \"mwra\" and look at it more in depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:02.184976Z",
     "start_time": "2024-10-14T17:39:02.175862Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"mwra\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   In \"connections\" we can see that positive mwra is ~62%, indicating that there are more positive cases and therefore in future when we put it into our model might falsely evaluate some connections. I would say the closer we are to 50/50 the better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:02.577104Z",
     "start_time": "2024-10-14T17:39:02.565708Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"][\"mwra\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   \"mwra\" is the same for \"processes\" as it is for \"connections\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:03.116301Z",
     "start_time": "2024-10-14T17:39:03.093799Z"
    }
   },
   "outputs": [],
   "source": [
    "chrome_data = dataset[\"connections\"][\"c.android.chrome\"]\n",
    "chrome_mean = chrome_data.mean()\n",
    "chrome_std = chrome_data.std()\n",
    "\n",
    "dogalize_data = dataset[\"connections\"][\"c.dogalize\"]\n",
    "dogalize_mean = dogalize_data.mean()\n",
    "dogalize_std = dogalize_data.std()\n",
    "\n",
    "gm_data = dataset[\"connections\"][\"c.android.gm\"]\n",
    "gm_mean = gm_data.mean()\n",
    "gm_std = gm_data.std()\n",
    "\n",
    "youtube_data = dataset[\"connections\"][\"c.android.youtube\"]\n",
    "youtube_mean = youtube_data.mean()\n",
    "youtube_std = youtube_data.std()\n",
    "\n",
    "katana_data = dataset[\"connections\"][\"c.katana\"]\n",
    "katana_mean = katana_data.mean()\n",
    "katana_std = katana_data.std()\n",
    "\n",
    "raider_data = dataset[\"connections\"][\"c.raider\"]\n",
    "raider_mean = raider_data.mean()\n",
    "raider_std = raider_data.std()\n",
    "\n",
    "vending_data = dataset[\"connections\"][\"c.android.vending\"]\n",
    "vending_mean = vending_data.mean()\n",
    "vending_std = vending_data.std()\n",
    "\n",
    "x86_data = dataset[\"connections\"][\"c.UCMobile.x86\"]\n",
    "x86_mean = x86_data.mean()\n",
    "x86_std = x86_data.std()\n",
    "\n",
    "\n",
    "updateassist_data = dataset[\"connections\"][\"c.updateassist\"]\n",
    "updateassist_mean = updateassist_data.mean()\n",
    "updateassist_std = updateassist_data.std()\n",
    "\n",
    "intl_data = dataset[\"connections\"][\"c.UCMobile.intl\"]\n",
    "intl_mean = intl_data.mean()\n",
    "intl_std = intl_data.std()\n",
    "\n",
    "all_str_connections: list[str] = [\n",
    "    \"c.android.chrome\",\n",
    "    \"c.dogalize\",\n",
    "    \"c.android.gm\",\n",
    "    \"c.android.youtube\",\n",
    "    \"c.katana\",\n",
    "    \"c.raider\",\n",
    "    \"c.android.vending\",\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "]\n",
    "\n",
    "all_data_connections: list[pd.Series] = [\n",
    "    chrome_data,\n",
    "    dogalize_data,\n",
    "    gm_data,\n",
    "    youtube_data,\n",
    "    katana_data,\n",
    "    raider_data,\n",
    "    vending_data,\n",
    "    x86_data,\n",
    "    updateassist_data,\n",
    "    intl_data,\n",
    "]\n",
    "\n",
    "all_means_connections: list[float] = [\n",
    "    chrome_mean,\n",
    "    dogalize_mean,\n",
    "    gm_mean,\n",
    "    youtube_mean,\n",
    "    katana_mean,\n",
    "    raider_mean,\n",
    "    vending_mean,\n",
    "    x86_mean,\n",
    "    updateassist_mean,\n",
    "    intl_mean,\n",
    "]\n",
    "\n",
    "all_std_connections: list[float] = [\n",
    "    chrome_std,\n",
    "    dogalize_std,\n",
    "    gm_std,\n",
    "    youtube_std,\n",
    "    katana_std,\n",
    "    raider_std,\n",
    "    vending_std,\n",
    "    x86_std,\n",
    "    updateassist_std,\n",
    "    intl_std,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of dispersion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:03.364502Z",
     "start_time": "2024-10-14T17:39:03.313725Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dataset[\"connections\"].iloc[:, 3:].describe()\n",
    "df.loc[\"full_range\"] = df.loc[\"max\"] - df.loc[\"min\"]\n",
    "df.loc[\"interquartile_range\"] = df.loc[\"75%\"] - df.loc[\"25%\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:03.633223Z",
     "start_time": "2024-10-14T17:39:03.566370Z"
    }
   },
   "outputs": [],
   "source": [
    "apps = all_str_connections\n",
    "\n",
    "means = all_means_connections\n",
    "\n",
    "medians = [\n",
    "    chrome_data.median(),\n",
    "    dogalize_data.median(),\n",
    "    gm_data.median(),\n",
    "    youtube_data.median(),\n",
    "    katana_data.median(),\n",
    "    raider_data.median(),\n",
    "    vending_data.median(),\n",
    "    x86_data.median(),\n",
    "    updateassist_data.median(),\n",
    "    intl_data.median(),\n",
    "]\n",
    "\n",
    "max_values = []\n",
    "most_occurring_values = []\n",
    "\n",
    "value_counts = chrome_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = dogalize_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = gm_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = youtube_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = katana_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = raider_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = vending_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = x86_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = updateassist_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "value_counts = intl_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "for i in range(len(most_occurring_values)):\n",
    "    most_occurring_values[i] = most_occurring_values[i][: min(3, len(most_occurring_values[i]))]\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"connection\": apps,\n",
    "    \"mean\": means,\n",
    "    \"median\": medians,\n",
    "    \"mode_count\": max_values,\n",
    "    \"mode_values\": most_occurring_values,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:03.760285Z",
     "start_time": "2024-10-14T17:39:03.754722Z"
    }
   },
   "outputs": [],
   "source": [
    "def skewness_type(skew_value: float) -> str:\n",
    "    if skew_value <= -1:\n",
    "        return \"Highly Negative Skew\"\n",
    "\n",
    "    elif skew_value <= -0.5:\n",
    "        return \"Moderately Negative Skew\"\n",
    "\n",
    "    elif skew_value <= 0.5:\n",
    "        return \"Approximately Symmetric\"\n",
    "\n",
    "    elif skew_value <= 1:\n",
    "        return \"Moderately Positive Skew\"\n",
    "\n",
    "    return \"Highly Positive Skew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:04.016236Z",
     "start_time": "2024-10-14T17:39:04.009027Z"
    }
   },
   "outputs": [],
   "source": [
    "def kurtosis_type(kurtosis_value: float) -> str:\n",
    "    if kurtosis_value < -1:\n",
    "        return \"Negative Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < -0.5:\n",
    "        return \"Moderately Negative Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < 0.5:\n",
    "        return \"Approximately Normal Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < 1:\n",
    "        return \"Moderately Positive Kurtosis\"\n",
    "\n",
    "    return \"Positive Kurtosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:04.406018Z",
     "start_time": "2024-10-14T17:39:04.366973Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"connection\": all_str_connections,\n",
    "    \"skew\": [\n",
    "        stats.skew(chrome_data),\n",
    "        stats.skew(dogalize_data),\n",
    "        stats.skew(gm_data),\n",
    "        stats.skew(youtube_data),\n",
    "        stats.skew(katana_data),\n",
    "        stats.skew(raider_data),\n",
    "        stats.skew(vending_data),\n",
    "        stats.skew(x86_data),\n",
    "        stats.skew(updateassist_data),\n",
    "        stats.skew(intl_data),\n",
    "    ],\n",
    "    \"kurtosis\": [\n",
    "        stats.kurtosis(chrome_data),\n",
    "        stats.kurtosis(dogalize_data),\n",
    "        stats.kurtosis(gm_data),\n",
    "        stats.kurtosis(youtube_data),\n",
    "        stats.kurtosis(katana_data),\n",
    "        stats.kurtosis(raider_data),\n",
    "        stats.kurtosis(vending_data),\n",
    "        stats.kurtosis(x86_data),\n",
    "        stats.kurtosis(updateassist_data),\n",
    "        stats.kurtosis(intl_data),\n",
    "    ],\n",
    "}\n",
    "\n",
    "shape_df = pd.DataFrame(data)\n",
    "\n",
    "shape_df[\"result skew\"] = shape_df[\"skew\"].apply(skewness_type)\n",
    "shape_df[\"result kurtosis\"] = shape_df[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_df.set_index(\"connection\", inplace=True)\n",
    "shape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms with KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:12.888835Z",
     "start_time": "2024-10-14T17:39:04.620012Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "\n",
    "## Having all the data in a list, we can iterate over it and plot the histogram with KDE for each connection.\n",
    "for i in range(len(all_data_connections)):\n",
    "    sns.histplot(all_data_connections[i], bins=30, kde=True, ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        all_means_connections[i], color=\"r\", linestyle=\"--\", label=f\"Mean: {all_means_connections[i]:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Skewness: {shape_df.loc[all_str_connections[i]]['skew']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Kurtosis: {shape_df.loc[all_str_connections[i]]['kurtosis']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "## Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:20.533119Z",
     "start_time": "2024-10-14T17:39:12.891848Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "for i in range(len(all_data_connections)):\n",
    "    sns.histplot(\n",
    "        data=all_data_connections[i],\n",
    "        bins=30,\n",
    "        stat=\"density\",\n",
    "        alpha=0.3,\n",
    "        color=\"gray\",\n",
    "        label=\"Histogram\",\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=all_data_connections[i],\n",
    "        color=\"blue\",\n",
    "        label=\"Actual Distribution\",\n",
    "        linewidth=2,\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "\n",
    "    if i <= 5:  ## We know that first 6 connections are not uniform\n",
    "        x = np.linspace(all_data_connections[i].min(), all_data_connections[i].max(), 100)\n",
    "        gaussian = stats.norm.pdf(x, all_means_connections[i], all_std_connections[i])\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, gaussian, color=\"red\", linestyle=\"--\", label=\"Gaussian Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        a = all_data_connections[i].min()\n",
    "        b = all_data_connections[i].max()\n",
    "        x = np.linspace(a, b, all_data_connections[i].size)\n",
    "        uniform_dist = stats.uniform(loc=a, scale=b - a)\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, uniform_dist.pdf(x), color=\"red\", linestyle=\"--\", label=\"Uniform Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "## Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:22.702248Z",
     "start_time": "2024-10-14T17:39:20.535133Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "for i in range(len(all_data_connections)):\n",
    "    sns.boxplot(all_data_connections[i], ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "## Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Q plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:26.198338Z",
     "start_time": "2024-10-14T17:39:22.704776Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "for i in range(len(all_data_connections)):\n",
    "    sm.qqplot(all_data_connections[i], fit=True, line=\"45\", ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "## Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:26.213186Z",
     "start_time": "2024-10-14T17:39:26.199354Z"
    }
   },
   "outputs": [],
   "source": [
    "chrome_data = dataset[\"processes\"][\"p.android.chrome\"]\n",
    "chrome_mean = chrome_data.mean()\n",
    "chrome_std = chrome_data.std()\n",
    "\n",
    "dogalize_data = dataset[\"processes\"][\"p.dogalize\"]\n",
    "dogalize_mean = dogalize_data.mean()\n",
    "dogalize_std = dogalize_data.std()\n",
    "\n",
    "katana_data = dataset[\"processes\"][\"p.katana\"]\n",
    "katana_mean = katana_data.mean()\n",
    "katana_std = katana_data.std()\n",
    "\n",
    "settings_data = dataset[\"processes\"][\"p.android.settings\"]\n",
    "settings_mean = settings_data.mean()\n",
    "settings_std = settings_data.std()\n",
    "\n",
    "system_data = dataset[\"processes\"][\"p.system\"]\n",
    "system_mean = system_data.mean()\n",
    "system_std = system_data.std()\n",
    "\n",
    "simulator_data = dataset[\"processes\"][\"p.simulator\"]\n",
    "simulator_mean = simulator_data.mean()\n",
    "simulator_std = simulator_data.std()\n",
    "\n",
    "all_str_processes: list[str] = [\n",
    "    \"p.android.chrome\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.katana\",\n",
    "    \"p.android.settings\",\n",
    "    \"p.system\",\n",
    "    \"p.simulator\",\n",
    "]\n",
    "\n",
    "all_data_processes: list[pd.Series] = [\n",
    "    chrome_data,\n",
    "    dogalize_data,\n",
    "    katana_data,\n",
    "    settings_data,\n",
    "    system_data,\n",
    "    simulator_data,\n",
    "]\n",
    "\n",
    "all_means_processes: list[float] = [\n",
    "    chrome_mean,\n",
    "    dogalize_mean,\n",
    "    katana_mean,\n",
    "    settings_mean,\n",
    "    system_mean,\n",
    "    simulator_mean,\n",
    "]\n",
    "\n",
    "all_std_processes: list[float] = [\n",
    "    chrome_std,\n",
    "    dogalize_std,\n",
    "    katana_std,\n",
    "    settings_std,\n",
    "    system_std,\n",
    "    simulator_std,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of dispersion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:26.250922Z",
     "start_time": "2024-10-14T17:39:26.214715Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dataset[\"processes\"][all_str_processes].describe()\n",
    "df.loc[\"full_range\"] = df.loc[\"max\"] - df.loc[\"min\"]\n",
    "df.loc[\"interquartile_range\"] = df.loc[\"75%\"] - df.loc[\"25%\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:26.298237Z",
     "start_time": "2024-10-14T17:39:26.251936Z"
    }
   },
   "outputs": [],
   "source": [
    "apps = all_str_processes\n",
    "\n",
    "means = all_means_processes\n",
    "\n",
    "medians = [\n",
    "    chrome_data.median(),\n",
    "    dogalize_data.median(),\n",
    "    katana_data.median(),\n",
    "    settings_data.median(),\n",
    "    system_data.median(),\n",
    "    simulator_data.median(),\n",
    "]\n",
    "\n",
    "max_values = []\n",
    "most_occurring_values = []\n",
    "\n",
    "value_counts = chrome_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = dogalize_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = katana_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = settings_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = system_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = simulator_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "for i in range(len(most_occurring_values)):\n",
    "    most_occurring_values[i] = most_occurring_values[i][: min(3, len(most_occurring_values[i]))]\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"process\": apps,\n",
    "    \"mean\": means,\n",
    "    \"median\": medians,\n",
    "    \"mode_count\": max_values,\n",
    "    \"mode_values\": most_occurring_values,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:26.328072Z",
     "start_time": "2024-10-14T17:39:26.300250Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"process\": all_str_processes,\n",
    "    \"skew\": [\n",
    "        stats.skew(chrome_data),\n",
    "        stats.skew(dogalize_data),\n",
    "        stats.skew(katana_data),\n",
    "        stats.skew(settings_data),\n",
    "        stats.skew(system_data),\n",
    "        stats.skew(simulator_data),\n",
    "    ],\n",
    "    \"kurtosis\": [\n",
    "        stats.kurtosis(chrome_data),\n",
    "        stats.kurtosis(dogalize_data),\n",
    "        stats.kurtosis(katana_data),\n",
    "        stats.kurtosis(settings_data),\n",
    "        stats.kurtosis(system_data),\n",
    "        stats.kurtosis(simulator_data),\n",
    "    ],\n",
    "}\n",
    "\n",
    "shape_df = pd.DataFrame(data)\n",
    "shape_df[\"result skew\"] = shape_df[\"skew\"].apply(skewness_type)\n",
    "shape_df[\"result kurtosis\"] = shape_df[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_df.set_index(\"process\", inplace=True)\n",
    "shape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Histograms with KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:31.892693Z",
     "start_time": "2024-10-14T17:39:26.329086Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sns.histplot(all_data_processes[i], bins=30, kde=True, ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        all_means_processes[i], color=\"r\", linestyle=\"--\", label=f\"Mean: {all_means_processes[i]:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Skewness: {shape_df.loc[all_str_processes[i]]['skew']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Kurtosis: {shape_df.loc[all_str_processes[i]]['kurtosis']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:36.239655Z",
     "start_time": "2024-10-14T17:39:31.897242Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "gaussian_models = [chrome_data, settings_data, system_data]\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sns.histplot(\n",
    "        data=all_data_processes[i],\n",
    "        bins=30,\n",
    "        stat=\"density\",\n",
    "        alpha=0.3,\n",
    "        color=\"gray\",\n",
    "        label=\"Histogram\",\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=all_data_processes[i],\n",
    "        color=\"blue\",\n",
    "        label=\"Actual Distribution\",\n",
    "        linewidth=2,\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "\n",
    "    if any(all_data_processes[i] is model for model in gaussian_models):\n",
    "        x = np.linspace(all_data_processes[i].min(), all_data_processes[i].max(), 100)\n",
    "        gaussian = stats.norm.pdf(x, all_means_processes[i], all_std_processes[i])\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, gaussian, color=\"red\", linestyle=\"--\", label=\"Gaussian Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        a = all_data_processes[i].min()\n",
    "        b = all_data_processes[i].max()\n",
    "        x = np.linspace(a, b, all_data_processes[i].size)\n",
    "        uniform_dist = stats.uniform(loc=a, scale=b - a)\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, uniform_dist.pdf(x), color=\"red\", linestyle=\"--\", label=\"Uniform Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:37.572871Z",
     "start_time": "2024-10-14T17:39:36.240662Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sns.boxplot(all_data_processes[i], ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q-Q plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:39.642995Z",
     "start_time": "2024-10-14T17:39:37.574880Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sm.qqplot(all_data_processes[i], fit=True, line=\"45\", ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:40.317720Z",
     "start_time": "2024-10-14T17:39:39.644006Z"
    }
   },
   "outputs": [],
   "source": [
    "matica = dataset[\"connections\"].iloc[:, 2:].corr()\n",
    "\n",
    "mask = np.triu(np.ones_like(matica, dtype=bool))\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(matica, mask=mask, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:41.888433Z",
     "start_time": "2024-10-14T17:39:40.319731Z"
    }
   },
   "outputs": [],
   "source": [
    "matica = dataset[\"connections\"].iloc[:, 2:].corr(method=\"spearman\")\n",
    "\n",
    "mask = np.triu(np.ones_like(matica, dtype=bool))\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(matica, mask=mask, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:39:42.927467Z",
     "start_time": "2024-10-14T17:39:41.890450Z"
    }
   },
   "outputs": [],
   "source": [
    "matica = dataset[\"processes\"].iloc[:, 2:].corr()\n",
    "matica = matica.round(2)\n",
    "\n",
    "mask = np.triu(np.ones_like(matica, dtype=bool))\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "sns.heatmap(matica, mask=mask, annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1)\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:18.833289Z",
     "start_time": "2024-10-14T17:39:42.929477Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.pairplot(\n",
    "    dataset[\"connections\"].iloc[:, 2:], hue=\"mwra\", diag_kind=\"kde\", palette={0.0: \"blue\", 1.0: \"red\"}\n",
    ")\n",
    "# sns.pairplot(connections, hue=\"mwra\", diag_kind=\"kde\", palette = {0.0: 'blue', 1.0: 'red'})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:19.178830Z",
     "start_time": "2024-10-14T17:40:18.834811Z"
    }
   },
   "outputs": [],
   "source": [
    "processes_columns = [\"p.android.chrome\", \"p.dogalize\", \"p.katana\", \"p.android.gm\", \"p.android.vending\"]\n",
    "connections_columns = [\"c.android.chrome\", \"c.dogalize\", \"c.katana\", \"c.android.gm\", \"c.android.vending\"]\n",
    "\n",
    "combined_df = pd.concat(\n",
    "    [dataset[\"processes\"][processes_columns], dataset[\"connections\"][connections_columns]], axis=1\n",
    ")\n",
    "\n",
    "correlation_matrix = combined_df.corr(method=\"pearson\")\n",
    "\n",
    "filtered_corr = correlation_matrix.loc[processes_columns, connections_columns]\n",
    "\n",
    "mask = np.ones_like(filtered_corr, dtype=bool)\n",
    "np.fill_diagonal(mask, False)\n",
    "\n",
    "sns.heatmap(\n",
    "    filtered_corr,\n",
    "    mask=mask,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    xticklabels=connections_columns,\n",
    "    yticklabels=processes_columns,\n",
    ")\n",
    "plt.xlabel(\"Connections\")\n",
    "plt.ylabel(\"Processes\")\n",
    "plt.title(\"Korelácia medzi Processes a Connections (len stredná diagonála)\")\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:20.415250Z",
     "start_time": "2024-10-14T17:40:19.179840Z"
    }
   },
   "outputs": [],
   "source": [
    "mwra = dataset[\"processes\"][\"mwra\"]\n",
    "settings = dataset[\"processes\"][\"p.android.settings\"]\n",
    "\n",
    "sns.regplot(x=mwra, y=settings, line_kws={\"color\": \"red\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:20.708330Z",
     "start_time": "2024-10-14T17:40:20.416776Z"
    }
   },
   "outputs": [],
   "source": [
    "connections_list = all_str_connections\n",
    "mwra_list = [\"mwra\"]\n",
    "\n",
    "combined_df = pd.concat([dataset[\"connections\"][connections_list], dataset[\"connections\"][mwra_list]], axis=1)\n",
    "\n",
    "correlation_matrix = combined_df.corr(method=\"pearson\")\n",
    "\n",
    "filtered_corr = correlation_matrix.loc[connections_list, mwra_list]\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    filtered_corr,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    xticklabels=mwra_list,\n",
    "    yticklabels=connections_list,\n",
    ")\n",
    "plt.xlabel(\"Connections\")\n",
    "plt.ylabel(\"Processes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.153923Z",
     "start_time": "2024-10-14T17:40:20.709343Z"
    }
   },
   "outputs": [],
   "source": [
    "processes_list = dataset[\"processes\"].columns[3:]\n",
    "mwra_list = [\"mwra\"]\n",
    "\n",
    "combined_df = pd.concat([dataset[\"processes\"][processes_list], dataset[\"processes\"][mwra_list]], axis=1)\n",
    "\n",
    "correlation_matrix = combined_df.corr(method=\"pearson\")\n",
    "\n",
    "filtered_corr = correlation_matrix.loc[processes_list, mwra_list]\n",
    "\n",
    "plt.figure(figsize=(8, 10))\n",
    "sns.heatmap(\n",
    "    filtered_corr,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    vmin=-1,\n",
    "    vmax=1,\n",
    "    xticklabels=mwra_list,\n",
    "    yticklabels=processes_list,\n",
    ")\n",
    "plt.xlabel(\"Connections\")\n",
    "plt.ylabel(\"Processes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"devices\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset[\"devices\"].copy()\n",
    "df[\"continent\"] = dataset[\"devices\"][\"location\"].apply(lambda x: x.split(\"/\")[0])\n",
    "df = df.merge(dataset[\"connections\"][[\"imei\", \"mwra\"]], on=\"imei\")\n",
    "df = df.groupby(\"continent\").agg({\"mwra\": \"mean\"})\n",
    "df.plot(kind=\"barh\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## E.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dokumentujte Vaše prvotné zamyslenie k riešeniu zadania projektu, napr. sú\n",
    "niektoré atribúty medzi sebou závislé? od ktorých atribútov závisí predikovaná\n",
    "premenná? či je potrebné kombinovať záznamy z viacerých súborov?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations\n",
    "\n",
    "Connections:\n",
    "\n",
    "-   Correlation matrix for **mwra** in **connections** shows slight correlations between **c.dogalize** and **c.android.youtube**\n",
    "-   Surprisingly there is a negative correlation between **c.katana**\n",
    "\n",
    "Processes:\n",
    "\n",
    "-   Correlation matrix for **mwra** in **processes** shows slight correlation between **p.android.settings**\n",
    "-   There is also slight negative correlation between **p.system**\n",
    "\n",
    "#### Combination of data\n",
    "\n",
    "-   We can combine data from **connections** and **processes** by **imei** to get more data, especially important data that will be crucial in our model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 - Identification of problems, integration and data cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 1.1-A we already transformed the \"ts\" column to datetime. WIth this we can expect every instance to be of the same format, if there were any errors in the data, the function would throw an error.\n",
    "\n",
    "But here is also a simple function to check if the data is in the correct format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.303499Z",
     "start_time": "2024-10-14T17:40:21.155880Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_correct_format(date: str) -> bool:\n",
    "    if date[4] == \"-\" and date[7] == \"-\" and date[10] == \" \" and date[13] == \":\" and date[16] == \":\":\n",
    "        return True\n",
    "    print(f\"Date {date} is not in correct format\")\n",
    "    return False\n",
    "\n",
    "\n",
    "# Since we already changed the format of the datetime, we will read cvs again\n",
    "df = pd.read_csv(\"../dataset/connections.csv\", sep=\"\\t\")\n",
    "bool_val = df[\"ts\"].apply(check_correct_format).all()\n",
    "print(bool_val)\n",
    "\n",
    "df = pd.read_csv(\"../dataset/processes.csv\", sep=\"\\t\")\n",
    "bool_val = df[\"ts\"].apply(check_correct_format).all()\n",
    "print(bool_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The format of date time in \"connections\" and \"processes\" is correct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.317950Z",
     "start_time": "2024-10-14T17:40:21.305043Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in dataset:\n",
    "    has_missing_values = dataset[key].isnull().values.any()\n",
    "    print(\n",
    "        f\"DataFrame {key:<12} has {dataset[key].isnull().sum().sum() if has_missing_values else 'no':<4} missing values\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see that **profiles** have some missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.341357Z",
     "start_time": "2024-10-14T17:40:21.319961Z"
    }
   },
   "outputs": [],
   "source": [
    "missing_columns = dataset[\"profiles\"].columns[dataset[\"profiles\"].isnull().any()]\n",
    "print(\"Columns with missing values:\", missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We can see the columns with missing values in **profiles** are: \"address\", \"job\", \"residence\", \"birthdate\"\n",
    "-   These columns hold no important information for our analysis, so we can drop this table in later part\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.425837Z",
     "start_time": "2024-10-14T17:40:21.342365Z"
    }
   },
   "outputs": [],
   "source": [
    "for key in dataset:\n",
    "    has_duplicates = dataset[key].duplicated().any()\n",
    "    print(\n",
    "        f'DataFrame {key:<12} has {dataset[key].duplicated().sum() if has_duplicates else \"no\":<4} duplicates'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates in **connections**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.456767Z",
     "start_time": "2024-10-14T17:40:21.426848Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][dataset[\"connections\"].duplicated(keep=\"first\")].sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates in **devices**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.474433Z",
     "start_time": "2024-10-14T17:40:21.458777Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"devices\"][dataset[\"devices\"].duplicated(keep=\"first\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicates in **processes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.527008Z",
     "start_time": "2024-10-14T17:40:21.476441Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"][dataset[\"processes\"].duplicated(keep=\"first\")].sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping duplicates in all tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dataset:\n",
    "    dataset[key].drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.544073Z",
     "start_time": "2024-10-14T17:40:21.532015Z"
    }
   },
   "outputs": [],
   "source": [
    "profiles_copy = dataset[\"profiles\"].copy()\n",
    "\n",
    "before_drop = profiles_copy.shape[0]\n",
    "profiles_copy.dropna(inplace=True)\n",
    "\n",
    "after_drop = profiles_copy.shape[0]\n",
    "\n",
    "print(f\"DataFrame profiles had {before_drop} rows before dropping NaN values\")\n",
    "print(f\"DataFrame profiles has {after_drop} rows after dropping NaN values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   We see that after drop we have only 137 from original 2571 rows, which result in almost no data to work with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:21.682571Z",
     "start_time": "2024-10-14T17:40:21.545080Z"
    }
   },
   "outputs": [],
   "source": [
    "profiles_copy = dataset[\"profiles\"].copy()\n",
    "\n",
    "before_manipulating = profiles_copy.isnull().sum().sum()\n",
    "number_of_rows = len(profiles_copy)\n",
    "number_of_values = profiles_copy.count().sum()\n",
    "missing_values = profiles_copy.isnull().sum().sum()\n",
    "\n",
    "profiles_copy[\"job\"].fillna(profiles_copy[\"job\"].mode()[0], inplace=True)  # using mode\n",
    "profiles_copy[\"residence\"].fillna(profiles_copy[\"residence\"].mode()[0], inplace=True)\n",
    "\n",
    "profiles_copy[\"birth_year\"] = profiles_copy[\"birthdate\"].dt.year  # taking out the year\n",
    "profiles_copy[\"birth_year\"] = profiles_copy[\"birth_year\"].interpolate(method=\"linear\")  # using interpolation\n",
    "\n",
    "profiles_copy[\"birthdate\"] = pd.to_datetime(\n",
    "    profiles_copy[\"birth_year\"].round().astype(int), format=\"%Y\", errors=\"coerce\"\n",
    ")\n",
    "profiles_copy.drop(columns=\"birth_year\", inplace=True)\n",
    "\n",
    "\n",
    "le_residence = LabelEncoder()\n",
    "profiles_copy[\"residence_encoded\"] = le_residence.fit_transform(\n",
    "    profiles_copy[\"residence\"].astype(str)\n",
    ")  # Encoding\n",
    "\n",
    "le_address = LabelEncoder()\n",
    "profiles_copy[\"address_encoded\"] = le_address.fit_transform(\n",
    "    profiles_copy[\"address\"].fillna(\"NaN\").astype(str)\n",
    ")  # keeping the values\n",
    "\n",
    "subset = profiles_copy[[\"address_encoded\", \"residence_encoded\"]]\n",
    "subset.loc[profiles_copy[\"address\"].isnull(), \"address_encoded\"] = np.nan\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=2)\n",
    "subset_imputed = imputer.fit_transform(subset)  # using kNN\n",
    "\n",
    "profiles_copy[\"address_encoded\"] = subset_imputed[:, 0]\n",
    "profiles_copy[\"address\"] = le_address.inverse_transform(profiles_copy[\"address_encoded\"].round().astype(int))\n",
    "\n",
    "profiles_copy.drop(columns=[\"address_encoded\", \"residence_encoded\"], inplace=True)\n",
    "\n",
    "after_manipulating = profiles_copy.isnull().sum().sum()\n",
    "number_of_rows_new = len(profiles_copy)\n",
    "number_of_values_new = profiles_copy.count().sum()\n",
    "missing_values_new = profiles_copy.isnull().sum().sum()\n",
    "\n",
    "print(\n",
    "    f\"Before manipulating: {before_manipulating} nan rows, after manipulating: {after_manipulating} nan rows\"\n",
    ")\n",
    "print(f\"Number of rows before: {number_of_rows}, after: {number_of_rows_new}\")\n",
    "print(\n",
    "    f\"Number of values before: {number_of_values} + {missing_values} missing ({number_of_values + missing_values}), after: {number_of_values_new} + {missing_values_new} missing ({number_of_values_new + missing_values_new})\"\n",
    ")\n",
    "profiles_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:22.129732Z",
     "start_time": "2024-10-14T17:40:21.683585Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"].iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(14, 10), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:22.701081Z",
     "start_time": "2024-10-14T17:40:22.130739Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"].iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(14, 14), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier detections using **Z-score**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of outliers in **Connections**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:22.725737Z",
     "start_time": "2024-10-14T17:40:22.702093Z"
    }
   },
   "outputs": [],
   "source": [
    "z_scores = dataset[\"connections\"].iloc[:, 2:].apply(stats.zscore)\n",
    "outliers = z_scores[(z_scores.abs() > 3).any(axis=1)]\n",
    "print(f\"Number of connections with |z-score| > 3: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of outliers in **Processes**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:22.760792Z",
     "start_time": "2024-10-14T17:40:22.726744Z"
    }
   },
   "outputs": [],
   "source": [
    "z_scores = dataset[\"processes\"].iloc[:, 2:].apply(stats.zscore)\n",
    "outliers = z_scores[(z_scores.abs() > 3).any(axis=1)]\n",
    "print(f\"Number of processes with |z-score| > 3: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers from **Connections** and showing boxplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:22.778280Z",
     "start_time": "2024-10-14T17:40:22.761804Z"
    }
   },
   "outputs": [],
   "source": [
    "connections_copy = dataset[\"connections\"].copy()\n",
    "print(\"Number of connections before removing outliers:\\t\", connections_copy.shape[0])\n",
    "\n",
    "connections_copy = connections_copy[(np.abs(stats.zscore(connections_copy.iloc[:, 2:])) < 3).all(axis=1)]\n",
    "print(\"Number of connections after removing outliers:\\t\", connections_copy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:23.412622Z",
     "start_time": "2024-10-14T17:40:22.779290Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"].iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(10, 8), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")\n",
    "plt.title(\"Before removing outliers using Z-score\")\n",
    "plt.show()\n",
    "\n",
    "connections_copy.iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(10, 8), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")\n",
    "plt.title(\"After removing outliers using Z-score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outlier detections using **IQR**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:23.420061Z",
     "start_time": "2024-10-14T17:40:23.414689Z"
    }
   },
   "outputs": [],
   "source": [
    "def identify_outliers(a):\n",
    "    lower = a.quantile(0.25) - 1.5 * stats.iqr(a)\n",
    "    upper = a.quantile(0.75) + 1.5 * stats.iqr(a)\n",
    "\n",
    "    return a[(a > upper) | (a < lower)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:23.478990Z",
     "start_time": "2024-10-14T17:40:23.422070Z"
    }
   },
   "outputs": [],
   "source": [
    "connections_copy = dataset[\"connections\"].copy()\n",
    "print(\"Number of connections before removing outliers:\\t\", connections_copy.shape[0])\n",
    "\n",
    "outlier = connections_copy.iloc[:, 2:].apply(identify_outliers)\n",
    "connections_copy = connections_copy.drop(outlier.index)\n",
    "print(\"Number of connections after removing outliers:\\t\", connections_copy.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:24.138156Z",
     "start_time": "2024-10-14T17:40:23.479998Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"].iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(10, 8), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")\n",
    "plt.title(\"Before removing outliers using IQR\")\n",
    "plt.show()\n",
    "\n",
    "connections_copy.iloc[:, 3:].plot(\n",
    "    kind=\"box\", vert=False, figsize=(10, 8), flierprops=dict(marker=\"o\", color=\"r\", alpha=0.5)\n",
    ")\n",
    "plt.title(\"After removing outliers using IQR\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:40:24.144308Z",
     "start_time": "2024-10-14T17:40:24.140166Z"
    }
   },
   "outputs": [],
   "source": [
    "# z_scores = dataset[\"connections\"].iloc[:, 2:].apply(stats.zscore)\n",
    "\n",
    "# # Vytvorenie masky pre hodnoty, kde je Z-skóre väčšie než 3 alebo menšie než -3\n",
    "# outlier_mask = z_scores.abs() > 3\n",
    "\n",
    "# # Použitie masky na nastavenie hodnôt na NaN len v stĺpcoch s outliers\n",
    "# dataset[\"connections\"].iloc[:, 2:] = dataset[\"connections\"].iloc[:, 2:].mask(outlier_mask, np.nan)\n",
    "\n",
    "# dataset[\"connections\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 Formulation and statistical verification of hypotheses about data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c.android.youtube\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: c.android.youtube has same values for mwra = 0 and mwra = 1\n",
    "\n",
    "$H_A$: c.android.youtube has different values (higher) for mwra = 0 and mwra = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:28.837853Z",
     "start_time": "2024-10-14T17:41:28.831284Z"
    }
   },
   "outputs": [],
   "source": [
    "connections_copy = dataset[\"connections\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:31.749451Z",
     "start_time": "2024-10-14T17:41:31.723946Z"
    }
   },
   "outputs": [],
   "source": [
    "without_mwra = connections_copy[connections_copy[\"mwra\"] == 0][[\"c.android.youtube\", \"mwra\"]].dropna()\n",
    "outlier = without_mwra.apply(identify_outliers)\n",
    "without_mwra = without_mwra.drop(outlier.index)\n",
    "without_mwra.drop(columns=\"mwra\", inplace=True)\n",
    "without_mwra.reset_index(drop=True, inplace=True)\n",
    "without_mwra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:35.004391Z",
     "start_time": "2024-10-14T17:41:34.981290Z"
    }
   },
   "outputs": [],
   "source": [
    "with_mwra = connections_copy[connections_copy[\"mwra\"] == 1][[\"c.android.youtube\", \"mwra\"]].dropna()\n",
    "outlier = with_mwra.apply(identify_outliers)\n",
    "with_mwra = with_mwra.drop(outlier.index)\n",
    "with_mwra.drop(columns=\"mwra\", inplace=True)\n",
    "with_mwra.reset_index(drop=True, inplace=True)\n",
    "with_mwra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:37.887600Z",
     "start_time": "2024-10-14T17:41:37.875367Z"
    }
   },
   "outputs": [],
   "source": [
    "anderson_result = stats.anderson(with_mwra[\"c.android.youtube\"], dist=\"norm\")\n",
    "print(anderson_result)\n",
    "print(f\"\\nDoes fit normal distribution: {anderson_result.fit_result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:39.808579Z",
     "start_time": "2024-10-14T17:41:39.797766Z"
    }
   },
   "outputs": [],
   "source": [
    "anderson_result = stats.anderson(without_mwra[\"c.android.youtube\"], dist=\"norm\")\n",
    "print(anderson_result)\n",
    "print(f\"\\nDoes fit normal distribution: {anderson_result.fit_result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:41.593139Z",
     "start_time": "2024-10-14T17:41:41.581625Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.levene(with_mwra[\"c.android.youtube\"], without_mwra[\"c.android.youtube\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:44.649499Z",
     "start_time": "2024-10-14T17:41:44.175514Z"
    }
   },
   "outputs": [],
   "source": [
    "data_to_plot = pd.DataFrame(\n",
    "    {\"With MWRA\": with_mwra[\"c.android.youtube\"], \"Without MWRA\": without_mwra[\"c.android.youtube\"]}\n",
    ").plot(kind=\"hist\", bins=30, alpha=0.5, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:41:46.399673Z",
     "start_time": "2024-10-14T17:41:46.388512Z"
    }
   },
   "outputs": [],
   "source": [
    "stat, p_value = stats.ttest_ind(\n",
    "    with_mwra[\"c.android.youtube\"], without_mwra[\"c.android.youtube\"], equal_var=False\n",
    ")\n",
    "\n",
    "print(f\"Welch’s T-test Statistic: {stat}\")\n",
    "print(f\"p_value: {float(p_value):.10f}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a significant difference between the c.android.youtube with malware-related-activity and without.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No significant difference between the two groups.\")\n",
    "\n",
    "if stat < 0:\n",
    "    print(\"c.android.youtube has higher weight in normal activity\")\n",
    "else:\n",
    "    print(\"c.android.youtube has higher weight in malware-related activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:49:57.337032Z",
     "start_time": "2024-10-14T17:49:57.326456Z"
    }
   },
   "outputs": [],
   "source": [
    "power_analysis = TTestIndPower()\n",
    "\n",
    "mean_with_mwra = with_mwra[\"c.android.youtube\"].mean()\n",
    "mean_without_mwra = without_mwra[\"c.android.youtube\"].mean()\n",
    "std_with_mwra = with_mwra[\"c.android.youtube\"].std()\n",
    "std_without_mwra = without_mwra[\"c.android.youtube\"].std()\n",
    "\n",
    "pooled_std = ((std_with_mwra**2 + std_without_mwra**2) / 2) ** 0.5\n",
    "\n",
    "print(\"std of with mwra:\", std_with_mwra)\n",
    "print(\"std of without mwra:\", std_without_mwra)\n",
    "print(\"pooled std:\", pooled_std)\n",
    "\n",
    "effect_size = (mean_with_mwra - mean_without_mwra) / pooled_std\n",
    "\n",
    "alpha = 0.05\n",
    "sample_size = len(with_mwra) + len(without_mwra)\n",
    "\n",
    "power = power_analysis.power(\n",
    "    effect_size=effect_size, nobs1=len(with_mwra), alpha=alpha, ratio=len(without_mwra) / len(with_mwra)\n",
    ")\n",
    "\n",
    "if power > 0.8:\n",
    "    print(f\"Yes, the strength of the test is sufficient. Power: {power:.2f}\")\n",
    "else:\n",
    "    print(f\"No, the strength of the test is not sufficient. Power: {power:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:50:27.367296Z",
     "start_time": "2024-10-14T17:50:27.353745Z"
    }
   },
   "outputs": [],
   "source": [
    "required_sample_size = power_analysis.solve_power(\n",
    "    effect_size=effect_size, alpha=alpha, power=0.8, ratio=len(without_mwra) / len(with_mwra)\n",
    ")\n",
    "print(f\"required data size for the strength of 0.8 is: {required_sample_size:.0f}\")\n",
    "print(\n",
    "    \"actual size data of with_mwra: \",\n",
    "    len(with_mwra),\n",
    "    \" actual size data of without_mwra: \",\n",
    "    len(without_mwra),\n",
    ")\n",
    "if len(with_mwra) < required_sample_size or len(without_mwra) < required_sample_size:\n",
    "    print(\"We need to collect more data\")\n",
    "else:\n",
    "    print(\"We have enough data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### p.android.settings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$H_0$: p.android.setting has same values for mwra = 0 and mwra = 1\n",
    "\n",
    "$H_A$: p.android.setting has different (higher) values for mwra = 0 and mwra = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:34.470170Z",
     "start_time": "2024-10-14T17:51:34.434083Z"
    }
   },
   "outputs": [],
   "source": [
    "with_mwra = dataset[\"processes\"][(dataset[\"processes\"][\"mwra\"] == 1)][[\"mwra\", \"p.android.settings\"]]\n",
    "without_mwra = dataset[\"processes\"][(dataset[\"processes\"][\"mwra\"] == 0)][[\"mwra\", \"p.android.settings\"]]\n",
    "\n",
    "print(\"Number of with_mwra before removing outliers:\\t\", with_mwra.shape[0])\n",
    "print(\"Number of without_mwra before removing outliers:\\t\", without_mwra.shape[0])\n",
    "\n",
    "outliers = with_mwra.apply(identify_outliers)\n",
    "with_mwra = with_mwra.drop(outliers.index)\n",
    "\n",
    "outliers = without_mwra.apply(identify_outliers)\n",
    "without_mwra = without_mwra.drop(outliers.index)\n",
    "\n",
    "print(\"Number of with_mwra after removing outliers:\\t\", with_mwra.shape[0])\n",
    "print(\"Number of without_mwra after removing outliers:\\t\", without_mwra.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:37.264887Z",
     "start_time": "2024-10-14T17:51:37.251170Z"
    }
   },
   "outputs": [],
   "source": [
    "anderson_result = stats.anderson(with_mwra[\"p.android.settings\"], dist=\"norm\")\n",
    "print(anderson_result)\n",
    "print(f\"\\nDoes fit normal distribution: {anderson_result.fit_result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:39.432571Z",
     "start_time": "2024-10-14T17:51:39.417177Z"
    }
   },
   "outputs": [],
   "source": [
    "anderson_result = stats.anderson(without_mwra[\"p.android.settings\"], dist=\"norm\")\n",
    "print(anderson_result)\n",
    "print(f\"\\nDoes fit normal distribution: {anderson_result.fit_result.success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:41.734554Z",
     "start_time": "2024-10-14T17:51:41.720792Z"
    }
   },
   "outputs": [],
   "source": [
    "stats.levene(with_mwra[\"p.android.settings\"], without_mwra[\"p.android.settings\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:46.423012Z",
     "start_time": "2024-10-14T17:51:44.889240Z"
    }
   },
   "outputs": [],
   "source": [
    "data_to_plot = pd.DataFrame(\n",
    "    {\"With MWRA\": with_mwra[\"p.android.settings\"], \"Without MWRA\": without_mwra[\"p.android.settings\"]}\n",
    ").plot(kind=\"hist\", bins=30, alpha=0.5, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:49.138435Z",
     "start_time": "2024-10-14T17:51:49.124825Z"
    }
   },
   "outputs": [],
   "source": [
    "stat, p_value = stats.ttest_ind(\n",
    "    with_mwra[\"p.android.settings\"], without_mwra[\"p.android.settings\"], equal_var=False\n",
    ")\n",
    "\n",
    "print(f\"Welch’s T-test Statistic: {stat}\")\n",
    "print(p_value)\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\n",
    "        \"There is a significant difference between the p.android.settings with malware-related-activity and without.\"\n",
    "    )\n",
    "else:\n",
    "    print(\"No significant difference between the two groups.\")\n",
    "\n",
    "if stat < 0:\n",
    "    print(\"p.android.settings has higher weight in normal activity\")\n",
    "else:\n",
    "    print(\"p.android.settings has higher weight in malware-related activity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: zisit ci sa tabulky v connecitona processes mwra rovanju v case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:52.589799Z",
     "start_time": "2024-10-14T17:51:52.578947Z"
    }
   },
   "outputs": [],
   "source": [
    "power_analysis = TTestIndPower()\n",
    "\n",
    "mean_with_mwra = with_mwra[\"p.android.settings\"].mean()\n",
    "mean_without_mwra = without_mwra[\"p.android.settings\"].mean()\n",
    "std_with_mwra = with_mwra[\"p.android.settings\"].std()\n",
    "std_without_mwra = without_mwra[\"p.android.settings\"].std()\n",
    "\n",
    "pooled_std = ((std_with_mwra**2 + std_without_mwra**2) / 2) ** 0.5\n",
    "effect_size = (mean_with_mwra - mean_without_mwra) / pooled_std\n",
    "\n",
    "alpha = 0.05\n",
    "sample_size = len(with_mwra) + len(without_mwra)\n",
    "\n",
    "power = power_analysis.power(\n",
    "    effect_size=effect_size, nobs1=len(with_mwra), alpha=alpha, ratio=len(without_mwra) / len(with_mwra)\n",
    ")\n",
    "\n",
    "if power > 0.8:\n",
    "    print(f\"Yes, the strength of the test is sufficient. Power: {power:.2f}\")\n",
    "else:\n",
    "    print(f\"No, the strength of the test is not sufficient. Power: {power:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-14T17:51:54.611534Z",
     "start_time": "2024-10-14T17:51:54.593958Z"
    }
   },
   "outputs": [],
   "source": [
    "required_sample_size = power_analysis.solve_power(\n",
    "    effect_size=effect_size, alpha=alpha, power=0.8, ratio=len(without_mwra) / len(with_mwra)\n",
    ")\n",
    "print(f\"required data size for the strength of 0.8 is: {required_sample_size:.0f}\")\n",
    "print(\n",
    "    \"actual size data of with_mwra: \",\n",
    "    len(with_mwra),\n",
    "    \" actual size data of without_mwra: \",\n",
    "    len(without_mwra),\n",
    ")\n",
    "if len(with_mwra) < required_sample_size or len(without_mwra) < required_sample_size:\n",
    "    print(\"We need to collect more data\")\n",
    "else:\n",
    "    print(\"We have enough data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nothing Important\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def format_size(size):\n",
    "    \"\"\"Convert size in bytes to KB or MB as appropriate.\"\"\"\n",
    "    if size >= 1024 * 1024:\n",
    "        return f\"{size / (1024 * 1024):.2f} MB\"\n",
    "    elif size >= 1024:\n",
    "        return f\"{size / 1024:.2f} KB\"\n",
    "    else:\n",
    "        return f\"{size} bytes\"\n",
    "\n",
    "\n",
    "def print_memory_usage():\n",
    "\n",
    "    memory_usage_list = []\n",
    "\n",
    "    for name, var in globals().items():\n",
    "        try:\n",
    "            memory_usage_list.append((name, sys.getsizeof(var)))\n",
    "        except TypeError:\n",
    "            memory_usage_list.append((name, float(\"inf\")))  # Use infinity for undetermined sizes\n",
    "\n",
    "    # Sort the list by memory usage in descending order\n",
    "    memory_usage_list.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Print the sorted list\n",
    "    print(\"Memory usage of variables (sorted):\")\n",
    "    print(f\"Memory sum: {format_size(sum(size for _, size in memory_usage_list))}\")\n",
    "    for name, size in memory_usage_list:\n",
    "        if size == float(\"inf\"):\n",
    "            print(f\"Memory usage of {name}: Unable to determine size\")\n",
    "        else:\n",
    "            print(f\"Memory usage of {name}: {format_size(size)}\")\n",
    "\n",
    "\n",
    "print_memory_usage()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
