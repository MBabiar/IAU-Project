{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:35.443773Z",
     "start_time": "2024-10-12T17:21:35.326718Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "from typing import Optional\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "file_path: str = \"../dataset\"\n",
    "files: tuple[str, ...] = (\"connections\", \"devices\", \"processes\", \"profiles\")\n",
    "\n",
    "dataset: dict[str, pd.DataFrame] = {}\n",
    "for file in files:\n",
    "    dataset[file] = pd.read_csv(f\"{file_path}/{file}.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   importing the necessary libraries\n",
    "-   declaring the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connections description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:35.805016Z",
     "start_time": "2024-10-12T17:21:35.795575Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Total Entries: 15,108\n",
    "-   Total Columns: 13\n",
    "-   Column Types:\n",
    "-   11 columns of type float64\n",
    "-   1 column of type int64\n",
    "-   1 column of type object\n",
    "-   There are no missing values in this data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:35.848721Z",
     "start_time": "2024-10-12T17:21:35.843077Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"ts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   The object column \"ts\" is date and time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.003804Z",
     "start_time": "2024-10-12T17:21:35.985169Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"ts\"] = pd.to_datetime(dataset[\"connections\"].ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Cast the \"ts\" column to datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.081369Z",
     "start_time": "2024-10-12T17:21:36.034990Z"
    }
   },
   "outputs": [],
   "source": [
    "connection_summary = dataset[\"connections\"].describe()\n",
    "median = (\n",
    "    dataset[\"connections\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  # adding median to describe method output\n",
    "connection_summary.loc[\"median\"] = median\n",
    "\n",
    "# dropping imei, as it has no meaning to make these statistics out of it\n",
    "connection_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "connection_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   From these tables above we can see imei is a long integer and looks like an ID, if we look at processes table, we can also see same values indicating this could be an Id of device.\n",
    "-   Another assumption we can make is that columns specifying a connection type (columns starting with c. such as c.android.youtube) have values ranging from 0 to 100, this could indicate that it is a percentage amount of time that the connection was established.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First few rows might indicate that the data was sample in a 1 minute interval.\n",
    "-   Let's look at it closer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.183953Z",
     "start_time": "2024-10-12T17:21:36.134975Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"].sort_values(by=\"ts\", ascending=True)[\"ts\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Now we see it looks like samples are in a 1 minute interval.\n",
    "-   Let's go further.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.321677Z",
     "start_time": "2024-10-12T17:21:36.225021Z"
    }
   },
   "outputs": [],
   "source": [
    "times = dataset[\"connections\"].sort_values(by=\"ts\")[\"ts\"]\n",
    "times = pd.to_datetime(times)\n",
    "\n",
    "previous_time: Optional[pd.Series] = None\n",
    "\n",
    "same_times: int = 0\n",
    "non_minute_differences: int = 0\n",
    "\n",
    "\n",
    "for current_time in times:\n",
    "    if previous_time is None:\n",
    "        previous_time = current_time\n",
    "        continue\n",
    "\n",
    "    if (current_time - previous_time).seconds == 0:\n",
    "        same_times += 1\n",
    "\n",
    "    elif (current_time - previous_time).seconds != 60:\n",
    "        non_minute_differences += 1\n",
    "\n",
    "    previous_time = current_time\n",
    "\n",
    "print(f\"Non minute differences: {non_minute_differences}\")\n",
    "print(f\"Same times: {same_times}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   From this we can see, that there are data every minute, sometimes more than once at the same time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.478087Z",
     "start_time": "2024-10-12T17:21:36.331197Z"
    }
   },
   "outputs": [],
   "source": [
    "times = (\n",
    "    dataset[\"connections\"]\n",
    "    .groupby(by=\"imei\")[[\"imei\", \"ts\"]]\n",
    "    .apply(lambda val: val.sort_values(by=\"ts\", ascending=True))\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   If we assume that columns starting with \"c.\" are representing percentage amount of time being active during a time window, we need to group them by device serial number (imei) and then look at the time difference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.528715Z",
     "start_time": "2024-10-12T17:21:36.521212Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"mwra\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   mwra is (Malware-related-activity)\n",
    "-   In data there are only values 1.0 and 0.0 indicating if there was a malware activity in specific time frame.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Devices description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.845928Z",
     "start_time": "2024-10-12T17:21:36.835170Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"devices\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:36.934741Z",
     "start_time": "2024-10-12T17:21:36.916636Z"
    }
   },
   "outputs": [],
   "source": [
    "devices_summary = dataset[\"devices\"].describe()\n",
    "median = (\n",
    "    dataset[\"devices\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  # adding median to describe method output\n",
    "devices_summary.loc[\"median\"] = median\n",
    "\n",
    "# dropping imei, as it has no meaning to make these statistics out of it\n",
    "devices_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "devices_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:37.223828Z",
     "start_time": "2024-10-12T17:21:37.213986Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"devices\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   \"store_name\" object is a string\n",
    "-   \"code\" is string, holding code for state\n",
    "-   \"location\" is a string, containing continent and city\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processes description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:37.321167Z",
     "start_time": "2024-10-12T17:21:37.308625Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:37.395348Z",
     "start_time": "2024-10-12T17:21:37.381974Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"][\"ts\"] = pd.to_datetime(dataset[\"processes\"].ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:37.646792Z",
     "start_time": "2024-10-12T17:21:37.551318Z"
    }
   },
   "outputs": [],
   "source": [
    "processes_summary = dataset[\"processes\"].describe()\n",
    "median = (\n",
    "    dataset[\"processes\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  # adding median to describe method output\n",
    "processes_summary.loc[\"median\"] = median\n",
    "\n",
    "# dropping imei, as it has no meaning to make these statistics out of it\n",
    "processes_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "processes_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:37.843518Z",
     "start_time": "2024-10-12T17:21:37.826671Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiles description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:37.933220Z",
     "start_time": "2024-10-12T17:21:37.922873Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"profiles\"].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:38.062717Z",
     "start_time": "2024-10-12T17:21:38.045946Z"
    }
   },
   "outputs": [],
   "source": [
    "profiles_summary = dataset[\"profiles\"].describe()\n",
    "median = (\n",
    "    dataset[\"profiles\"].select_dtypes(include=[\"float64\", \"int64\"]).median()\n",
    ")  # adding median to describe method output\n",
    "profiles_summary.loc[\"median\"] = median\n",
    "\n",
    "# dropping imei, as it has no meaning to make these statistics out of it\n",
    "profiles_summary.drop(columns=[\"imei\"], inplace=True)\n",
    "profiles_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:38.177433Z",
     "start_time": "2024-10-12T17:21:38.166116Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"profiles\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:38.682739Z",
     "start_time": "2024-10-12T17:21:38.671185Z"
    }
   },
   "outputs": [],
   "source": [
    "null_values = {file: data.isnull().sum() for file, data in dataset.items()}\n",
    "for file, nulls in null_values.items():\n",
    "    if nulls.sum() == 0:\n",
    "        continue\n",
    "    print(f\"Null values in {file} dataset:\")\n",
    "    print(nulls)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MWRA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   First we look at the most important column \"mwra\" and look at it more in depth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:38.757159Z",
     "start_time": "2024-10-12T17:21:38.751049Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"connections\"][\"mwra\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   In \"connections\" we can see that positive mwra is ~62%, indicating that there are more positive cases and therefore in future when we put it into our model might falsely evaluate some connections. I would say the closer we are to 50/50 the better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:39.366588Z",
     "start_time": "2024-10-12T17:21:39.357963Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset[\"processes\"][\"mwra\"].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   \"mwra\" is the same for \"processes\" as it is for \"connections\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:39.438008Z",
     "start_time": "2024-10-12T17:21:39.426975Z"
    }
   },
   "outputs": [],
   "source": [
    "chrome_data = dataset[\"connections\"][\"c.android.chrome\"]\n",
    "chrome_mean = chrome_data.mean()\n",
    "chrome_std = chrome_data.std()\n",
    "\n",
    "dogalize_data = dataset[\"connections\"][\"c.dogalize\"]\n",
    "dogalize_mean = dogalize_data.mean()\n",
    "dogalize_std = dogalize_data.std()\n",
    "\n",
    "gm_data = dataset[\"connections\"][\"c.android.gm\"]\n",
    "gm_mean = gm_data.mean()\n",
    "gm_std = gm_data.std()\n",
    "\n",
    "youtube_data = dataset[\"connections\"][\"c.android.youtube\"]\n",
    "youtube_mean = youtube_data.mean()\n",
    "youtube_std = youtube_data.std()\n",
    "\n",
    "katana_data = dataset[\"connections\"][\"c.katana\"]\n",
    "katana_mean = katana_data.mean()\n",
    "katana_std = katana_data.std()\n",
    "\n",
    "raider_data = dataset[\"connections\"][\"c.raider\"]\n",
    "raider_mean = raider_data.mean()\n",
    "raider_std = raider_data.std()\n",
    "\n",
    "vending_data = dataset[\"connections\"][\"c.android.vending\"]\n",
    "vending_mean = vending_data.mean()\n",
    "vending_std = vending_data.std()\n",
    "\n",
    "x86_data = dataset[\"connections\"][\"c.UCMobile.x86\"]\n",
    "x86_mean = x86_data.mean()\n",
    "x86_std = x86_data.std()\n",
    "\n",
    "\n",
    "updateassist_data = dataset[\"connections\"][\"c.updateassist\"]\n",
    "updateassist_mean = updateassist_data.mean()\n",
    "updateassist_std = updateassist_data.std()\n",
    "\n",
    "intl_data = dataset[\"connections\"][\"c.UCMobile.intl\"]\n",
    "intl_mean = intl_data.mean()\n",
    "intl_std = intl_data.std()\n",
    "\n",
    "all_str_connections: list[str] = [\n",
    "    \"c.android.chrome\",\n",
    "    \"c.dogalize\",\n",
    "    \"c.android.gm\",\n",
    "    \"c.android.youtube\",\n",
    "    \"c.katana\",\n",
    "    \"c.raider\",\n",
    "    \"c.android.vending\",\n",
    "    \"c.UCMobile.x86\",\n",
    "    \"c.updateassist\",\n",
    "    \"c.UCMobile.intl\",\n",
    "]\n",
    "\n",
    "all_data_connections: list[pd.Series] = [\n",
    "    chrome_data,\n",
    "    dogalize_data,\n",
    "    gm_data,\n",
    "    youtube_data,\n",
    "    katana_data,\n",
    "    raider_data,\n",
    "    vending_data,\n",
    "    x86_data,\n",
    "    updateassist_data,\n",
    "    intl_data,\n",
    "]\n",
    "\n",
    "all_means_connections: list[float] = [\n",
    "    chrome_mean,\n",
    "    dogalize_mean,\n",
    "    gm_mean,\n",
    "    youtube_mean,\n",
    "    katana_mean,\n",
    "    raider_mean,\n",
    "    vending_mean,\n",
    "    x86_mean,\n",
    "    updateassist_mean,\n",
    "    intl_mean,\n",
    "]\n",
    "\n",
    "all_std_connections: list[float] = [\n",
    "    chrome_std,\n",
    "    dogalize_std,\n",
    "    gm_std,\n",
    "    youtube_std,\n",
    "    katana_std,\n",
    "    raider_std,\n",
    "    vending_std,\n",
    "    x86_std,\n",
    "    updateassist_std,\n",
    "    intl_std,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of dispersion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:39.732805Z",
     "start_time": "2024-10-12T17:21:39.689149Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dataset[\"connections\"].iloc[:, 3:].describe()\n",
    "df.loc[\"full_range\"] = df.loc[\"max\"] - df.loc[\"min\"]\n",
    "df.loc[\"interquartile_range\"] = df.loc[\"75%\"] - df.loc[\"25%\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:39.827950Z",
     "start_time": "2024-10-12T17:21:39.785954Z"
    }
   },
   "outputs": [],
   "source": [
    "apps = all_str_connections\n",
    "\n",
    "means = all_means_connections\n",
    "\n",
    "medians = [\n",
    "    chrome_data.median(),\n",
    "    dogalize_data.median(),\n",
    "    gm_data.median(),\n",
    "    youtube_data.median(),\n",
    "    katana_data.median(),\n",
    "    raider_data.median(),\n",
    "    vending_data.median(),\n",
    "    x86_data.median(),\n",
    "    updateassist_data.median(),\n",
    "    intl_data.median(),\n",
    "]\n",
    "\n",
    "max_values = []\n",
    "most_occurring_values = []\n",
    "\n",
    "value_counts = chrome_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = dogalize_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = gm_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = youtube_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = katana_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = raider_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = vending_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = x86_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = updateassist_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "value_counts = intl_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "for i in range(len(most_occurring_values)):\n",
    "    most_occurring_values[i] = most_occurring_values[i][: min(3, len(most_occurring_values[i]))]\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"connection\": apps,\n",
    "    \"mean\": means,\n",
    "    \"median\": medians,\n",
    "    \"mode_count\": max_values,\n",
    "    \"mode_values\": most_occurring_values,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:39.893605Z",
     "start_time": "2024-10-12T17:21:39.889687Z"
    }
   },
   "outputs": [],
   "source": [
    "def skewness_type(skew_value: float) -> str:\n",
    "    if skew_value <= -1:\n",
    "        return \"Highly Negative Skew\"\n",
    "\n",
    "    elif skew_value <= -0.5:\n",
    "        return \"Moderately Negative Skew\"\n",
    "\n",
    "    elif skew_value <= 0.5:\n",
    "        return \"Approximately Symmetric\"\n",
    "\n",
    "    elif skew_value <= 1:\n",
    "        return \"Moderately Positive Skew\"\n",
    "\n",
    "    return \"Highly Positive Skew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:40.021223Z",
     "start_time": "2024-10-12T17:21:40.016876Z"
    }
   },
   "outputs": [],
   "source": [
    "def kurtosis_type(kurtosis_value: float) -> str:\n",
    "    if kurtosis_value < -1:\n",
    "        return \"Negative Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < -0.5:\n",
    "        return \"Moderately Negative Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < 0.5:\n",
    "        return \"Approximately Normal Kurtosis\"\n",
    "\n",
    "    elif kurtosis_value < 1:\n",
    "        return \"Moderately Positive Kurtosis\"\n",
    "\n",
    "    return \"Positive Kurtosis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:40.132927Z",
     "start_time": "2024-10-12T17:21:40.107826Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"connection\": all_str_connections,\n",
    "    \"skew\": [\n",
    "        stats.skew(chrome_data),\n",
    "        stats.skew(dogalize_data),\n",
    "        stats.skew(gm_data),\n",
    "        stats.skew(youtube_data),\n",
    "        stats.skew(katana_data),\n",
    "        stats.skew(raider_data),\n",
    "        stats.skew(vending_data),\n",
    "        stats.skew(x86_data),\n",
    "        stats.skew(updateassist_data),\n",
    "        stats.skew(intl_data),\n",
    "    ],\n",
    "    \"kurtosis\": [\n",
    "        stats.kurtosis(chrome_data),\n",
    "        stats.kurtosis(dogalize_data),\n",
    "        stats.kurtosis(gm_data),\n",
    "        stats.kurtosis(youtube_data),\n",
    "        stats.kurtosis(katana_data),\n",
    "        stats.kurtosis(raider_data),\n",
    "        stats.kurtosis(vending_data),\n",
    "        stats.kurtosis(x86_data),\n",
    "        stats.kurtosis(updateassist_data),\n",
    "        stats.kurtosis(intl_data),\n",
    "    ],\n",
    "}\n",
    "\n",
    "shape_df = pd.DataFrame(data)\n",
    "\n",
    "shape_df[\"result skew\"] = shape_df[\"skew\"].apply(skewness_type)\n",
    "shape_df[\"result kurtosis\"] = shape_df[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_df.set_index(\"connection\", inplace=True)\n",
    "shape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms with KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:45.185620Z",
     "start_time": "2024-10-12T17:21:40.441441Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "\n",
    "# Having all the data in a list, we can iterate over it and plot the histogram with KDE for each connection.\n",
    "for i in range(len(all_data_connections)):\n",
    "    sns.histplot(all_data_connections[i], bins=30, kde=True, ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        all_means_connections[i], color=\"r\", linestyle=\"--\", label=f\"Mean: {all_means_connections[i]:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Skewness: {shape_df.loc[all_str_connections[i]]['skew']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Kurtosis: {shape_df.loc[all_str_connections[i]]['kurtosis']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:49.421632Z",
     "start_time": "2024-10-12T17:21:45.186582Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "for i in range(len(all_data_connections)):\n",
    "    sns.histplot(\n",
    "        data=all_data_connections[i],\n",
    "        bins=30,\n",
    "        stat=\"density\",\n",
    "        alpha=0.3,\n",
    "        color=\"gray\",\n",
    "        label=\"Histogram\",\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=all_data_connections[i],\n",
    "        color=\"blue\",\n",
    "        label=\"Actual Distribution\",\n",
    "        linewidth=2,\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "\n",
    "    if i <= 5:  # We know that first 6 connections are not uniform\n",
    "        x = np.linspace(all_data_connections[i].min(), all_data_connections[i].max(), 100)\n",
    "        gaussian = stats.norm.pdf(x, all_means_connections[i], all_std_connections[i])\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, gaussian, color=\"red\", linestyle=\"--\", label=\"Gaussian Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        a = all_data_connections[i].min()\n",
    "        b = all_data_connections[i].max()\n",
    "        x = np.linspace(a, b, all_data_connections[i].size)\n",
    "        uniform_dist = stats.uniform(loc=a, scale=b - a)\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, uniform_dist.pdf(x), color=\"red\", linestyle=\"--\", label=\"Uniform Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:50.991621Z",
     "start_time": "2024-10-12T17:21:49.422641Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "for i in range(len(all_data_connections)):\n",
    "    sns.boxplot(all_data_connections[i], ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Q plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:53.156862Z",
     "start_time": "2024-10-12T17:21:50.992627Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(5, 2, figsize=(16, 26))\n",
    "\n",
    "for i in range(len(all_data_connections)):\n",
    "    sm.qqplot(all_data_connections[i], fit=True, line=\"45\", ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_connections[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "# Adjust the layout\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:53.174585Z",
     "start_time": "2024-10-12T17:21:53.157870Z"
    }
   },
   "outputs": [],
   "source": [
    "chrome_data = dataset[\"processes\"][\"p.android.chrome\"]\n",
    "chrome_mean = chrome_data.mean()\n",
    "chrome_std = chrome_data.std()\n",
    "\n",
    "dogalize_data = dataset[\"processes\"][\"p.dogalize\"]\n",
    "dogalize_mean = dogalize_data.mean()\n",
    "dogalize_std = dogalize_data.std()\n",
    "\n",
    "katana_data = dataset[\"processes\"][\"p.katana\"]\n",
    "katana_mean = katana_data.mean()\n",
    "katana_std = katana_data.std()\n",
    "\n",
    "settings_data = dataset[\"processes\"][\"p.android.settings\"]\n",
    "settings_mean = settings_data.mean()\n",
    "settings_std = settings_data.std()\n",
    "\n",
    "system_data = dataset[\"processes\"][\"p.system\"]\n",
    "system_mean = system_data.mean()\n",
    "system_std = system_data.std()\n",
    "\n",
    "simulator_data = dataset[\"processes\"][\"p.simulator\"]\n",
    "simulator_mean = simulator_data.mean()\n",
    "simulator_std = simulator_data.std()\n",
    "\n",
    "all_str_processes: list[str] = [\n",
    "    \"p.android.chrome\",\n",
    "    \"p.dogalize\",\n",
    "    \"p.katana\",\n",
    "    \"p.android.settings\",\n",
    "    \"p.system\",\n",
    "    \"p.simulator\",\n",
    "]\n",
    "\n",
    "all_data_processes: list[pd.Series] = [\n",
    "    chrome_data,\n",
    "    dogalize_data,\n",
    "    katana_data,\n",
    "    settings_data,\n",
    "    system_data,\n",
    "    simulator_data,\n",
    "]\n",
    "\n",
    "all_means_processes: list[float] = [\n",
    "    chrome_mean,\n",
    "    dogalize_mean,\n",
    "    katana_mean,\n",
    "    settings_mean,\n",
    "    system_mean,\n",
    "    simulator_mean,\n",
    "]\n",
    "\n",
    "all_std_processes: list[float] = [\n",
    "    chrome_std,\n",
    "    dogalize_std,\n",
    "    katana_std,\n",
    "    settings_std,\n",
    "    system_std,\n",
    "    simulator_std,\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of dispersion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:53.203559Z",
     "start_time": "2024-10-12T17:21:53.175592Z"
    }
   },
   "outputs": [],
   "source": [
    "df = dataset[\"processes\"][all_str_processes].describe()\n",
    "df.loc[\"full_range\"] = df.loc[\"max\"] - df.loc[\"min\"]\n",
    "df.loc[\"interquartile_range\"] = df.loc[\"75%\"] - df.loc[\"25%\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of center\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:53.236241Z",
     "start_time": "2024-10-12T17:21:53.204565Z"
    }
   },
   "outputs": [],
   "source": [
    "apps = all_str_processes\n",
    "\n",
    "means = all_means_processes\n",
    "\n",
    "medians = [\n",
    "    chrome_data.median(),\n",
    "    dogalize_data.median(),\n",
    "    katana_data.median(),\n",
    "    settings_data.median(),\n",
    "    system_data.median(),\n",
    "    simulator_data.median(),\n",
    "]\n",
    "\n",
    "max_values = []\n",
    "most_occurring_values = []\n",
    "\n",
    "value_counts = chrome_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = dogalize_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = katana_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = settings_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = system_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "\n",
    "value_counts = simulator_data.value_counts()\n",
    "max_val = value_counts.max()\n",
    "max_values.append(max_val)\n",
    "most_occurring_values.append(value_counts[value_counts == max_val].index.tolist())\n",
    "\n",
    "for i in range(len(most_occurring_values)):\n",
    "    most_occurring_values[i] = most_occurring_values[i][: min(3, len(most_occurring_values[i]))]\n",
    "\n",
    "\n",
    "data = {\n",
    "    \"process\": apps,\n",
    "    \"mean\": means,\n",
    "    \"median\": medians,\n",
    "    \"mode_count\": max_values,\n",
    "    \"mode_values\": most_occurring_values,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measure of shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:53.256770Z",
     "start_time": "2024-10-12T17:21:53.237247Z"
    }
   },
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"process\": all_str_processes,\n",
    "    \"skew\": [\n",
    "        stats.skew(chrome_data),\n",
    "        stats.skew(dogalize_data),\n",
    "        stats.skew(katana_data),\n",
    "        stats.skew(settings_data),\n",
    "        stats.skew(system_data),\n",
    "        stats.skew(simulator_data),\n",
    "    ],\n",
    "    \"kurtosis\": [\n",
    "        stats.kurtosis(chrome_data),\n",
    "        stats.kurtosis(dogalize_data),\n",
    "        stats.kurtosis(katana_data),\n",
    "        stats.kurtosis(settings_data),\n",
    "        stats.kurtosis(system_data),\n",
    "        stats.kurtosis(simulator_data),\n",
    "    ],\n",
    "}\n",
    "\n",
    "shape_df = pd.DataFrame(data)\n",
    "shape_df[\"result skew\"] = shape_df[\"skew\"].apply(skewness_type)\n",
    "shape_df[\"result kurtosis\"] = shape_df[\"kurtosis\"].apply(kurtosis_type)\n",
    "shape_df.set_index(\"process\", inplace=True)\n",
    "shape_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histograms with KDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:56.571017Z",
     "start_time": "2024-10-12T17:21:53.257776Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sns.histplot(all_data_processes[i], bins=30, kde=True, ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        all_means_processes[i], color=\"r\", linestyle=\"--\", label=f\"Mean: {all_means_processes[i]:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Skewness: {shape_df.loc[all_str_processes[i]]['skew']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].axvline(\n",
    "        linestyle=\"\", label=f\"Kurtosis: {shape_df.loc[all_str_processes[i]]['kurtosis']:.2f}\"\n",
    "    )\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:21:59.877574Z",
     "start_time": "2024-10-12T17:21:56.574532Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "gaussian_models = [chrome_data, settings_data, system_data]\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sns.histplot(\n",
    "        data=all_data_processes[i],\n",
    "        bins=30,\n",
    "        stat=\"density\",\n",
    "        alpha=0.3,\n",
    "        color=\"gray\",\n",
    "        label=\"Histogram\",\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "    sns.kdeplot(\n",
    "        data=all_data_processes[i],\n",
    "        color=\"blue\",\n",
    "        label=\"Actual Distribution\",\n",
    "        linewidth=2,\n",
    "        ax=axes[i // 2, i % 2],\n",
    "    )\n",
    "\n",
    "    if any(all_data_processes[i] is model for model in gaussian_models):\n",
    "        x = np.linspace(all_data_processes[i].min(), all_data_processes[i].max(), 100)\n",
    "        gaussian = stats.norm.pdf(x, all_means_processes[i], all_std_processes[i])\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, gaussian, color=\"red\", linestyle=\"--\", label=\"Gaussian Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        a = all_data_processes[i].min()\n",
    "        b = all_data_processes[i].max()\n",
    "        x = np.linspace(a, b, all_data_processes[i].size)\n",
    "        uniform_dist = stats.uniform(loc=a, scale=b - a)\n",
    "        axes[i // 2, i % 2].plot(\n",
    "            x, uniform_dist.pdf(x), color=\"red\", linestyle=\"--\", label=\"Uniform Model\", linewidth=2\n",
    "        )\n",
    "\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].legend()\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boxplots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:22:00.778283Z",
     "start_time": "2024-10-12T17:21:59.878176Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sns.boxplot(all_data_processes[i], ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-Q plots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-12T17:22:02.135451Z",
     "start_time": "2024-10-12T17:22:00.779188Z"
    }
   },
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(3, 2, figsize=(16, 16))\n",
    "\n",
    "\n",
    "for i in range(len(all_data_processes)):\n",
    "    sm.qqplot(all_data_processes[i], fit=True, line=\"45\", ax=axes[i // 2, i % 2])\n",
    "    axes[i // 2, i % 2].set_title(f\"Distribution of {all_str_processes[i]}\")\n",
    "    axes[i // 2, i % 2].grid(True, alpha=0.3)\n",
    "\n",
    "\n",
    "plt.tight_layout(w_pad=3, h_pad=3)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
